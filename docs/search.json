[{"path":"https://khliland.github.io/multiblock/articles/vignette_A_data.html","id":"read-from-file","dir":"Articles","previous_headings":"","what":"Read from file","title":"A. Data handling","text":"Data stored many different file formats. following three examples cover two types CSV-files generic flat files.","code":"# Find directory extdata from the multiblock package mbdir <- system.file('extdata/', package = \"multiblock\")  # Comma separated values, row names in first column meta_data <- read.csv(paste0(mbdir, \"/meta_data.csv\"), row.names = 1) # If working directory matches file location: # meta_data <- read.csv('meta_data.csv', row.names = 1) meta_data #>         temperature colour #> John           38.0   blue #> Julia          37.0  green #> James          37.5   blue #> Jacob          37.6    red #> Jane           37.2    red #> Johanna        37.9  green  # Semi-colon separated values (locales where the decimal point is comma), # no row names proteins <- read.csv2(paste0(mbdir, \"/proteins.csv\")) proteins #>         prot1       prot2      prot3 #> 1  0.46532048  0.30183300 -1.4654414 #> 2 -1.79802081 -0.22812232 -0.4639203 #> 3 -1.92962434 -0.40513080  0.1767796 #> 4  0.87437138  0.79843798  0.1234731 #> 5 -0.62445278 -0.07975479 -1.1126332 #> 6 -0.07493721  1.09576027  1.2656596  # Blank space separated data without labels genes <- read.table(paste0(mbdir, \"/genes.dat\")) genes #>            V1         V2         V3 #> 1  0.39033106 -0.5720390  1.9147573 #> 2  0.55352785  0.0948703 -0.2239755 #> 3  0.09872346 -0.1029385  0.9047138 #> 4 -0.59213740 -0.6027739  0.6177083 #> 5 -0.02350148  0.3572809 -0.5168416 #> 6  0.76644845  1.2863428  1.8239298"},{"path":"https://khliland.github.io/multiblock/articles/vignette_A_data.html","id":"data-pre-processing","dir":"Articles","previous_headings":"","what":"Data pre-processing","title":"A. Data handling","text":"analysis, various types pre-processing may needed. Centring standardising/scaling may considered basic. R, operations performed column-wise default, leading autoscaling. operations performed rows, perform standard normal variate (SNV) instead.","code":"# Column-centring genes_centred <- scale(genes, scale=FALSE) colMeans(genes_centred) # Check mean values #>           V1           V2           V3  #> 1.850372e-17 0.000000e+00 7.401487e-17  # Autoscaling genes_scaled <- scale(genes) apply(genes_scaled, 2, sd) # Check standard deviations #> V1 V2 V3  #>  1  1  1  # SNV (transpose, autoscale, re-transpose) genes_snv <- t(scale(t(genes))) apply(genes_snv, 1, sd) # Check standard deviations #> [1] 1 1 1 1 1 1"},{"path":"https://khliland.github.io/multiblock/articles/vignette_A_data.html","id":"re-coding-categorical-data","dir":"Articles","previous_headings":"Data pre-processing","what":"Re-coding categorical data","title":"A. Data handling","text":"analysis methods require continuous input data. meta_data data.frame contains character vector (factor older R versions) categories. package function dummycode converting categorical data various dummy formats.","code":"# Default is sum coding dummycode(meta_data$colour) #>   x1 x2 #> 1  1  0 #> 2  0  1 #> 3  1  0 #> 4 -1 -1 #> 5 -1 -1 #> 6  0  1  # Treatment coding dummycode(meta_data$colour, \"contr.treatment\") #>   xgreen xred #> 1      0    0 #> 2      1    0 #> 3      0    0 #> 4      0    1 #> 5      0    1 #> 6      1    0  # Full dummy-coding (rank deficient) dummycode(meta_data$colour, drop = FALSE) #>   xblue xgreen xred #> 1     1      0    0 #> 2     0      1    0 #> 3     1      0    0 #> 4     0      0    1 #> 5     0      0    1 #> 6     0      1    0  # Replace categorical with dummy-coded, use I() to index by common name meta_data2 <- meta_data meta_data2$colour <- I(dummycode(meta_data$colour, drop = FALSE)) meta_data2 #>         temperature colour.xblue colour.xgreen colour.xred #> John           38.0            1             0           0 #> Julia          37.0            0             1           0 #> James          37.5            1             0           0 #> Jacob          37.6            0             0           1 #> Jane           37.2            0             0           1 #> Johanna        37.9            0             1           0 meta_data2$colour #>   xblue xgreen xred #> 1     1      0    0 #> 2     0      1    0 #> 3     1      0    0 #> 4     0      0    1 #> 5     0      0    1 #> 6     0      1    0"},{"path":[]},{"path":"https://khliland.github.io/multiblock/articles/vignette_A_data.html","id":"create-list-of-blocks","dir":"Articles","previous_headings":"Data structures for multiblock analysis","what":"Create list of blocks","title":"A. Data handling","text":"simple list blocks can created using list() function. Naming blocks can done directly creation.","code":"# Direct approach blocks1 <- list(meta = meta_data2, proteins = proteins, genes = genes)  # Two-step approach blocks2 <- list(meta_data2, proteins, genes) names(blocks2) <- c('meta', 'proteins', 'genes')  # Same result identical(blocks1, blocks2) #> [1] TRUE  # Access by name or number blocks1[['meta']] #>         temperature colour.xblue colour.xgreen colour.xred #> John           38.0            1             0           0 #> Julia          37.0            0             1           0 #> James          37.5            1             0           0 #> Jacob          37.6            0             0           1 #> Jane           37.2            0             0           1 #> Johanna        37.9            0             1           0 blocks2[[1]] #>         temperature colour.xblue colour.xgreen colour.xred #> John           38.0            1             0           0 #> Julia          37.0            0             1           0 #> James          37.5            1             0           0 #> Jacob          37.6            0             0           1 #> Jane           37.2            0             0           1 #> Johanna        37.9            0             1           0"},{"path":"https://khliland.github.io/multiblock/articles/vignette_A_data.html","id":"create-data-frame-of-blocks","dir":"Articles","previous_headings":"Data structures for multiblock analysis","what":"Create data.frame of blocks","title":"A. Data handling","text":"data.frame convenient storage format data R can handle many types variables, e.g. numeric, logical, character, factor matrices. latter useful analyses data shared sample mode.","code":"# Construct block data.frame from list df1 <- block.data.frame(blocks1)  # Construct block data.frame from data.frame: # First merge blocks into data.frame my_data <- cbind(meta_data2, proteins, genes) # Then construct block data.frame using named  # list of indexes df2 <- block.data.frame(my_data, block_inds =          list(meta = 1:2, proteins = 3:5, genes = 6:8))  # Same result identical(df1,df2) #> [1] TRUE  # Access by name or number df1[[2]] #>               prot1       prot2      prot3 #> John     0.46532048  0.30183300 -1.4654414 #> Julia   -1.79802081 -0.22812232 -0.4639203 #> James   -1.92962434 -0.40513080  0.1767796 #> Jacob    0.87437138  0.79843798  0.1234731 #> Jane    -0.62445278 -0.07975479 -1.1126332 #> Johanna -0.07493721  1.09576027  1.2656596 df2[['proteins']] #>               prot1       prot2      prot3 #> John     0.46532048  0.30183300 -1.4654414 #> Julia   -1.79802081 -0.22812232 -0.4639203 #> James   -1.92962434 -0.40513080  0.1767796 #> Jacob    0.87437138  0.79843798  0.1234731 #> Jane    -0.62445278 -0.07975479 -1.1126332 #> Johanna -0.07493721  1.09576027  1.2656596 df1[c(1,3)] #>         meta.temperature meta.colour.xblue meta.colour.xgreen meta.colour.xred #> John                38.0               1.0                0.0              0.0 #> Julia               37.0               0.0                1.0              0.0 #> James               37.5               1.0                0.0              0.0 #> Jacob               37.6               0.0                0.0              1.0 #> Jane                37.2               0.0                0.0              1.0 #> Johanna             37.9               0.0                1.0              0.0 #>            genes.V1    genes.V2    genes.V3 #> John     0.39033106 -0.57203901  1.91475732 #> Julia    0.55352785  0.09487030 -0.22397553 #> James    0.09872346 -0.10293847  0.90471382 #> Jacob   -0.59213740 -0.60277392  0.61770832 #> Jane    -0.02350148  0.35728086 -0.51684156 #> Johanna  0.76644845  1.28634283  1.82392983 df1[-2] #>         meta.temperature meta.colour.xblue meta.colour.xgreen meta.colour.xred #> John                38.0               1.0                0.0              0.0 #> Julia               37.0               0.0                1.0              0.0 #> James               37.5               1.0                0.0              0.0 #> Jacob               37.6               0.0                0.0              1.0 #> Jane                37.2               0.0                0.0              1.0 #> Johanna             37.9               0.0                1.0              0.0 #>            genes.V1    genes.V2    genes.V3 #> John     0.39033106 -0.57203901  1.91475732 #> Julia    0.55352785  0.09487030 -0.22397553 #> James    0.09872346 -0.10293847  0.90471382 #> Jacob   -0.59213740 -0.60277392  0.61770832 #> Jane    -0.02350148  0.35728086 -0.51684156 #> Johanna  0.76644845  1.28634283  1.82392983 df2[c('proteins','genes')] #>         proteins.prot1 proteins.prot2 proteins.prot3    genes.V1    genes.V2 #> John        0.46532048     0.30183300    -1.46544136  0.39033106 -0.57203901 #> Julia      -1.79802081    -0.22812232    -0.46392027  0.55352785  0.09487030 #> James      -1.92962434    -0.40513080     0.17677963  0.09872346 -0.10293847 #> Jacob       0.87437138     0.79843798     0.12347308 -0.59213740 -0.60277392 #> Jane       -0.62445278    -0.07975479    -1.11263323 -0.02350148  0.35728086 #> Johanna    -0.07493721     1.09576027     1.26565956  0.76644845  1.28634283 #>            genes.V3 #> John     1.91475732 #> Julia   -0.22397553 #> James    0.90471382 #> Jacob    0.61770832 #> Jane    -0.51684156 #> Johanna  1.82392983  # Use with formula interface (see other vignettes) # sopls(meta ~ proteins + genes, data = df1)  # Use with single list interface (see other vignettes) # mfa(df1[c(1,3)], ncomp = 3)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_B_basic.html","id":"basic-methods","dir":"Articles","previous_headings":"","what":"Basic methods","title":"B. Basic analysis","text":"following single- two-block methods available multiblock package (function names parentheses): PCA - Principal Component Analysis (pca) PCR - Principal Component Regression (pcr) PLSR - Partial Least Squares Regression (plsr) CCA - Canonical Correlation Analysis (cca) IFA - Interbattery Factor Analysis (ifa) GSVD - Generalized SVD (gsvd) following sections describe format data analysis invoke methods list .","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_B_basic.html","id":"prepare-data","dir":"Articles","previous_headings":"Basic methods","what":"Prepare data","title":"B. Basic analysis","text":"use selection extracts potato data included package basic data analyses. data set stored named list nine matrices chemical, rheological, spectral sensory measurements measurements 26 raw cooked potatoes.","code":"data(potato) X <- potato$Chemical y <- potato$Sensory[,1,drop=FALSE]"},{"path":"https://khliland.github.io/multiblock/articles/vignette_B_basic.html","id":"modelling","dir":"Articles","previous_headings":"Basic methods","what":"Modelling","title":"B. Basic analysis","text":"Since basic methods cover single block analysis, supervised unsupervised analysis, interfaces basic methods vary bit. Supervised methods use formula interface remaining methods take input single matrix list matrices. See vignettes supervised unsupervised analysis details.","code":"# Single block pot.pca  <- pca(X, ncomp = 2)  # Two blocks, supervised pot.pcr  <- pcr(y ~ X, ncomp = 2) pot.pls  <- plsr(y ~ X, ncomp = 2)  # Two blocks, unsupervised pot.cca  <- cca(potato[1:2]) pot.ifa  <- ifa(potato[1:2])  # Variable linked decomposition pot.gsvd <- gsvd(lapply(potato[3:4], t))"},{"path":"https://khliland.github.io/multiblock/articles/vignette_B_basic.html","id":"common-output-elements-across-methods","dir":"Articles","previous_headings":"Basic methods","what":"Common output elements across methods","title":"B. Basic analysis","text":"Output methods include matrices called loadings, scores, blockLoadings blockScores, suitable subset according method used. info list describes types (block) loadings/scores output. may various extra elements addition common elements, e.g. coefficients, weights etc. names() summary() functions show elements object summary based info list, respectively.","code":"# PCA returns loadings and scores: names(pot.pca) #> [1] \"loadings\" \"scores\"   \"Xmeans\"   \"explvar\"  \"PCA\"      \"info\"     \"call\" summary(pot.pca) #> Principal Component Analysis  #> ============================  #>  #> $scores: Scores (26x2) #> $loadings: Loadings (14x2) # GSVD returns block scores and common loadings: names(pot.gsvd) #> [1] \"loadings\"    \"blockScores\" \"GSVD\"        \"info\"        \"call\" summary(pot.gsvd) #> Generalized Singular Value Decomposition  #> ========================================  #>  #> $loadings: Loadings (26x26) #> $blockScores: Block scores: #> - NIRraw (1050x1050), NIRcooked (1050x1050)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_B_basic.html","id":"scores-and-loadings","dir":"Articles","previous_headings":"Basic methods","what":"Scores and loadings","title":"B. Basic analysis","text":"Functions accessing scores loadings based functions pls package, extended block parameter allow extraction common/global scores/loadings block counterparts. default value block 0, corresponding common/global block. Block scores/loadings can accessed setting block number name.","code":"# Global scores plotted with object labels scoreplot(pot.pca, labels = \"names\") # Block loadings for Chemical block with variable labels in scatter format loadingplot(pot.cca, block = \"Chemical\", labels = \"names\") # Non-existing elements are swapped with existing ones with a warning. sc <- scores(pot.cca) #> Warning in scores.multiblock(pot.cca): No global/consensus scores. Returning #> block 1 scores."},{"path":"https://khliland.github.io/multiblock/articles/vignette_C_unsupervised.html","id":"unsupervised-methods","dir":"Articles","previous_headings":"","what":"Unsupervised methods","title":"C. Unsupervised multiblock analysis","text":"following unsupervised methods available multiblock package (function names parentheses): SCA - Simultaneous Component Analysis (sca) GCA - Generalised Canonical Analysis (gca) GPA - Generalised Procrustes Analysis (gpa) MFA - Multiple Factor Analysis (mfa) PCA-GCA (pcagca) DISCO - Distinct Common Components SCA (disco) HPCA - Hierarchical Principal component analysis (hpca) MCOA - Multiple Co-Inertia Analysis (mcoa) JIVE - Joint Individual Variation Explained (jive) STATIS - Structuration des Tableaux à Trois Indices de la Statistique (statis) HOGSVD - Higher Order Generalized SVD (hogsvd) following sections describe format data analysis invoke methods list .","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_C_unsupervised.html","id":"formatting-data-for-multiblock-data-analysis","dir":"Articles","previous_headings":"","what":"Formatting data for multiblock data analysis","title":"C. Unsupervised multiblock analysis","text":"Data blocks best stored named lists use unsupervised methods package. also column names row names used blocks, can used easy labelling plots supplied pls package. See examples illustrations .","code":"# Load potato data data(potato) class(potato) #> [1] \"data.frame\" # data.frames can contain matrices as variables,  # thus becoming object linked lists of blocks. str(potato[1:3]) #> 'data.frame':    26 obs. of  3 variables: #>  $ Chemical   : 'AsIs' num [1:26, 1:14] 3.21 3.26 5.18 3.75 2.92 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:26] \"1\" \"2\" \"3\" \"4\" ... #>   .. ..$ : chr [1:14] \"PEU\" \"Sta.\" \"TotN\" \"Phy.\" ... #>  $ Compression: 'AsIs' num [1:26, 1:12] 2.23 1.21 1.63 2.68 2.85 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:26] \"1\" \"2\" \"3\" \"4\" ... #>   .. ..$ : chr [1:12] \"FW20\" \"BW20\" \"ST20\" \"SH20\" ... #>  $ NIRraw     : 'AsIs' num [1:26, 1:1050] -0.831 -0.807 -0.836 -0.78 -0.769 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:26] \"1\" \"2\" \"3\" \"4\" ... #>   .. ..$ : chr [1:1050] \"400\" \"402\" \"404\" \"406\" ...  # Explicit conversion to a list potList <- as.list(potato[1:3]) str(potList) #> List of 3 #>  $ Chemical   : 'AsIs' num [1:26, 1:14] 3.21 3.26 5.18 3.75 2.92 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:26] \"1\" \"2\" \"3\" \"4\" ... #>   .. ..$ : chr [1:14] \"PEU\" \"Sta.\" \"TotN\" \"Phy.\" ... #>  $ Compression: 'AsIs' num [1:26, 1:12] 2.23 1.21 1.63 2.68 2.85 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:26] \"1\" \"2\" \"3\" \"4\" ... #>   .. ..$ : chr [1:12] \"FW20\" \"BW20\" \"ST20\" \"SH20\" ... #>  $ NIRraw     : 'AsIs' num [1:26, 1:1050] -0.831 -0.807 -0.836 -0.78 -0.769 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:26] \"1\" \"2\" \"3\" \"4\" ... #>   .. ..$ : chr [1:1050] \"400\" \"402\" \"404\" \"406\" ..."},{"path":"https://khliland.github.io/multiblock/articles/vignette_C_unsupervised.html","id":"method-interfaces","dir":"Articles","previous_headings":"","what":"Method interfaces","title":"C. Unsupervised multiblock analysis","text":"unsupervised methods supplied package share common interface expects list blocks first input. Methods imported packages wrapped function gives mentioned interface. Results imported method stored separate slot output case specialised plot summary functions available direct inspection needed. default parameters used, single list blocks suitably linked matrices (shared objects variables) result basic analysis (see first code block ). addition, methods parameters control behaviour, e.g., number components, convergence criteria etc.","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_C_unsupervised.html","id":"shared-sample-mode","dir":"Articles","previous_headings":"Method interfaces","what":"Shared sample mode","title":"C. Unsupervised multiblock analysis","text":"following block code loads multiblock data set, extracts three blocks runs included unsupervised methods shared sample mode using interface.","code":"# Object linked data data(potato) potList <- as.list(potato[c(1,2,9)])  suppressWarnings( # FactoMineR <=2.3 uses recycling of length 1 array. invisible({capture.output({ # DISCOsca in package RegularizedSCA is highly verbose. pot.sca    <- sca(potList) pot.gca    <- gca(potList) pot.gpa    <- gpa(potList) pot.mfa    <- mfa(potList) pot.pcagca <- pcagca(potList) pot.disco  <- disco(potList) pot.hpca   <- hpca(potList) pot.mcoa   <- mcoa(potList) })}))"},{"path":"https://khliland.github.io/multiblock/articles/vignette_C_unsupervised.html","id":"shared-variable-mode","dir":"Articles","previous_headings":"Method interfaces","what":"Shared variable mode","title":"C. Unsupervised multiblock analysis","text":"following block code loads sensory data set, extracts blocks runs included unsupervised methods shared variable mode using interface.","code":"# Shared variable mode data data(candies) candyList  <- lapply(1:nlevels(candies$candy), function(x)candies$assessment[candies$candy==x,])  invisible({capture.output({ # jive in package r.jive is highly verbose. can.sca    <- sca(candyList, samplelinked = FALSE) can.jive   <- jive(candyList) can.statis <- statis(candyList) can.hogsvd <- hogsvd(candyList) })})"},{"path":"https://khliland.github.io/multiblock/articles/vignette_C_unsupervised.html","id":"common-output-elements-across-methods","dir":"Articles","previous_headings":"Method interfaces","what":"Common output elements across methods","title":"C. Unsupervised multiblock analysis","text":"Output methods include slots called loadings, scores, blockLoadings blockScores, suitable subset . info slot describes types (block) loadings/scores output. may various extra elements addition common elements, e.g. coefficients, weights etc.","code":"# SCA used with shared variable mode data returns block loadings and common scores: names(pot.sca) #> [1] \"blockLoadings\" \"scores\"        \"samplelinked\"  \"info\"          #> [5] \"explvar\"       \"call\"          \"data\" summary(pot.sca) #> Simultaneous Component Analysis  #> ===============================  #>  #> $scores: Common scores (26x2) #> $blockLoadings: Block loadings: #> - Chemical (14x2), Compression (12x2), Sensory (9x2) # MFA stores individual PCA scores and loadings as block elements: names(pot.mfa) #> [1] \"scores\"        \"loadings\"      \"blockScores\"   \"blockLoadings\" #> [5] \"info\"          \"MFA\"           \"call\"          \"explvar\"       #> [9] \"data\" summary(pot.mfa) #> Multiple Factor Analysis  #> ========================  #>  #> $scores: Global scores (26x5) #> $loadings: Global loadings (35x5) #> $blockScores: Individual PCA scores: #> - Chemical (26x5), Compression (26x5), Sensory (26x5) #> $blockLoadings: Individual PCA loadings: #> - Chemical (14x5), Compression (12x5), Sensory (9x5)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_C_unsupervised.html","id":"scores-and-loadings","dir":"Articles","previous_headings":"Method interfaces","what":"Scores and loadings","title":"C. Unsupervised multiblock analysis","text":"Functions accessing scores loadings based functions pls package, extended block parameter allow extraction common/global scores/loadings block counterparts. default block 0, corresponding common/global block. Block scores/loadings can accessed number name.","code":"# Global scores plotted with object labels scoreplot(pot.sca, labels = \"names\") # Block loadings for Sensory block with variable labels in scatter format loadingplot(pot.sca, block = \"Sensory\", labels = \"names\") # Non-existing elements are swapped with existing ones with a warning. sc <- scores(pot.sca, block = 1) #> Warning in scores.multiblock(pot.sca, block = 1): No block scores. Returning #> global/consensus scores."},{"path":"https://khliland.github.io/multiblock/articles/vignette_C_unsupervised.html","id":"plot-from-imported-package","dir":"Articles","previous_headings":"Method interfaces","what":"Plot from imported package","title":"C. Unsupervised multiblock analysis","text":"methods package wrappers imported methods packages. Using stored object imported method (see $statis code ), one can exploit methods original package expand methods available package. example summary plot statis method package ade4.","code":"# Apply a plot function from ade4 (no extra import required). plot(can.statis$statis)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_D_asca.html","id":"anova-simultaneous-component-analysis-asca","dir":"Articles","previous_headings":"","what":"ANOVA Simultaneous Component Analysis – ASCA","title":"D. ASCA","text":"following example uses simulated dataset showcasing possibilities ASCA method.","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_D_asca.html","id":"simulated-data","dir":"Articles","previous_headings":"ANOVA Simultaneous Component Analysis – ASCA","what":"Simulated data","title":"D. ASCA","text":"Two categorical factors covariate simulated together standard normal set 10 responses.","code":"set.seed(1) dataset   <- data.frame(y = I(matrix(rnorm(24*10), ncol = 10)),                          x = factor(c(rep(2,8), rep(1,8), rep(0,8))),                          z = factor(rep(c(1,0), 12)), w = rnorm(24)) colnames(dataset$y) <- paste('Var', 1:10, sep = \" \") rownames(dataset)   <- paste('Obj', 1:24, sep = \" \") str(dataset) #> 'data.frame':    24 obs. of  4 variables: #>  $ y: 'AsIs' num [1:24, 1:10] -0.626 0.184 -0.836 1.595 0.33 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:10] \"Var 1\" \"Var 2\" \"Var 3\" \"Var 4\" ... #>  $ x: Factor w/ 3 levels \"0\",\"1\",\"2\": 3 3 3 3 3 3 3 3 2 2 ... #>  $ z: Factor w/ 2 levels \"0\",\"1\": 2 1 2 1 2 1 2 1 2 1 ... #>  $ w: num  0.707 1.034 0.223 -0.879 1.163 ..."},{"path":"https://khliland.github.io/multiblock/articles/vignette_D_asca.html","id":"formula-interface","dir":"Articles","previous_headings":"ANOVA Simultaneous Component Analysis – ASCA","what":"Formula interface","title":"D. ASCA","text":"ASCA implementation uses R’s formula interface model specification. means first argument formula response left design right, separated tilde operator, e.g. y ~ x + z assessment ~ assessor + candy. names formula refer variables data.frame (list). Separation plus (+) adds main effects model, separation stars (*) adds main effects interactions, e.g. y ~ x * z. Colons (:) can used explicit interactions, e.g. y ~ x + z + x:z. complicated formulas exist, simple subset supported asca.","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_D_asca.html","id":"asca-modelling","dir":"Articles","previous_headings":"ANOVA Simultaneous Component Analysis – ASCA","what":"ASCA modelling","title":"D. ASCA","text":"basic ASCA model two factors fitted printed follows.","code":"mod <- asca(y~x+z, data = dataset) print(mod) #> Anova Simultaneous Component Analysis fitted using 'lm' (Linear Model) #> Call: #> asca(formula = y ~ x + z, data = dataset)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_D_asca.html","id":"scores","dir":"Articles","previous_headings":"ANOVA Simultaneous Component Analysis – ASCA","what":"Scores","title":"D. ASCA","text":"Scores first factor extracted scoreplot confidence ellipsoids produced.  repeated second factor.","code":"sc <- scores(mod) head(sc) #>          Comp 1     Comp 2 #> Obj 1 0.9395791 -0.1039977 #> Obj 2 0.9395791 -0.1039977 #> Obj 3 0.9395791 -0.1039977 #> Obj 4 0.9395791 -0.1039977 #> Obj 5 0.9395791 -0.1039977 #> Obj 6 0.9395791 -0.1039977  scoreplot(mod, legendpos = \"topleft\", ellipsoids = \"confidence\") sc <- scores(mod, factor = \"z\") head(sc) #>           Comp 1 #> Obj 1 -0.3831621 #> Obj 2  0.3831621 #> Obj 3 -0.3831621 #> Obj 4  0.3831621 #> Obj 5 -0.3831621 #> Obj 6  0.3831621  scoreplot(mod, factor = \"z\", ellipsoids = \"confidence\")"},{"path":"https://khliland.github.io/multiblock/articles/vignette_D_asca.html","id":"loadings","dir":"Articles","previous_headings":"ANOVA Simultaneous Component Analysis – ASCA","what":"Loadings","title":"D. ASCA","text":"basic loadingplot first factor generated using graphics pls package.","code":"lo <- loadings(mod) head(lo) #>            Comp 1      Comp 2 #> Var 1 -0.03688007 -0.15615007 #> Var 2 -0.01764472 -0.05590506 #> Var 3  0.14250312  0.06184430 #> Var 4 -0.50220715 -0.35817451 #> Var 5 -0.54263018  0.45252899 #> Var 6  0.44399942 -0.01293480  loadingplot(mod, scatter = TRUE, labels = 'names')"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"supervised-methods","dir":"Articles","previous_headings":"","what":"Supervised methods","title":"E. Supervised multiblock analysis","text":"following supervised methods available multiblock package (function names parentheses): MB-PLS - Multiblock Partial Least Squares (mbpls) sMB-PLS - Sparse Multiblock Partial Least Squares (smbpls) -PLS - Sequential Orthogonalised PLS (sopls) PO-PLS - Parallel Orthogonalised PLS (popls) ROSA - Response Oriented Sequential Alternation (rosa) mbRDA - Multiblock Redundancy Analysis (mbrda) following sections describe format data analysis invoke methods list .","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"formatting-data-for-multiblock-analyses","dir":"Articles","previous_headings":"","what":"Formatting data for multiblock analyses","title":"E. Supervised multiblock analysis","text":"Data blocks best stored named lists use formula interface R. following example sample data one data block one response block.","code":"# Random data n <- 30; p <- 90 X <- matrix(rnorm(n*p), nrow=n) y <- X %*% rnorm(p) + 10  # Split X into three blocks in a named list ABC <- list(A = X[,1:20], B = X[,21:50], C = X[,51:90], y = y)  # Model using names of blocks (see below for full SO-PLS example) so.abc <- sopls(y ~ A + B + C, data = ABC, ncomp = c(4,3,4))"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"multiblock-partial-least-squares---mb-pls","dir":"Articles","previous_headings":"","what":"Multiblock Partial Least Squares - MB-PLS","title":"E. Supervised multiblock analysis","text":"Multiblock PLS presented briefly using potato data.","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"modelling","dir":"Articles","previous_headings":"Multiblock Partial Least Squares - MB-PLS","what":"Modelling","title":"E. Supervised multiblock analysis","text":"multi-response two-block MB-PLS model 10 components total cross-validated 10 random segments.","code":"data(potato) mb <- mbpls(X=potato[c('Chemical','Compression')], Y=potato[['Sensory']], ncomp=10,             max_comps=10, validation=\"CV\", segments=10) print(mb) #> Multiblock PLS  #>  #> Call: #> mbpls(X = potato[c(\"Chemical\", \"Compression\")], Y = potato[[\"Sensory\"]],     ncomp = 10, max_comps = 10, validation = \"CV\", segments = 10)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"summaries-and-plotting","dir":"Articles","previous_headings":"Multiblock Partial Least Squares - MB-PLS","what":"Summaries and plotting","title":"E. Supervised multiblock analysis","text":"MB-PLS implemented block-wise weighted concatenated ordinary PLSR. Therefore, methods available plsr available global part MB-PL. addition one can extrac blockScores blockLoadings.","code":"Tb1 <- scores(mb, block=1) scoreplot(mb, block = 1, labels = \"names\") Pb2 <- loadings(mb, block=2) loadingplot(mb, block = 1, labels = \"names\")"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"sparse-multiblock-partial-least-squares---smb-pls","dir":"Articles","previous_headings":"","what":"Sparse Multiblock Partial Least Squares - sMB-PLS","title":"E. Supervised multiblock analysis","text":"Sparse MB-PLS presented briefly using potato data.","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"modelling-1","dir":"Articles","previous_headings":"Sparse Multiblock Partial Least Squares - sMB-PLS","what":"Modelling","title":"E. Supervised multiblock analysis","text":"multi-response two-block sMB-PLS model 10 components total cross-validated 10 random segments. , Soft-Threshold version used (Truncation version also available) parameter shrink = 0.6 means loading weights 60% largest values subtracted setting negative values 0.","code":"data(potato) smb <- smbpls(X=potato[c('Chemical','Compression')], Y=potato[['Sensory']], ncomp = 10,             max_comps=10, shrink = 0.6, validation=\"CV\", segments=10) print(smb) #> Sparse Multiblock PLS (Soft-Threshold)  #>  #> Call: #> smbpls(X = potato[c(\"Chemical\", \"Compression\")], Y = potato[[\"Sensory\"]],     ncomp = 10, shrink = 0.6, max_comps = 10, validation = \"CV\",     segments = 10)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"plotting","dir":"Articles","previous_headings":"Sparse Multiblock Partial Least Squares - sMB-PLS","what":"Plotting","title":"E. Supervised multiblock analysis","text":"demonstrate effect shrinkage scores sparseness loading weights plotting results three values shrinkage parameter. loading weight plots can follow shrinkage toward origin variable, score plots show effect sample scores.","code":"old.par <- par(mfrow = c(3,2), mar = c(3.5,3.5,1.5,1), mgp = c(2,1,0)) for(shrink in c(0.2, 0.5, 0.8)){   smb <- smbpls(X=potato[c('Chemical','Compression')], Y=potato[['Sensory']], ncomp = 10,             max_comps=10, shrink = shrink)   scoreplot(smb, labels = \"names\", main = paste0(\"Superscores, shrink=\", shrink))   loadingweightplot(smb, labels = \"names\", main = paste0(\"Super-loading weights, shrink=\", shrink)) } par(old.par)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"sequential-and-orthogonalised-pls---so-pls","dir":"Articles","previous_headings":"","what":"Sequential and orthogonalised PLS - SO-PLS","title":"E. Supervised multiblock analysis","text":"following example uses potato data showcase functions available -PLS analyses.","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"modelling-2","dir":"Articles","previous_headings":"Sequential and orthogonalised PLS - SO-PLS","what":"Modelling","title":"E. Supervised multiblock analysis","text":"multi-response two-block -PLS model 10 components total cross-validated 10 random segments.","code":"# Load potato data and fit SO-PLS model so.pot <- sopls(Sensory ~ Chemical + Compression, data=potato,              ncomp=c(10,10), max_comps=10, validation=\"CV\", segments=10) print(so.pot) #> Sequential and Orthogonalized Partial Least Squares, fitted with the PKPLS algorithm. #> Cross-validated using 10 random segments. #> Call: #> sopls(formula = Sensory ~ Chemical + Compression, ncomp = c(10,     10), max_comps = 10, data = potato, validation = \"CV\", segments = 10) summary(so.pot) #> Data:    X dimension: 26 0  #>  Y dimension: 26 9 #> Fit method: PKPLS #> Number of components considered: 10 #>  #> VALIDATION: RMSEP #> Cross-validated using 10 random segments. #>    0,0     0,1     0,2     0,3     0,4     0,5     0,6     0,7     0,8     0,9   #> 1.1158  0.9873  0.9928  0.9950  1.0357  1.2615  1.1828  1.2614  1.2782  1.2562   #>   0,10     1,0     1,1     1,2     1,3     1,4     1,5     1,6     1,7     1,8   #> 1.2398  0.8544  0.8194  0.8627  0.8087  0.8705  0.9283  0.9292  1.0142  1.0404   #>    1,9     2,0     2,1     2,2     2,3     2,4     2,5     2,6     2,7     2,8   #> 1.0814  0.7251  0.6321  0.6218  0.6717  0.6814  0.7237  0.7493  0.8037  0.8713   #>    3,0     3,1     3,2     3,3     3,4     3,5     3,6     3,7     4,0     4,1   #> 0.6773  0.6544  0.6424  0.7171  0.7314  0.7555  0.8011  0.8634  0.6764  0.6475   #>    4,2     4,3     4,4     4,5     4,6     5,0     5,1     5,2     5,3     5,4   #> 0.6430  0.6922  0.7042  0.7299  0.7479  0.6888  0.6866  0.6806  0.7391  0.7475   #>    5,5     6,0     6,1     6,2     6,3     6,4     7,0     7,1     7,2     7,3   #> 0.8826  0.7014  0.7131  0.6972  0.7783  0.7960  0.7124  0.7253  0.7091  0.8079   #>    8,0     8,1     8,2     9,0     9,1    10,0   #> 0.7604  0.7683  0.7434  0.7426  0.7576  1.3878   #>  #> TRAINING: % variance explained #>         0,0    0,1    0,2    0,3    0,4    0,5    0,6    0,7    0,8    0,9 #> X         0  45.87  55.51  62.90  66.46  67.73  74.95  78.26  79.85  82.39 #> ref       0  42.19  54.73  65.01  66.85  73.96  74.10  74.44  77.45  77.57 #> hard      0  39.11  41.97  42.23  43.80  50.95  54.87  56.78  59.50  74.53 #> firm      0  42.55  57.44  59.44  61.06  66.78  68.62  69.02  71.34  76.53 #> elas      0  38.64  65.31  73.51  75.63  77.23  79.25  81.19  83.71  86.57 #> adhes     0  16.13  18.11  26.71  26.74  29.70  42.07  44.57  46.47  46.54 #> grainy    0  23.21  43.78  62.23  64.02  67.18  67.72  69.83  74.79  74.79 #> mealy     0  35.35  41.99  57.36  58.84  67.17  70.33  73.21  77.77  78.88 #> moist     0  24.48  27.71  43.10  44.27  48.41  53.39  62.37  67.60  74.79 #> chewi     0  21.98  22.78  48.17  55.50  59.96  68.39  72.54  76.39  77.42 #>          0,10    1,0    1,1    1,2    1,3    1,4    1,5    1,6    1,7    1,8 #> X       83.18  34.20  64.12  71.71  76.24  78.20  79.49  83.37  84.42  85.59 #> ref     77.57  55.79  64.00  64.25  73.75  77.39  79.53  80.42  80.50  80.96 #> hard    75.43  24.10  41.42  44.05  44.07  44.09  47.61  53.70  53.86  62.46 #> firm    79.31  42.73  54.16  58.42  62.05  63.55  64.91  70.85  70.91  70.93 #> elas    88.14  53.24  59.32  63.95  71.43  74.51  75.33  77.16  78.86  78.88 #> adhes   54.68  17.49  22.70  33.54  33.75  34.70  34.90  39.43  48.51  48.92 #> grainy  74.82  57.69  58.26  58.39  71.89  75.95  76.07  76.72  77.73  79.00 #> mealy   79.25  61.37  65.64  66.70  74.33  75.36  77.44  78.35  79.55  80.15 #> moist   77.22  57.32  58.51  62.12  66.20  66.35  67.13  67.14  69.51  71.02 #> chewi   81.68  53.27  54.25  64.22  66.35  69.59  69.96  72.80  77.64  77.64 #>           1,9    2,0    2,1    2,2    2,3    2,4    2,5    2,6    2,7    2,8 #> X       86.07  42.76  72.61  79.40  81.41  82.69  84.98  88.16  88.87  89.84 #> ref     81.20  76.03  85.17  87.21  89.03  90.67  90.68  91.36  91.36  91.39 #> hard    69.98  25.29  44.10  46.63  46.63  46.88  52.03  61.89  64.48  73.84 #> firm    80.21  55.93  69.19  76.45  76.45  76.80  77.79  82.58  82.64  86.03 #> elas    87.63  63.10  70.21  78.03  78.08  78.17  80.37  82.19  84.54  85.69 #> adhes   49.97  34.43  39.48  46.70  46.78  48.48  54.50  56.16  67.45  72.74 #> grainy  79.50  83.95  84.78  87.19  88.01  88.56  89.28  89.29  89.30  89.49 #> mealy   80.19  81.14  85.67  85.68  87.94  88.28  88.57  89.15  89.69  90.49 #> moist   72.44  67.94  69.06  70.49  72.51  72.53  72.61  72.80  73.61  78.69 #> chewi   78.05  70.55  71.41  77.11  77.11  78.09  78.17  79.79  83.27  86.51 #>           3,0    3,1    3,2    3,3    3,4    3,5    3,6    3,7    4,0    4,1 #> X       63.76  78.59  84.55  86.77  87.73  90.09  91.81  92.46  70.09  80.35 #> ref     84.50  86.31  87.91  89.34  91.72  91.74  93.12  93.13  84.91  87.28 #> hard    29.51  45.43  50.00  50.23  51.56  54.69  61.12  63.12  30.80  49.39 #> firm    62.42  68.64  76.93  76.96  77.84  78.25  82.67  82.72  62.64  73.46 #> elas    69.44  70.75  78.04  78.06  78.07  80.60  82.75  85.36  69.94  73.16 #> adhes   34.51  46.88  50.83  51.04  51.60  57.45  58.26  69.10  64.76  65.66 #> grainy  87.18  87.45  88.87  89.86  90.34  91.06  91.37  91.45  87.20  87.21 #> mealy   84.89  86.14  86.18  88.32  89.25  89.48  91.02  91.95  88.83  88.96 #> moist   70.03  70.05  72.13  74.57  74.71  74.88  74.97  76.40  75.09  76.33 #> chewi   70.56  72.61  77.34  77.39  78.58  78.58  79.89  83.77  82.06  82.29 #>           4,2    4,3    4,4    4,5    4,6    5,0    5,1    5,2    5,3    5,4 #> X       87.12  88.89  89.78  92.03  93.37  75.21  84.27  91.16  92.52  93.47 #> ref     88.13  89.65  92.48  92.54  93.63  85.03  88.23  89.16  90.27  92.85 #> hard    49.95  50.65  50.76  54.96  60.99  41.38  53.88  54.08  54.33  54.70 #> firm    77.00  77.10  77.44  78.23  83.34  68.24  75.97  78.78  78.78  79.40 #> elas    78.98  79.09  79.43  82.78  83.85  72.35  74.56  79.87  80.48  80.91 #> adhes   67.28  68.26  69.21  70.41  70.90  64.77  65.81  67.35  67.83  69.01 #> grainy  89.07  90.46  91.63  92.15  92.30  87.53  87.56  89.67  90.98  91.93 #> mealy   88.99  93.13  94.52  94.64  95.00  89.21  89.65  89.73  93.45  94.51 #> moist   76.60  82.33  82.90  82.90  83.28  79.72  79.91  79.98  83.86  84.08 #> chewi   84.08  84.45  86.24  86.38  86.39  82.11  82.31  83.97  84.76  86.45 #>           5,5    6,0    6,1    6,2    6,3    6,4    7,0    7,1    7,2    7,3 #> X       95.40  77.28  86.22  93.18  94.55  95.63  79.57  88.43  95.46  96.65 #> ref     92.91  86.80  90.43  91.47  92.26  94.07  88.07  91.60  92.62  92.70 #> hard    60.53  45.27  56.94  57.05  57.64  59.71  45.28  56.91  56.99  57.22 #> firm    80.75  68.98  76.56  79.17  79.42  80.55  69.02  76.72  79.16  79.35 #> elas    83.34  72.55  74.96  80.08  80.15  80.26  73.76  76.39  81.36  81.61 #> adhes   70.53  64.77  65.79  67.29  69.17  69.37  65.04  65.96  67.53  68.89 #> grainy  92.38  91.29  91.41  93.80  94.06  94.27  91.78  91.89  94.29  94.34 #> mealy   94.83  90.67  91.24  91.36  94.83  95.44  92.38  92.87  92.98  94.77 #> moist   84.08  82.80  82.90  82.93  85.65  85.67  85.12  85.26  85.29  86.55 #> chewi   86.50  84.60  84.72  86.16  86.49  87.50  86.05  86.22  87.61  87.62 #>           8,0    8,1    8,2    9,0    9,1   10,0 #> X       82.82  88.16  95.96  85.49  90.21  87.08 #> ref     90.82  94.67  94.93  91.52  94.42  91.79 #> hard    52.73  59.90  60.33  52.75  63.37  52.92 #> firm    71.26  80.42  80.49  71.81  80.88  71.82 #> elas    73.78  80.71  81.41  75.22  80.15  76.14 #> adhes   68.88  68.89  69.28  71.74  72.73  74.17 #> grainy  91.80  93.21  94.39  91.99  92.91  92.43 #> mealy   93.59  94.05  94.31  93.75  93.98  93.83 #> moist   86.40  86.60  87.34  87.11  88.40  87.14 #> chewi   87.11  88.40  88.43  87.27  89.53  87.28"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"måge-plot","dir":"Articles","previous_headings":"Sequential and orthogonalised PLS - SO-PLS","what":"Måge plot","title":"E. Supervised multiblock analysis","text":"full Måge plot combinations components blocks produced. can used global search best fitting cross-validated model. point figure accompanied sequence four numbers referring number components used four blocks. Horizontal location given total number components used across blocks, vertical location indicates validated explained variance percentage.  sequential Måge plot can used sequential search optimal model.","code":"# Load Wine data and model with SO-PLS data(wine) ncomp <- unlist(lapply(wine, ncol))[-5] so.wine <- sopls(`Global quality` ~ ., data=wine, ncomp=ncomp,               max_comps=6, validation=\"CV\", segments=10) maage(so.wine) # Sequential search for optimal number of components per block old.par <- par(mfrow=c(2,2), mar=c(3,3,0.5,1), mgp=c(2,0.7,0)) maageSeq(so.wine) maageSeq(so.wine, 2) maageSeq(so.wine, c(2,1)) maageSeq(so.wine, c(2,1,1)) par(old.par)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"loadings","dir":"Articles","previous_headings":"Sequential and orthogonalised PLS - SO-PLS","what":"Loadings","title":"E. Supervised multiblock analysis","text":"One set loadings printed two sets plotted show select specific components specific blocks. extracting plotting loadings second later blocks, one must specify many components used previous block(s) (ncomp) affect choice loadings. addition one can specify components current block extracted (comps).","code":"# Display loadings for first block loadings(so.pot, block = 1) #>  #> Loadings: #>      1,0    2,0    3,0    4,0    5,0    6,0    7,0    8,0    9,0    10,0   #> PEU   0.645 -3.672  1.197  2.277 -0.589 -1.684  1.028  0.431  0.118 -0.132 #> Sta. -4.542 -0.975 -0.984 -0.678 -0.559 -0.926 -0.418 -0.583  0.508  0.220 #> TotN  0.478 -1.848  3.046 -1.613  1.604 -1.088  1.441  0.355 -1.874        #> Phy. -3.970        -1.445  0.948  1.148 -0.286  1.519 -0.669  0.233 -1.415 #> Ca   -1.365 -0.982  1.804 -1.190 -3.763  1.249  0.107  0.281 -0.401 -1.229 #> Mg   -4.009 -0.280        -2.344  0.996 -0.320  1.152  0.172  0.801  0.481 #> Na   -3.066 -2.488  0.669  1.616 -1.119  1.520 -0.570 -0.430 -0.452  1.440 #> K    -0.186 -0.255 -4.161  0.149  0.700  1.225 -1.469  1.284 -1.263 -0.411 #> Hi.1 -4.493  2.113         0.344 -0.226        -0.126  0.108 -0.154  0.162 #> Hi.2 -4.099  2.656 -0.739  0.488 -0.311 -0.225  0.135  0.120 -0.254  0.146 #> Hi.3 -4.382  2.270 -0.259  0.398 -0.272 -0.271  0.105  0.337 -0.369        #> Hi.4  3.000  0.732 -2.855        -1.994 -0.483  1.552 -0.173 -0.200  0.528 #> Hi.5 -4.419  2.023 -0.177  0.372 -0.362 -0.359  0.192  0.494 -0.668        #> Hi.6  1.580  2.266 -3.570  0.571 -1.131 -0.664  1.351 -0.390 -0.371  0.279 #>  #>                    1,0    2,0    3,0    4,0    5,0    6,0    7,0    8,0    9,0 #> SS loadings    151.624 51.586 56.326 19.671 27.054 11.370 13.749  3.605  7.288 #> Proportion Var  10.830  3.685  4.023  1.405  1.932  0.812  0.982  0.257  0.521 #> Cumulative Var  10.830 14.515 18.538 19.943 21.876 22.688 23.670 23.927 24.448 #>                  10,0 #> SS loadings     6.470 #> Proportion Var  0.462 #> Cumulative Var 24.910 # Plot loadings from block 1 and 2 old.par <- par(mfrow=c(1,2)) loadingplot(so.pot, comps = c(2,3), block = 1, main = \"Block 1\", labels = \"names\", cex = 0.8) loadingplot(so.pot, ncomp = 4, block = 2, main = \"Block 2\", labels = \"names\", cex = 0.8) par(old.par)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"scores","dir":"Articles","previous_headings":"Sequential and orthogonalised PLS - SO-PLS","what":"Scores","title":"E. Supervised multiblock analysis","text":"One set scores printed two sets plotted show select specific components specific blocks. Specification component use preceding blocks follows pattern loadings.","code":"# Display scores for first block scores(so.pot, block = 1) #>             1,0         2,0          3,0         4,0         5,0          6,0 #> 1  -0.078379126 -0.15756558 -0.030150796 -0.08882899 -0.01376296 -0.056671801 #> 2   0.033599245  0.03345139 -0.264837392 -0.02082345 -0.11717078 -0.151392736 #> 3  -0.454087240 -0.50387774 -0.257625630  0.24822188 -0.02903093 -0.086528935 #> 4  -0.010144029  0.04409907  0.254739277  0.34206013  0.02495265  0.074552441 #> 5  -0.231320589  0.02813994  0.331647163 -0.15209020 -0.75827354  0.341572360 #> 6  -0.100806072 -0.03203490  0.058511494 -0.07824489 -0.03272086  0.022355259 #> 7   0.103759602  0.05587580  0.171495995  0.13245956 -0.01979756 -0.159062060 #> 8   0.142341829 -0.02952316  0.135315864  0.17766566 -0.04381490 -0.186272842 #> 9   0.160175421 -0.13395363  0.067732083 -0.34567441  0.17107748  0.172779015 #> 10  0.078862890 -0.20282246  0.065251294 -0.21205811  0.20044571  0.328237338 #> 11  0.200245777 -0.02882659  0.149667777 -0.08872396 -0.08768916 -0.174332305 #> 12  0.223602068 -0.07321286 -0.029748834 -0.22950703 -0.03709102 -0.193124707 #> 13  0.217320106 -0.26815383  0.096949900 -0.10070260  0.05733144 -0.253089620 #> 14  0.142847549 -0.29951537  0.077252287  0.24996525 -0.11362892 -0.187257376 #> 15  0.213820293  0.17228886 -0.461863019 -0.11767172 -0.27195381 -0.069378444 #> 16  0.164964325  0.26005269 -0.323577542  0.10235857 -0.18083698  0.028860577 #> 17  0.002967383  0.19480792 -0.246885356  0.19701818  0.05083294  0.193040181 #> 18  0.066258347  0.09356886 -0.228532411  0.20484080  0.06435515  0.193713440 #> 19  0.194213760 -0.01568159  0.132000297  0.14447620  0.07380230  0.134307084 #> 20  0.141301554 -0.07654188  0.049224760  0.26084474  0.16978368  0.406994445 #> 21 -0.129888279  0.04471652  0.038982799 -0.30565064  0.07729299 -0.272193959 #> 22 -0.105636544  0.24576605 -0.030041538 -0.14535670  0.24832087  0.010288729 #> 23 -0.464479945 -0.11433433 -0.194275154 -0.06714686  0.13063332 -0.005785022 #> 24 -0.082441922  0.22751259  0.233417343  0.13675311  0.22568931 -0.091378804 #> 25 -0.325181587  0.44765983  0.208213841  0.07217114  0.05115869 -0.267361478 #> 26 -0.103914818  0.08810440 -0.002864502 -0.31635566  0.16009487  0.247129222 #>             7,0          8,0         9,0         10,0 #> 1  -0.170176673 -0.353657625  0.09144069 -0.188197767 #> 2   0.376363608 -0.223166913 -0.06432803  0.102154561 #> 3   0.053642203  0.053088656  0.11136825  0.089274658 #> 4   0.080021975 -0.455836399  0.29151166  0.160435908 #> 5   0.060316124  0.088814534 -0.01259842 -0.241887363 #> 6  -0.143868448  0.209487156  0.44247087  0.460290223 #> 7  -0.067499572  0.172789197 -0.01007070  0.014280187 #> 8   0.003023123  0.020901351 -0.15855793  0.115799243 #> 9   0.099124600  0.077168263 -0.22926057  0.020019625 #> 10 -0.006546077  0.001048562 -0.15821313  0.090958585 #> 11 -0.321845257 -0.388050068 -0.15769574  0.033224651 #> 12 -0.114302438 -0.157344716  0.01456158 -0.118230072 #> 13  0.159102296  0.426179096  0.31221443 -0.244022144 #> 14  0.164565349  0.160117465 -0.31148972  0.004138940 #> 15  0.160269738 -0.034424824  0.04760954  0.177518448 #> 16  0.073035199  0.028396505  0.02512587  0.008674474 #> 17 -0.336494502  0.228154141 -0.02760929 -0.191196309 #> 18 -0.353315626  0.070825686  0.13990043 -0.255631862 #> 19 -0.192020302  0.118534017 -0.05488875  0.206887988 #> 20  0.167499146 -0.065961803 -0.17176149 -0.018385084 #> 21 -0.291917226 -0.005778312  0.06774798 -0.093267865 #> 22  0.315505112  0.055322691 -0.04212437 -0.272120565 #> 23 -0.070388026 -0.103937894 -0.28625584 -0.102958571 #> 24  0.271169417 -0.112282869  0.28534458 -0.337006550 #> 25 -0.033293058  0.199555988 -0.33284978  0.259557484 #> 26  0.118029313 -0.009941885  0.18840789  0.319689179 #> attr(,\"explvar\") #>       1,0       2,0       3,0       4,0       5,0       6,0       7,0       8,0  #> 34.201725  8.556741 20.999993  6.330308  5.124745  2.071311  2.284023  3.250427  #>       9,0      10,0  #>  2.674759  1.582372  #> attr(,\"class\") #> [1] \"scores.multiblock\" \"scores\" # Plot scores from block 1 and 2 old.par <- par(mfrow=c(1,2)) scoreplot(so.pot, comps = c(2,3), block = 1, main = \"Block 1\", labels = \"names\") scoreplot(so.pot, ncomp = 4, block = 2, main = \"Block 2\", labels = \"names\") par(old.par)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"prediction","dir":"Articles","previous_headings":"Sequential and orthogonalised PLS - SO-PLS","what":"Prediction","title":"E. Supervised multiblock analysis","text":"three block model fitted using single response, 5 components subset data. remaining data used test set prediction.","code":"# Modify data to contain a single response potato1 <- potato; potato1$Sensory <- potato1$Sensory[,1] # Model 20 first objects with SO-PLS so.pot20 <- sopls(Sensory ~ ., data = potato1[c(1:3,9)], ncomp = 5, subset = 1:20) # Predict remaining objects testset <- potato1[-(1:20),]; # testset$Sensory <- NULL predict(so.pot20, testset, comps=c(2,1,2)) #> , , 1,0,0 #>  #>       Sensory #> [1,] 3.710097 #> [2,] 3.508955 #> [3,] 6.066989 #> [4,] 3.521423 #> [5,] 4.944123 #> [6,] 3.539052 #>  #> , , 2,0,0 #>  #>       Sensory #> [1,] 3.636431 #> [2,] 3.610855 #> [3,] 6.429357 #> [4,] 3.393957 #> [5,] 4.062585 #> [6,] 3.449857 #>  #> , , 3,0,0 #>  #>       Sensory #> [1,] 3.688660 #> [2,] 3.685508 #> [3,] 6.480693 #> [4,] 3.211579 #> [5,] 3.956964 #> [6,] 3.464106 #>  #> , , 4,0,0 #>  #>       Sensory #> [1,] 3.746689 #> [2,] 3.545318 #> [3,] 6.342659 #> [4,] 2.980819 #> [5,] 3.631846 #> [6,] 3.419858 #>  #> , , 5,0,0 #>  #>       Sensory #> [1,] 3.741608 #> [2,] 3.034433 #> [3,] 6.123613 #> [4,] 2.363783 #> [5,] 2.979181 #> [6,] 3.078927 #>  #> , , 5,1,0 #>  #>       Sensory #> [1,] 3.636086 #> [2,] 2.582345 #> [3,] 6.196188 #> [4,] 1.914878 #> [5,] 2.804766 #> [6,] 3.092452 #>  #> , , 5,2,0 #>  #>       Sensory #> [1,] 3.847071 #> [2,] 3.105369 #> [3,] 6.731938 #> [4,] 1.914845 #> [5,] 2.913156 #> [6,] 3.201600 #>  #> , , 5,3,0 #>  #>       Sensory #> [1,] 4.339639 #> [2,] 3.956609 #> [3,] 8.709663 #> [4,] 2.405164 #> [5,] 3.544869 #> [6,] 3.771154 #>  #> , , 5,4,0 #>  #>       Sensory #> [1,] 4.791787 #> [2,] 4.211071 #> [3,] 8.738256 #> [4,] 2.547092 #> [5,] 3.635783 #> [6,] 3.771432 #>  #> , , 5,5,0 #>  #>       Sensory #> [1,] 4.896776 #> [2,] 4.273363 #> [3,] 9.041290 #> [4,] 2.462006 #> [5,] 3.738154 #> [6,] 3.987452 #>  #> , , 5,5,1 #>  #>       Sensory #> [1,] 5.127082 #> [2,] 4.593908 #> [3,] 9.859248 #> [4,] 2.409637 #> [5,] 4.392888 #> [6,] 4.321865 #>  #> , , 5,5,2 #>  #>       Sensory #> [1,] 4.893680 #> [2,] 4.293595 #> [3,] 8.950756 #> [4,] 2.643839 #> [5,] 4.549016 #> [6,] 3.825176 #>  #> , , 5,5,3 #>  #>       Sensory #> [1,] 4.809765 #> [2,] 3.407967 #> [3,] 8.351415 #> [4,] 1.533916 #> [5,] 3.098735 #> [6,] 2.980523 #>  #> , , 5,5,4 #>  #>        Sensory #> [1,]  5.206516 #> [2,]  3.827037 #> [3,] 10.217326 #> [4,]  1.880369 #> [5,]  5.232344 #> [6,]  4.708891 #>  #> , , 5,5,5 #>  #>        Sensory #> [1,]  4.910730 #> [2,]  3.410653 #> [3,] 11.063789 #> [4,]  1.817420 #> [5,]  6.038563 #> [6,]  6.823995"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"validation","dir":"Articles","previous_headings":"Sequential and orthogonalised PLS - SO-PLS","what":"Validation","title":"E. Supervised multiblock analysis","text":"Compute validation statistics; explained variance - R2^2, Root Mean Squared Error - RMSE(P/CV).","code":"# Cross-validation R2(so.pot, ncomp = c(5,5)) #>       1,0       2,0       3,0       4,0       5,0       5,1       5,2       5,3  #> 0.3725766 0.5481465 0.6057872 0.6068032 0.5922717 0.5948811 0.6019672 0.5305786  #>       5,4       5,5  #> 0.5197773 0.3305448 R2(so.pot, ncomp = c(5,5), individual = TRUE) #>               1,0         2,0         3,0        4,0        5,0        5,1 #> ref    0.36214407  0.56469277  0.68930955  0.6980272  0.6732567  0.7030829 #> hard   0.01554864 -0.06554243 -0.02356978 -0.2066266 -0.3179983 -0.1581612 #> firm   0.17665535  0.26163730  0.38041565  0.2897483  0.3544505  0.4301413 #> elas   0.39850777  0.48863848  0.54675908  0.5277118  0.5160369  0.5020343 #> adhes  0.07664970  0.18245255  0.09638291  0.2584602  0.3250433  0.3029435 #> grainy 0.38583269  0.70597919  0.76691993  0.7667584  0.7786072  0.7315524 #> mealy  0.47737188  0.70616954  0.75003068  0.7922686  0.7768048  0.7559721 #> moist  0.49447042  0.60410772  0.59662575  0.5536880  0.5432058  0.4865251 #> chewi  0.46983344  0.61391521  0.55336390  0.6374355  0.5546693  0.5298323 #>               5,2         5,3         5,4        5,5 #> ref     0.7410001  0.69827926  0.74704423  0.7648513 #> hard   -0.1980853 -0.36660169 -0.73821865 -1.3368093 #> firm    0.4757700  0.40266089  0.25687178 -0.1025061 #> elas    0.5624613  0.57145052  0.54102462  0.3000614 #> adhes   0.2322958  0.07395787  0.08853579 -1.1018881 #> grainy  0.7676007  0.76075064  0.74369076  0.7864572 #> mealy   0.7471824  0.68717433  0.73071507  0.6895273 #> moist   0.4318475  0.26213711  0.26483590 -0.1588749 #> chewi   0.5093917  0.39328706  0.36162629 -0.1487673 # Training R2(so.pot, 'train', ncomp = c(5,5)) #>       1,0       2,0       3,0       4,0       5,0       5,1       5,2       5,3  #> 0.5321195 0.7063309 0.7545212 0.7890377 0.8065415 0.8303087 0.8419431 0.8603538  #>       5,4       5,5  #> 0.8735251 0.8807225  # Test data R2(so.pot20, newdata = testset, ncomp = c(2,1,2)) #>      1,0,0      2,0,0      2,1,0      2,1,1      2,1,2  #>  0.5217279  0.7330829  0.7208834  0.4494703 -0.2607736 # Cross-validation RMSEP(so.pot, ncomp = c(5,5)) #>       1,0       2,0       3,0       4,0       5,0       5,1       5,2       5,3  #> 0.8544463 0.7251089 0.6772824 0.6764090 0.6887948 0.6865871 0.6805560 0.7390705  #>       5,4       5,5  #> 0.7475251 0.8826025 RMSEP(so.pot, ncomp = c(5,5), individual = TRUE) #>              1,0       2,0       3,0       4,0       5,0       5,1       5,2 #> ref    1.3651285 1.1277431 0.9527439 0.9392823 0.9770473 0.9313863 0.8698854 #> hard   0.7295578 0.7590108 0.7439116 0.8076981 0.8441508 0.7913108 0.8048343 #> firm   0.7862604 0.7445784 0.6820650 0.7302671 0.6962101 0.6541226 0.6273884 #> elas   0.5670081 0.5228032 0.4921968 0.5024326 0.5086046 0.5159100 0.4835957 #> adhes  0.5876289 0.5529380 0.5813158 0.5266077 0.5024096 0.5105684 0.5358175 #> grainy 0.8539775 0.5908703 0.5260847 0.5262669 0.5127254 0.5645896 0.5253158 #> mealy  1.1098846 0.8322041 0.7675820 0.6997333 0.7253103 0.7584051 0.7719428 #> moist  0.7712617 0.6825226 0.6889419 0.7246825 0.7331432 0.7772990 0.8176378 #> chewi  0.5778388 0.4931078 0.5303682 0.4778517 0.5295925 0.5441604 0.5558633 #>              5,3       5,4       5,5 #> ref    0.9388902 0.8596755 0.8288645 #> hard   0.8595746 0.9694263 1.1240205 #> firm   0.6697088 0.7469773 0.9098421 #> elas   0.4786022 0.4953007 0.6116517 #> adhes  0.5884849 0.5838345 0.8865939 #> grainy 0.5330016 0.5516774 0.5035534 #> mealy  0.8586826 0.7966865 0.8554471 #> moist  0.9317863 0.9300807 1.1677417 #> chewi  0.6181476 0.6340712 0.8505827 # Training RMSEP(so.pot, 'train', ncomp = c(5,5)) #>       1,0       2,0       3,0       4,0       5,0       5,1       5,2       5,3  #> 0.7378564 0.5845659 0.5344553 0.4954580 0.4744585 0.4443592 0.4288556 0.4031058  #>       5,4       5,5  #> 0.3836247 0.3725492  # Test data RMSEP(so.pot20, newdata = testset, ncomp = c(2,1,2)) #>    1,0,0    2,0,0    2,1,0    2,1,1    2,1,2  #> 1.562727 1.167438 1.193819 1.676625 2.537255"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"principal-components-of-predictions","dir":"Articles","previous_headings":"Sequential and orthogonalised PLS - SO-PLS","what":"Principal Components of Predictions","title":"E. Supervised multiblock analysis","text":"PCA computed cross-validated predictions get overview -PLS model across involved blocks. blocks projected onto scores form block-loadings see relate solution.","code":"# PCP from so.pot object PCP <- pcp(so.pot, c(3,2)) summary(PCP) #> Principal Components of Predictions  #> ===================================  #>  #> $scores: Scores (26x9) #> $loadings: Loadings (9x9) #> $blockLoadings: Block loadings: #> - Chemical (14x9), Compression (12x9) scoreplot(PCP) corrplot(PCP)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"cvanova","dir":"Articles","previous_headings":"Sequential and orthogonalised PLS - SO-PLS","what":"CVANOVA","title":"E. Supervised multiblock analysis","text":"CVANOVA model compares absolute squared cross-validated residuals two prediction models using ANOVA Model Object effects. Tukey’s pair-wise testing automatically computed implementation.","code":"# CVANOVA so.pot1 <- sopls(Sensory[,1] ~ Chemical + Compression + NIRraw, data=potato,              ncomp=c(10,10,10), max_comps=10, validation=\"CV\", segments=10) cva <- cvanova(so.pot1, \"2,1,2\") summary(cva) #> Analysis of Variance Table #>  #> Response: Residual #>           Df  Sum Sq Mean Sq F value   Pr(>F)     #> Model      2  0.5585 0.27925  3.7044  0.03161 *   #> Object    25 16.5196 0.66079  8.7657 5.89e-11 *** #> Residuals 50  3.7691 0.07538                      #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> Tukey's HSD #> Alpha: 0.05 #>  #>            Mean G1 G2 #> 2,0,0 0.8929078     B #> 2,1,0 0.7742818  A  B #> 2,1,2 0.6863993  A old.par <- par(mar = c(4,6,4,2)) plot(cva) par(old.par)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"parallel-and-orthgonalised-partial-least-squares---po-pls","dir":"Articles","previous_headings":"","what":"Parallel and Orthgonalised Partial Least Squares - PO-PLS","title":"E. Supervised multiblock analysis","text":"PO-PLS presented briefly using potato data. method separating predictive information common, local distinct parts.","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"modelling-3","dir":"Articles","previous_headings":"Parallel and Orthgonalised Partial Least Squares - PO-PLS","what":"Modelling","title":"E. Supervised multiblock analysis","text":"many choices regard numbers components possible local common components. Using automatic selection, user selects highest number blocks combine local/common components, minimum explained variance minimum squared correlation response. Manual selection can done setting number initial components blocks maximum number local/common components.","code":"# Automatic analysis pot.po.auto <- popls(potato[1:3], potato[['Sensory']][,1], commons = 2) #> Warning in gca.svd(X = X, tol = tol, ncomp = ncomp): 'ncomp' reduced due to low #> singular value for block 1 #> Warning in gca.svd(X = X, tol = tol, ncomp = ncomp): 'ncomp' reduced due to low #> singular value for block 1  # Explained variance pot.po.auto$explVar #> $Chemical #> named numeric(0) #>  #> $Compression #> C(1,2), Comp 1  #>       68.14595  #>  #> $NIRraw #> D(3), Comp 1  #>     42.53836 # Manual choice of up to 5 components for each block and 1, 0, and 2 blocks, # respectively from the (1,2), (1,3) and (2,3) combinations of blocks. pot.po.man <- popls(potato[1:3], potato[['Sensory']][,1], commons = 2,                     auto=FALSE, manual.par = list(ncomp=c(5,5,5),                                                   ncommon=c(1,0,2))) #> Warning in gca.svd(X = X, tol = tol, ncomp = ncomp): 'ncomp' reduced due to low #> singular value for block 1 #> Warning in gca.svd(X = X, tol = tol, ncomp = ncomp): 'ncomp' reduced due to low #> singular value for block 1 # Explained variance pot.po.man$explVar #> $Chemical #> C(1,2), Comp 1   D(1), Comp 1   D(1), Comp 2  #>       32.22944       20.74357       20.87956  #>  #> $Compression #> C(1,2), Comp 1 C(2,3), Comp 1 C(2,3), Comp 2  #>      68.145954       5.504006       7.214911  #>  #> $NIRraw #> C(2,3), Comp 1 C(2,3), Comp 2  #>      32.606459       5.475702"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"scores-and-loadings","dir":"Articles","previous_headings":"Parallel and Orthgonalised Partial Least Squares - PO-PLS","what":"Scores and loadings","title":"E. Supervised multiblock analysis","text":"Scores loadings stored per block. Common scores/loadings found blocks’ list components.","code":"# Score plot for local (2,3) components scoreplot(pot.po.man, block = 3, labels = \"names\") # Corresponding loadings loadingplot(pot.po.man, block = 3, labels=\"names\", scatter = FALSE)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"response-oriented-sequential-alternation---rosa","dir":"Articles","previous_headings":"","what":"Response Oriented Sequential Alternation - ROSA","title":"E. Supervised multiblock analysis","text":"following example uses potato data showcase functions available ROSA analyses.","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"modelling-4","dir":"Articles","previous_headings":"Response Oriented Sequential Alternation - ROSA","what":"Modelling","title":"E. Supervised multiblock analysis","text":"multi-response two-block ROSA model 10 components total cross-validated 10 random segments.","code":"# Model all eight potato blocks with ROSA ros.pot <- rosa(Sensory ~ ., data = potato1, ncomp = 10, validation = \"CV\", segments = 5) print(ros.pot) #> Response Orinented Sequential Alternation , fitted with the CPPLS algorithm. #> Cross-validated using 5 random segments. #> Call: #> rosa(formula = Sensory ~ ., ncomp = 10, data = potato1, validation = \"CV\",     segments = 5) summary(ros.pot) #> Data:    X dimension: 26 3946  #>  Y dimension: 26 1 #> Fit method: #> Number of components considered: 10 #>  #> VALIDATION: RMSEP #> Cross-validated using 5 random segments. #>        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps #> CV           1.778    1.381    1.239   0.9998   0.8072   0.7546   0.5884 #> adjCV        1.778    1.284    1.136   0.9019   0.7151   0.6722   0.5356 #>        7 comps  8 comps  9 comps  10 comps #> CV      0.5397   0.5464   0.6237    0.7192 #> adjCV   0.4959   0.5021   0.5652    0.6547 #>  #> TRAINING: % variance explained #>          1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps #> X          27.82    40.72    47.95    49.48    53.96    55.28    57.79    65.49 #> Sensory    76.54    86.77    94.07    96.47    97.03    97.49    97.83    98.03 #>          9 comps  10 comps #> X          67.14     68.16 #> Sensory    98.28     98.51"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"loadings-1","dir":"Articles","previous_headings":"Response Oriented Sequential Alternation - ROSA","what":"Loadings","title":"E. Supervised multiblock analysis","text":"Extract loadings (used ) plot two first vectors loadings.","code":"loads <- loadings(ros.pot) loadingplot(ros.pot, comps = 1:2, scatter = FALSE)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"scores-1","dir":"Articles","previous_headings":"Response Oriented Sequential Alternation - ROSA","what":"Scores","title":"E. Supervised multiblock analysis","text":"Extract scores (used ) plot two first vectors scores.","code":"sco <- scores(ros.pot) scoreplot(ros.pot, comps = 1:2, labels = \"names\")"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"prediction-1","dir":"Articles","previous_headings":"Response Oriented Sequential Alternation - ROSA","what":"Prediction","title":"E. Supervised multiblock analysis","text":"three block model fitted using single response, 5 components subset data. remaining data used test set prediction.","code":"# Model 20 first objects of three potato blocks rosT <- rosa(Sensory ~ ., data = potato1[c(1:3,9)], ncomp = 5, subset = 1:20) testset <- potato1[-(1:20),]; # testset$Sensory <- NULL predict(rosT, testset, comps=2) #>     Sensory #> 21 3.845579 #> 22 3.101318 #> 23 3.928266 #> 24 2.771968 #> 25 2.538627 #> 26 2.876964"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"validation-1","dir":"Articles","previous_headings":"Response Oriented Sequential Alternation - ROSA","what":"Validation","title":"E. Supervised multiblock analysis","text":"Compute validation statistics; explained variance - R2^2 Root Mean Squared Error - RMSE(P/CV).","code":"# Cross-validation R2(ros.pot) #> (Intercept)      1 comps      2 comps      3 comps      4 comps      5 comps   #>     -0.0816       0.3474       0.4748       0.6578       0.7770       0.8051   #>     6 comps      7 comps      8 comps      9 comps     10 comps   #>      0.8815       0.9003       0.8978       0.8668       0.8230 # Training R2(ros.pot, 'train') #> (Intercept)      1 comps      2 comps      3 comps      4 comps      5 comps   #>      0.0000       0.7654       0.8677       0.9407       0.9647       0.9703   #>     6 comps      7 comps      8 comps      9 comps     10 comps   #>      0.9749       0.9783       0.9803       0.9828       0.9851  # Test data R2(rosT, 'test', newdata = testset) #> (Intercept)      1 comps      2 comps      3 comps      4 comps      5 comps   #>     -0.1609       0.3158       0.3365       0.3562       0.4299       0.4217 # Cross-validation RMSEP(ros.pot) #>        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps #> CV           1.778    1.381    1.239   0.9998   0.8072   0.7546   0.5884 #> adjCV        1.778    1.284    1.136   0.9019   0.7151   0.6722   0.5356 #>        7 comps  8 comps  9 comps  10 comps #> CV      0.5397   0.5464   0.6237    0.7192 #> adjCV   0.4959   0.5021   0.5652    0.6547 # Training RMSEP(ros.pot, 'train') #> (Intercept)      1 comps      2 comps      3 comps      4 comps      5 comps   #>      1.7093       0.8279       0.6216       0.4163       0.3213       0.2948   #>     6 comps      7 comps      8 comps      9 comps     10 comps   #>      0.2710       0.2515       0.2397       0.2241       0.2083  # Test data RMSEP(rosT, newdata = testset) #> (Intercept)      1 comps      2 comps      3 comps      4 comps      5 comps   #>       2.435        1.869        1.841        1.813        1.706        1.718"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"image-plots","dir":"Articles","previous_headings":"Response Oriented Sequential Alternation - ROSA","what":"Image plots","title":"E. Supervised multiblock analysis","text":"plots evaluation block selection process ROSA. Correlation plots show different candidate scores (one candidate block component) correlate winning block’s scores. Residual response plots show different choices candidate scores affect RMSE residual response. One can instance use plots decide different block selection order one proposed automatically ROSA.","code":"# Correlation to winning scores image(ros.pot) # Residual response given candidate scores image(ros.pot, \"residual\")"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"multiblock-redundancy-analysis---mbrda","dir":"Articles","previous_headings":"","what":"Multiblock Redundancy Analysis - mbRDA","title":"E. Supervised multiblock analysis","text":"following example uses potato data showcase functions available mbRDA analyses.","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"modelling-5","dir":"Articles","previous_headings":"Multiblock Redundancy Analysis - mbRDA","what":"Modelling","title":"E. Supervised multiblock analysis","text":"implementation uses wrapper mbpcaiv function ade4 package perform mbRDA. multi-response 5 component model fitted.","code":"# Convert data.frame with AsIs objects to list of matrices potatoList <- lapply(potato, unclass)  # Perform mbRDA with two blocks explaining sensory attributes mbr <- mbrda(X = potatoList[c('Chemical','Compression')], Y = potatoList[['Sensory']], ncomp = 5) print(mbr) #> Multiblock RDA  #>  #> Call: #> mbrda(X = potatoList[c(\"Chemical\", \"Compression\")], Y = potatoList[[\"Sensory\"]],     ncomp = 5)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_E_supervised.html","id":"loadings-and-scores","dir":"Articles","previous_headings":"Multiblock Redundancy Analysis - mbRDA","what":"Loadings and scores","title":"E. Supervised multiblock analysis","text":"mbpcaiv wrapper extracts key elements inspection using format rest package. full fitted mbpcaiv object also available, e.g. mbr$mbpcaivObject.","code":"# Extract and view loadings lo_mbr <- loadings(mbr) #> Warning in loadings.multiblock(mbr): No global/consensus loadings available. #> Returning block 1 loadings. print(head(lo_mbr)) #>           Comp 1      Comp 2     Comp 3     Comp 4     Comp 5 #> PEU  -0.11801083  0.45883565 -1.7606202 -0.1936109 -2.3704052 #> Sta.  1.02113965 -2.99539512  1.4968283  4.6426038 -7.6478047 #> TotN  0.50084474 -1.40837541  1.0571404  1.8302797 -1.7127587 #> Phy.  0.24298763  0.27655908  0.3695837  0.4462580 -0.7461178 #> Ca    0.02050271 -0.04647818  0.1311656  0.6243666 -0.9713523 #> Mg   -0.21159305  1.41437345 -0.6562877 -1.4166021  2.0111970 # Plot scores scoreplot(mbr, labels = \"names\")"},{"path":"https://khliland.github.io/multiblock/articles/vignette_F_complex.html","id":"complex-data-structures","dir":"Articles","previous_headings":"","what":"Complex data structures","title":"F. Complex multiblock analysis","text":"following methods complex data structures available multiblock package (function names parentheses): L-PLS - Partial Least Squares L configuration (lpls) -PLS-PM - Sequential Orthogonalised PLS Path Modeling (sopls_pm)","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_F_complex.html","id":"l-pls","dir":"Articles","previous_headings":"Complex data structures","what":"L-PLS","title":"F. Complex multiblock analysis","text":"showcase L-PLS use simulated data specifically made L-shaped data. Regression using L-PLS can either outwards X1 X2 X3 inwards X2 X3 X1. former case, prediction can either X2 X3 given X1. Cross-validation performed either rows X1 columns X1.","code":"______N    |       |   |       |   |  X3   |   |       |  K|_______|                                ______N       ________J    |       |     |         |   |       |     |         |   |  X1   |     |   X2    |   |       |     |         |  I|_______|    I|_________|"},{"path":"https://khliland.github.io/multiblock/articles/vignette_F_complex.html","id":"simulated-l-shaped-data","dir":"Articles","previous_headings":"Complex data structures","what":"Simulated L-shaped data","title":"F. Complex multiblock analysis","text":"simulate two latent components L shape blocks dimensions (30x20), (20x5) (6x20) blocks X1, X2 X3, respectively.","code":"set.seed(42)  # Simulate data set sim <- lplsData(I = 30, N = 20, J = 5, K = 6, ncomp = 2)  # Split into separate blocks X1  <- sim$X1; X2 <- sim$X2; X3 <- sim$X3"},{"path":"https://khliland.github.io/multiblock/articles/vignette_F_complex.html","id":"exo-l-pls","dir":"Articles","previous_headings":"Complex data structures","what":"Exo-L-PLS","title":"F. Complex multiblock analysis","text":"first L-PLS outwards. Predictions accompanied direction.","code":"# exo-L-PLS: lp.exo  <- lpls(X1,X2,X3, ncomp = 2) # type = \"exo\" is default  # Predict X1 pred.exo.X2 <- predict(lp.exo, X1new = X1, exo.direction = \"X2\")  # Predict X3 pred.exo.X2 <- predict(lp.exo, X1new = X1, exo.direction = \"X3\")  # Correlation loading plot plot(lp.exo)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_F_complex.html","id":"endo-l-pls","dir":"Articles","previous_headings":"Complex data structures","what":"Endo-L-PLS","title":"F. Complex multiblock analysis","text":"second L-PLS inwards.","code":"# endo-L-PLS: lp.endo <- lpls(X1,X2,X3, ncomp = 2, type = \"endo\")  # Predict X1 from X2 and X3 (in this case fitted values): pred.endo.X1 <- predict(lp.endo, X2new = X2, X3new = X3)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_F_complex.html","id":"l-pls-cross-validation","dir":"Articles","previous_headings":"Complex data structures","what":"L-PLS cross-validation","title":"F. Complex multiblock analysis","text":"Cross-validation comes choices directions applying L-PLS since sample variable links. cross-validation routines compute RMSECV values perform cross-validated predictions.","code":"# LOO cross-validation horizontally lp.cv1 <- lplsCV(lp.exo, segments1 = as.list(1:dim(X1)[1]), trace = FALSE)  # LOO cross-validation vertically lp.cv2 <- lplsCV(lp.exo, segments2 = as.list(1:dim(X1)[2]), trace = FALSE)  # Three-fold CV, horizontal lp.cv3 <- lplsCV(lp.exo, segments1 = as.list(1:10, 11:20, 21:30), trace = FALSE)  # Three-fold CV, horizontal, inwards model lp.cv4 <- lplsCV(lp.endo, segments1 = as.list(1:10, 11:20, 21:30), trace = FALSE)"},{"path":"https://khliland.github.io/multiblock/articles/vignette_F_complex.html","id":"so-pls-path-modelling","dir":"Articles","previous_headings":"Complex data structures","what":"SO-PLS Path Modelling","title":"F. Complex multiblock analysis","text":"following example uses potato data wine data showcase functions available -PLS-PM analyses.","code":""},{"path":"https://khliland.github.io/multiblock/articles/vignette_F_complex.html","id":"single-so-pls-pm-model","dir":"Articles","previous_headings":"Complex data structures > SO-PLS Path Modelling","what":"Single SO-PLS-PM model","title":"F. Complex multiblock analysis","text":"model four blocks 5 components per input block fitted. set computeAdditional TRUE turn computation additional explained variance per added block model.","code":"# Load potato data data(potato)  # Single path pot.pm <- sopls_pm(potato[1:3], potato[['Sensory']], c(5,5,5), computeAdditional=TRUE)  # Report of explained variances and optimal number of components . # Bootstrapping can be enabled to assess stability. # (LOO cross-validation is default) pot.pm #>  direct indirect     total additional1 additional2 overall #>   0 (0)    52.44 52.44 (3)    4.09 (3)   14.01 (2)   70.55"},{"path":"https://khliland.github.io/multiblock/articles/vignette_F_complex.html","id":"multiple-paths-in-an-so-pls-pm-model","dir":"Articles","previous_headings":"Complex data structures > SO-PLS Path Modelling","what":"Multiple paths in an SO-PLS-PM model","title":"F. Complex multiblock analysis","text":"model containing five blocks fitted. Explained variances sub-paths estimated.","code":"# Load wine data data(wine)  # All path in the forward direction pot.pm.multiple <- sopls_pm_multiple(wine, ncomp = c(4,2,9,8))  # Report of direct, indirect and total explained variance per sub-path. # Bootstrapping can be enabled to assess stability. pot.pm.multiple #> $`Smell at rest->View` #>     direct indirect     total #>  32.68 (1)        0 32.68 (1) #>  #> $`Smell at rest->Smell after shaking` #>  direct indirect     total #>   0 (0)    40.03 40.03 (4) #>  #> $`Smell at rest->Tasting` #>  direct indirect     total #>   0 (0)    11.52 11.52 (2) #>  #> $`Smell at rest->Global quality` #>  direct indirect     total #>   0 (0)    25.25 25.25 (3) #>  #> $`View->Smell after shaking` #>     direct indirect     total #>  30.97 (2)        0 30.97 (2) #>  #> $`View->Tasting` #>  direct indirect     total #>   0 (0)    41.09 41.09 (2) #>  #> $`View->Global quality` #>  direct indirect     total #>   0 (0)    30.87 30.87 (2) #>  #> $`Smell after shaking->Tasting` #>     direct indirect     total #>  56.67 (3)        0 56.67 (3) #>  #> $`Smell after shaking->Global quality` #>  direct indirect     total #>   0 (0)    70.15 70.15 (2) #>  #> $`Tasting->Global quality` #>     direct indirect     total #>  78.12 (2)        0 78.12 (2)"},{"path":"https://khliland.github.io/multiblock/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kristian Hovde Liland. Author, maintainer. Solve Sæbø. Contributor. Stefan Schrunner. Reviewer.","code":""},{"path":"https://khliland.github.io/multiblock/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Liland K (2025). multiblock: Multiblock Data Fusion Statistics Machine Learning. R package version 0.8.10, https://github.com/khliland/multiblock/, https://khliland.github.io/multiblock/.","code":"@Manual{,   title = {multiblock: Multiblock Data Fusion in Statistics and Machine Learning},   author = {Kristian Hovde Liland},   year = {2025},   note = {R package version 0.8.10, https://github.com/khliland/multiblock/},   url = {https://khliland.github.io/multiblock/}, }"},{"path":[]},{"path":"https://khliland.github.io/multiblock/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Multiblock Data Fusion in Statistics and Machine Learning","text":"","code":"# Install release version from CRAN   install.packages(\"multiblock\")   # Install development version from GitHub   devtools::install_github(\"khliland/multiblock\")"},{"path":"https://khliland.github.io/multiblock/index.html","id":"multiblock-book-","dir":"","previous_headings":"","what":"Multiblock book","title":"Multiblock Data Fusion in Statistics and Machine Learning","text":"package contains large variety methods described Age K. Smilde, Tormod Næs Kristian Hovde Liland’s book: Multiblock Data Fusion Statistics Machine Learning- Applications Natural Life Sciences Published Wiley May 2022.","code":""},{"path":"https://khliland.github.io/multiblock/index.html","id":"contents","dir":"","previous_headings":"","what":"Contents","title":"Multiblock Data Fusion in Statistics and Machine Learning","text":"data handling basic methods unsupervised methods ASCA supervised methods methods complex structures selection datasets Common framework plotting routines","code":""},{"path":"https://khliland.github.io/multiblock/reference/DISCOsca.html","id":null,"dir":"Reference","previous_headings":"","what":"DISCO-SCA rotation. — DISCOsca","title":"DISCO-SCA rotation. — DISCOsca","text":"DISCO-SCA procedure identifying common distinctive components. code adapted orphaned RegularizedSCA package Zhengguo Gu.","code":""},{"path":"https://khliland.github.io/multiblock/reference/DISCOsca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DISCO-SCA rotation. — DISCOsca","text":"","code":"DISCOsca(DATA, R, Jk)"},{"path":"https://khliland.github.io/multiblock/reference/DISCOsca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DISCO-SCA rotation. — DISCOsca","text":"DATA matrix, contains concatenated data subjects multiple blocks. Note row represents subject. R Number components (R>=2). Jk vector containing number variables concatenated data matrix.","code":""},{"path":"https://khliland.github.io/multiblock/reference/DISCOsca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DISCO-SCA rotation. — DISCOsca","text":"Trot_best Estimated component score matrix (.e., T) Prot_best Estimated component loading matrix (.e., P) comdist matrix representing common distinctive components. (Rows data blocks columns components.) 0 matrix indicating corresponding component block estimated zeros, 1 indicates (least one component loading ) corresponding component block zero. Thus, column comdist matrix contains 1's, column common component, otherwise distinctive component. propExp_component Proportion variance per component.","code":""},{"path":"https://khliland.github.io/multiblock/reference/DISCOsca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"DISCO-SCA rotation. — DISCOsca","text":"Schouteden, M., Van Deun, K., Wilderjans, T. F., & Van Mechelen, . (2014). Performing DISCO-SCA search distinctive common information linked data. Behavior research methods, 46(2), 576-587.","code":""},{"path":"https://khliland.github.io/multiblock/reference/DISCOsca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"DISCO-SCA rotation. — DISCOsca","text":"","code":"if (FALSE) { # \\dontrun{ DATA1 <- matrix(rnorm(50), nrow=5) DATA2 <- matrix(rnorm(100), nrow=5)  DATA <- cbind(DATA1, DATA2) R <- 5 Jk <- c(10, 20)  DISCOsca(DATA, R, Jk) } # }"},{"path":"https://khliland.github.io/multiblock/reference/SO_TDI.html","id":null,"dir":"Reference","previous_headings":"","what":"Total, direct, indirect and additional effects in SO-PLS-PM. — SO_TDI","title":"Total, direct, indirect and additional effects in SO-PLS-PM. — SO_TDI","text":"-PLS-PM use -PLS path-modelling. particular function used compute effects (explained variances) sub-paths directed acyclic graph.","code":""},{"path":"https://khliland.github.io/multiblock/reference/SO_TDI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Total, direct, indirect and additional effects in SO-PLS-PM. — SO_TDI","text":"","code":"sopls_pm(   X,   Y,   ncomp,   max_comps = min(sum(ncomp), 20),   sel.comp = \"opt\",   computeAdditional = FALSE,   sequential = FALSE,   B = NULL,   k = 10,   type = \"consecutive\",   simultaneous = TRUE )  # S3 method for class 'SO_TDI' print(x, showComp = TRUE, heading = \"SO-PLS path effects\", digits = 2, ...)  sopls_pm_multiple(   X,   ncomp,   max_comps = min(sum(ncomp), 20),   sel.comp = \"opt\",   computeAdditional = FALSE,   sequential = FALSE,   B = NULL,   k = 10,   type = \"consecutive\" )  # S3 method for class 'SO_TDI_multiple' print(x, heading = \"SO-PLS path effects\", digits = 2, ...)"},{"path":"https://khliland.github.io/multiblock/reference/SO_TDI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Total, direct, indirect and additional effects in SO-PLS-PM. — SO_TDI","text":"X list input blocks (type matrix). Y matrix response(s). ncomp integer vector giving number components per block single integer common number components. max_comps Maximum total number components. sel.comp character integer vector indicating type (\"opt\" - minimum error / \"chi\" - chi-squared reduced) exact number components selections. computeAdditional logical indicating additional components computed. sequential logical indicating sequential component optimization applied. B integer giving number bootstrap replicates variation estimation. k integer indicating number cross-validation segments (default = 10). type character selecting type cross-validation segments (default = \"consecutive\"). simultaneous logical indicating simultaneous orthogonalisation intermediate blocks performed (default = TRUE). x object type SO_TDI. showComp logical indicating components shown print (default = TRUE). heading character giving heading print. digits integer selecting number digits print. ... implemented","code":""},{"path":"https://khliland.github.io/multiblock/reference/SO_TDI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Total, direct, indirect and additional effects in SO-PLS-PM. — SO_TDI","text":"object type SO_TDI containing total, direct indirect effects, plus possibly additional effects standard deviations (estimated bootstrapping).","code":""},{"path":"https://khliland.github.io/multiblock/reference/SO_TDI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Total, direct, indirect and additional effects in SO-PLS-PM. — SO_TDI","text":"sopls_pm computes 'total', 'direct', 'indirect' 'additional' effects 'first' versus 'last' input block cross-validated explained variances. 'total' explained variance regression 'first' -> 'last'. 'indirect' , controlled intermediate blocks. 'direct' left-part 'total' explained variance subtracting 'indirect'. Finally, 'additional' added explained variance 'last' block following 'first'. sopls_pm_multiple wrapper sopls_pm repeats calculation pairs blocks 'first' 'last'. sopls_pm separate response, Y, signifying 'last' block, sopls_pm_multiple multiple 'last' blocks, depending sub-path, thus collects response(s) list blocks X. sel.comp = \"opt\", number components models optimized using cross-validation within ncomp max_comps supplied. sel.comp \"chi\", optimization also performed, parsimonious solutions sought chi-square chriterion. setting sel.comp numeric vector, exact selection number components performed. setting B number, e.g. 200, procedures repeated B times using bootstrapping estimate standard deviations cross-validated explained variances.","code":""},{"path":"https://khliland.github.io/multiblock/reference/SO_TDI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Total, direct, indirect and additional effects in SO-PLS-PM. — SO_TDI","text":"Menichelli, E., Almøy, T., Tomic, O., Olsen, N. V., & Næs, T. (2014). -PLS exploratory tool path modelling. Food quality preference, 36, 122-134. Næs, T., Romano, R., Tomic, O., Måge, ., Smilde, ., & Liland, K. H. (2020). Sequential orthogonalized PLS (-PLS) regression path analysis: Order blocks relations effects. Journal Chemometrics, e3243.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/SO_TDI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Total, direct, indirect and additional effects in SO-PLS-PM. — SO_TDI","text":"","code":"# Single path for the potato data: data(potato) pot.pm <- sopls_pm(potato[1:3], potato[['Sensory']], c(5,5,5), computeAdditional=TRUE) pot.pm #>  direct indirect     total additional1 additional2 overall #>   0 (0)    52.44 52.44 (3)    4.09 (3)   14.01 (2)   70.55  # Corresponding SO-PLS model: # so <- sopls(Sensory ~ ., data=potato[c(1,2,3,9)], ncomp=c(5,5,5), validation=\"CV\", segments=10) # maageSeq(pot.so, compSeq = c(3,2,4))  # All path in the forward direction for the wine data: data(wine) pot.pm.multiple <- sopls_pm_multiple(wine, ncomp = c(4,2,9,8)) pot.pm.multiple #> $`Smell at rest->View` #>     direct indirect     total #>  32.68 (1)        0 32.68 (1) #>  #> $`Smell at rest->Smell after shaking` #>  direct indirect     total #>   0 (0)    40.03 40.03 (4) #>  #> $`Smell at rest->Tasting` #>  direct indirect     total #>   0 (0)    11.52 11.52 (2) #>  #> $`Smell at rest->Global quality` #>  direct indirect     total #>   0 (0)    25.25 25.25 (3) #>  #> $`View->Smell after shaking` #>     direct indirect     total #>  30.97 (2)        0 30.97 (2) #>  #> $`View->Tasting` #>  direct indirect     total #>   0 (0)    41.09 41.09 (2) #>  #> $`View->Global quality` #>  direct indirect     total #>   0 (0)    30.87 30.87 (2) #>  #> $`Smell after shaking->Tasting` #>     direct indirect     total #>  56.67 (3)        0 56.67 (3) #>  #> $`Smell after shaking->Global quality` #>  direct indirect     total #>   0 (0)    70.15 70.15 (2) #>  #> $`Tasting->Global quality` #>     direct indirect     total #>  78.12 (2)        0 78.12 (2) #>"},{"path":"https://khliland.github.io/multiblock/reference/asca_plots.html","id":null,"dir":"Reference","previous_headings":"","what":"ASCA Result Methods — asca_plots","title":"ASCA Result Methods — asca_plots","text":"Various plotting procedures asca objects.","code":""},{"path":"https://khliland.github.io/multiblock/reference/asca_plots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ASCA Result Methods — asca_plots","text":"","code":"# S3 method for class 'asca' loadingplot(object, factor = 1, comps = 1:2, ...)  # S3 method for class 'asca' scoreplot(   object,   factor = 1,   comps = 1:2,   pch.scores = 19,   pch.projections = 1,   gr.col = 1:nlevels(object$effects[[factor]]),   ellipsoids,   confidence,   xlim,   ylim,   xlab,   ylab,   legendpos,   ... )"},{"path":"https://khliland.github.io/multiblock/reference/asca_plots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ASCA Result Methods — asca_plots","text":"object asca object. factor integer/character selecting model factor. comps integer vector selected components. ... additional arguments underlying methods. pch.scores integer plotting symbol. pch.projections integer plotting symbol. gr.col integer vector colours groups. ellipsoids character \"confidence\" \"data\" ellipsoids balanced fixed effect models. confidence numeric vector ellipsoid confidences, default = c(0.4, 0.68, 0.95). xlim numeric x limits. ylim numeric y limits. xlab character x label. ylab character y label. legendpos character position legend.","code":""},{"path":"https://khliland.github.io/multiblock/reference/asca_plots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ASCA Result Methods — asca_plots","text":"plotting routines return.","code":""},{"path":"https://khliland.github.io/multiblock/reference/asca_plots.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ASCA Result Methods — asca_plots","text":"Usage functions shown using generics examples asca. Plot routines available scoreplot.asca loadingplot.asca.","code":""},{"path":"https://khliland.github.io/multiblock/reference/asca_plots.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ASCA Result Methods — asca_plots","text":"Smilde, ., Jansen, J., Hoefsloot, H., Lamers,R., Van Der Greef, J., Timmerman, M.(2005). ANOVA-Simultaneous Component Analysis (ASCA): new tool analyzing designed metabolomics data. Bioinformatics, 21(13), 3043–3048. Liland, K.H., Smilde, ., Marini, F., Næs,T. (2018). Confidence ellipsoids ASCA models based multivariate regression theory. Journal Chemometrics, 32(e2990), 1–13. Martin, M. Govaerts, B. (2020). LiMM-PCA: Combining ASCA+ linear mixed models analyse high-dimensional designed data. Journal Chemometrics, 34(6), e3232.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/asca_results.html","id":null,"dir":"Reference","previous_headings":"","what":"ASCA Result Methods — asca_results","title":"ASCA Result Methods — asca_results","text":"Standard result computation extraction functions ASCA (asca).","code":""},{"path":"https://khliland.github.io/multiblock/reference/asca_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ASCA Result Methods — asca_results","text":"","code":"# S3 method for class 'asca' print(x, ...)  # S3 method for class 'asca' summary(object, ...)  # S3 method for class 'summary.asca' print(x, digits = 2, ...)  # S3 method for class 'asca' loadings(object, factor = 1, ...)  # S3 method for class 'asca' scores(object, factor = 1, ...)  projections(object, ...)  # S3 method for class 'asca' projections(object, factor = 1, ...)"},{"path":"https://khliland.github.io/multiblock/reference/asca_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ASCA Result Methods — asca_results","text":"x asca object. ... additional arguments underlying methods. object asca object. digits integer number digits printing. factor integer/character selecting model factor.","code":""},{"path":"https://khliland.github.io/multiblock/reference/asca_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ASCA Result Methods — asca_results","text":"Returns depend method used, e.g. projections.asca returns projected samples, scores.asca return scores, print summary methods return object invisibly.","code":""},{"path":"https://khliland.github.io/multiblock/reference/asca_results.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ASCA Result Methods — asca_results","text":"Usage functions shown using generics examples asca. Explained variances available (block-wise global) blockexpl print.rosaexpl. Object printing summary available : print.asca summary.asca. Scores loadings extensions scores() loadings() scores.asca loadings.asca. Special ASCA scores factor level basis, back-projected samples function projections.asca.","code":""},{"path":"https://khliland.github.io/multiblock/reference/asca_results.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ASCA Result Methods — asca_results","text":"Smilde, ., Jansen, J., Hoefsloot, H., Lamers,R., Van Der Greef, J., Timmerman, M.(2005). ANOVA-Simultaneous Component Analysis (ASCA): new tool analyzing designed metabolomics data. Bioinformatics, 21(13), 3043–3048. Liland, K.H., Smilde, ., Marini, F., Næs,T. (2018). Confidence ellipsoids ASCA models based multivariate regression theory. Journal Chemometrics, 32(e2990), 1–13. Martin, M. Govaerts, B. (2020). LiMM-PCA: Combining ASCA+ linear mixed models analyse high-dimensional designed data. Journal Chemometrics, 34(6), e3232.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/basic.html","id":null,"dir":"Reference","previous_headings":"","what":"Single- and Two-Block Methods — basic","title":"Single- and Two-Block Methods — basic","text":"documentation covers range single- two-block methods. particular: PCA - Principal Component Analysis (pca) PCR - Principal Component Regression (pcr) PLSR - Partial Least Squares Regression (plsr) CCA - Canonical Correlation Analysis (cca) IFA - Interbattery Factor Analysis (ifa) GSVD - Generalized SVD (gsvd)","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/basic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Single- and Two-Block Methods — basic","text":"","code":"data(potato) X <- potato$Chemical y <- potato$Sensory[,1,drop=FALSE]  pca.pot  <- pca(X, ncomp = 2) pcr.pot  <- pcr(y ~ X, ncomp = 2) pls.pot  <- plsr(y ~ X, ncomp = 2) cca.pot  <- cca(potato[1:2]) ifa.pot  <- ifa(potato[1:2]) gsvd.pot <- gsvd(lapply(potato[3:4], t))"},{"path":"https://khliland.github.io/multiblock/reference/block.data.frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Block-wise indexable data.frame — block.data.frame","title":"Block-wise indexable data.frame — block.data.frame","text":"convenience function making data.frames easily indexed block-wise basis.","code":""},{"path":"https://khliland.github.io/multiblock/reference/block.data.frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Block-wise indexable data.frame — block.data.frame","text":"","code":"block.data.frame(X, block_inds = NULL, to.matrix = TRUE)"},{"path":"https://khliland.github.io/multiblock/reference/block.data.frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Block-wise indexable data.frame — block.data.frame","text":"X Either single data.frame index list matrices/data.frames block_inds Named list indexes X single data.frame, otherwise NULL. .matrix logical indicating input list elements converted matrices.","code":""},{"path":"https://khliland.github.io/multiblock/reference/block.data.frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Block-wise indexable data.frame — block.data.frame","text":"data.frame can indexed block-wise.","code":""},{"path":"https://khliland.github.io/multiblock/reference/block.data.frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Block-wise indexable data.frame — block.data.frame","text":"","code":"# Random data M <- matrix(rnorm(200), nrow = 10) # .. with dimnames dimnames(M) <- list(LETTERS[1:10], as.character(1:20))  # A named list for indexing inds <- list(B1 = 1:10, B2 = 11:20)  X <- block.data.frame(M, inds) str(X) #> 'data.frame':\t10 obs. of  2 variables: #>  $ B1: 'AsIs' num [1:10, 1:10] -0.936 -0.016 -0.827 -1.512 0.935 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:10] \"A\" \"B\" \"C\" \"D\" ... #>   .. ..$ : chr [1:10] \"1\" \"2\" \"3\" \"4\" ... #>  $ B2: 'AsIs' num [1:10, 1:10] 0.604 -0.263 -0.528 0.192 -1.146 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:10] \"A\" \"B\" \"C\" \"D\" ... #>   .. ..$ : chr [1:10] \"11\" \"12\" \"13\" \"14\" ..."},{"path":"https://khliland.github.io/multiblock/reference/candies.html","id":null,"dir":"Reference","previous_headings":"","what":"Sensory assessment of candies. — candies","title":"Sensory assessment of candies. — candies","text":"dataset containing 9 sensory attributes 5 candies assessed 11 trained assessors.","code":""},{"path":"https://khliland.github.io/multiblock/reference/candies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sensory assessment of candies. — candies","text":"","code":"data(candies)"},{"path":"https://khliland.github.io/multiblock/reference/candies.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sensory assessment of candies. — candies","text":"data.frame 165 rows 3 variables: assessment Matrix sensory attributes assessor Factor assessors candy Factor candies","code":""},{"path":"https://khliland.github.io/multiblock/reference/candies.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sensory assessment of candies. — candies","text":"Luciano G, Næs T. Interpreting sensory data combining principal component analysis analysis variance. Food Qual Prefer. 2009;20(3):167-175.","code":""},{"path":"https://khliland.github.io/multiblock/reference/cca.html","id":null,"dir":"Reference","previous_headings":"","what":"Canonical Correlation Analysis - CCA — cca","title":"Canonical Correlation Analysis - CCA — cca","text":"wrapper stats::cancor function computing CCA.","code":""},{"path":"https://khliland.github.io/multiblock/reference/cca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Canonical Correlation Analysis - CCA — cca","text":"","code":"cca(X)"},{"path":"https://khliland.github.io/multiblock/reference/cca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Canonical Correlation Analysis - CCA — cca","text":"X list input data blocks.","code":""},{"path":"https://khliland.github.io/multiblock/reference/cca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Canonical Correlation Analysis - CCA — cca","text":"multiblock object associated printing, scores, loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/cca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Canonical Correlation Analysis - CCA — cca","text":"CCA method maximises correlation linear combinations columns two blocks, .e. max(cor(X1 x , X2 x b)). done sequentially deflation , sequence correlations weight vectors b associated pair matrices.","code":""},{"path":"https://khliland.github.io/multiblock/reference/cca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Canonical Correlation Analysis - CCA — cca","text":"Hotelling, H. (1936) Relations two sets variates. Biometrika, 28, 321–377.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/cca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Canonical Correlation Analysis - CCA — cca","text":"","code":"data(potato) X <- potato$Chemical  cca.pot  <- cca(potato[1:2])"},{"path":"https://khliland.github.io/multiblock/reference/complex.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods With Complex Linkage — complex","title":"Methods With Complex Linkage — complex","text":"documentation covers complex methods. particular: L-PLS - Partial Least Squares L configuration (lpls) -PLS-PM - Sequential Orthogonalised PLS Path Modeling (sopls_pm)","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/complex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Methods With Complex Linkage — complex","text":"","code":"# L-PLS sim <- lplsData(I = 30, N = 20, J = 5, K = 6, ncomp = 2) X1  <- sim$X1; X2 <- sim$X2; X3 <- sim$X3 lp  <- lpls(X1,X2,X3) # exo-L-PLS"},{"path":"https://khliland.github.io/multiblock/reference/compnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Vector of component names — compnames","title":"Vector of component names — compnames","text":"Convenience function creating vector component names based dimensions input object (matrix object score function).","code":""},{"path":"https://khliland.github.io/multiblock/reference/compnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vector of component names — compnames","text":"","code":"compnames(object, comps, explvar = FALSE, ...)"},{"path":"https://khliland.github.io/multiblock/reference/compnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vector of component names — compnames","text":"object object fitted using multiblock package. comps integer vector components. explvar logical indicating explained variances included. ... Unused","code":""},{"path":"https://khliland.github.io/multiblock/reference/compnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vector of component names — compnames","text":"character vector component names.","code":""},{"path":"https://khliland.github.io/multiblock/reference/compnames.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Vector of component names — compnames","text":"copy compnames pls package work multiblock objects.","code":""},{"path":"https://khliland.github.io/multiblock/reference/disco.html","id":null,"dir":"Reference","previous_headings":"","what":"Distinctive and Common Components with SCA - DISCO — disco","title":"Distinctive and Common Components with SCA - DISCO — disco","text":"wrapper DISCOsca function Zhengguo Gu computing DISCO.","code":""},{"path":"https://khliland.github.io/multiblock/reference/disco.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distinctive and Common Components with SCA - DISCO — disco","text":"","code":"disco(X, ncomp = 2, ...)"},{"path":"https://khliland.github.io/multiblock/reference/disco.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distinctive and Common Components with SCA - DISCO — disco","text":"X list input blocks. ncomp integer number components extract. ... additional arguments (used).","code":""},{"path":"https://khliland.github.io/multiblock/reference/disco.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distinctive and Common Components with SCA - DISCO — disco","text":"multiblock object including relevant scores loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/disco.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distinctive and Common Components with SCA - DISCO — disco","text":"DISCO restriction SCA Alternating Least Squares used estimation loadings scores. SCA solution rotated towards loadings (sample linked mode) filled zeros pattern resembling distinct, local common components. used sample linked mode selecting distinct components, shares resemblance -PLS, unsupervised setting. Explained variances computed proportion block variation explained scores*loadings'.","code":""},{"path":"https://khliland.github.io/multiblock/reference/disco.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Distinctive and Common Components with SCA - DISCO — disco","text":"Schouteden, M., Van Deun, K., Wilderjans, T. F., & Van Mechelen, . (2014). Performing DISCO-SCA search distinctive common information linked data. Behavior research methods, 46(2), 576-587.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/disco.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Distinctive and Common Components with SCA - DISCO — disco","text":"","code":"data(potato) potList <- as.list(potato[c(1,2,9)]) pot.disco  <- disco(potList) #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    0 #> [2,]    1    0 #> [3,]    0    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    0 #> [2,]    0    1 #> [3,]    1    0 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    0 #> [2,]    0    1 #> [3,]    0    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    1    0 #> [3,]    1    0 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    1    0 #> [3,]    0    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    0    1 #> [3,]    1    0 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    1 #> [2,]    1    0 #> [3,]    1    0 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    0 #> [2,]    1    1 #> [3,]    1    0 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    0 #> [2,]    1    0 #> [3,]    1    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    1 #> [2,]    1    0 #> [3,]    0    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    0 #> [2,]    1    1 #> [3,]    0    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    1 #> [2,]    0    1 #> [3,]    1    0 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    0 #> [2,]    0    1 #> [3,]    1    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    1 #> [2,]    0    1 #> [3,]    0    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    1    1 #> [3,]    1    0 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    1    0 #> [3,]    1    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    1    1 #> [3,]    0    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    0    1 #> [3,]    1    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    1 #> [2,]    1    1 #> [3,]    1    0 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    1 #> [2,]    1    0 #> [3,]    1    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    0 #> [2,]    1    1 #> [3,]    1    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    1 #> [2,]    1    1 #> [3,]    0    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    1    1 #> [2,]    0    1 #> [3,]    1    1 #> Now checking the following component structure: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    1    1 #> [3,]    1    1 plot(scores(pot.disco), labels=\"names\")"},{"path":"https://khliland.github.io/multiblock/reference/dummycode.html","id":null,"dir":"Reference","previous_headings":"","what":"Dummy-coding of a single vector — dummycode","title":"Dummy-coding of a single vector — dummycode","text":"Flexible dummy-coding allowing R's built-types contrasts optional dropping factor level reduce rank defficiency probability.","code":""},{"path":"https://khliland.github.io/multiblock/reference/dummycode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dummy-coding of a single vector — dummycode","text":"","code":"dummycode(Y, contrast = \"contr.sum\", drop = TRUE)"},{"path":"https://khliland.github.io/multiblock/reference/dummycode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dummy-coding of a single vector — dummycode","text":"Y vector dummy code. contrast Contrast type, default = \"contr.sum\". drop logical indicating one level dropped (default = TRUE).","code":""},{"path":"https://khliland.github.io/multiblock/reference/dummycode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dummy-coding of a single vector — dummycode","text":"matrix made dummy-coding input vector.","code":""},{"path":"https://khliland.github.io/multiblock/reference/dummycode.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dummy-coding of a single vector — dummycode","text":"","code":"vec <- c(\"a\",\"a\",\"b\",\"b\",\"c\",\"c\") dummycode(vec) #>   x1 x2 #> 1  1  0 #> 2  1  0 #> 3  0  1 #> 4  0  1 #> 5 -1 -1 #> 6 -1 -1"},{"path":"https://khliland.github.io/multiblock/reference/explvar.html","id":null,"dir":"Reference","previous_headings":"","what":"Explained predictor variance — explvar","title":"Explained predictor variance — explvar","text":"Extraction /computation explained variances various object classes multiblock package.","code":""},{"path":"https://khliland.github.io/multiblock/reference/explvar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explained predictor variance — explvar","text":"","code":"explvar(object)"},{"path":"https://khliland.github.io/multiblock/reference/explvar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explained predictor variance — explvar","text":"object object fitted using method multiblock package","code":""},{"path":"https://khliland.github.io/multiblock/reference/explvar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explained predictor variance — explvar","text":"vector component-wise explained variances predictors.","code":""},{"path":"https://khliland.github.io/multiblock/reference/explvar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explained predictor variance — explvar","text":"","code":"data(potato) so <- sopls(Sensory ~ Chemical + Compression, data=potato, ncomp=c(10,10),              max_comps=10) explvar(so) #>        0,0        0,1        0,2        0,3        0,4        0,5        0,6  #>  0.0000000 45.8687627  9.6453264  7.3898305  3.5545689  1.2708076  7.2218549  #>        0,7        0,8        0,9       0,10        1,0        1,1        1,2  #>  3.3122521  1.5830365  2.5404624  0.7899845 34.2017249 29.9203640  7.5862050  #>        1,3        1,4        1,5        1,6        1,7        1,8        1,9  #>  4.5354153  1.9562759  1.2891286  3.8823352  1.0455730  1.1736034  0.4786749  #>        2,0        2,1        2,2        2,3        2,4        2,5        2,6  #>  8.5567408 29.8494182  6.7924606  2.0046763  1.2816857  2.2955734  3.1794417  #>        2,7        2,8        3,0        3,1        3,2        3,3        3,4  #>  0.7035895  0.9788461 20.9999933 14.8311902  5.9640780  2.2114124  0.9630738  #>        3,5        3,6        3,7        4,0        4,1        4,2        4,3  #>  2.3612130  1.7170928  0.6543032  6.3303082 10.2624882  6.7734592  1.7625131  #>        4,4        4,5        4,6        5,0        5,1        5,2        5,3  #>  0.8944426  2.2524447  1.3335044  5.1247451  9.0556886  6.8925550  1.3579712  #>        5,4        5,5        6,0        6,1        6,2        6,3        6,4  #>  0.9480858  1.9343360  2.0713113  8.9383967  6.9547883  1.3697888  1.0793572  #>        7,0        7,1        7,2        7,3        8,0        8,1        8,2  #>  2.2840233  8.8631448  7.0319143  1.1838720  3.2504266  5.3411760  7.8007596  #>        9,0        9,1       10,0  #>  2.6747591  4.7191749  1.5823723"},{"path":"https://khliland.github.io/multiblock/reference/extended.model.frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracting the Extended Model Frame from a Formula or Fit — extended.model.frame","title":"Extracting the Extended Model Frame from a Formula or Fit — extended.model.frame","text":"function attempts apply model.frame extend result columns interactions.","code":""},{"path":"https://khliland.github.io/multiblock/reference/extended.model.frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracting the Extended Model Frame from a Formula or Fit — extended.model.frame","text":"","code":"extended.model.frame(formula, data, ..., sep = \".\")"},{"path":"https://khliland.github.io/multiblock/reference/extended.model.frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracting the Extended Model Frame from a Formula or Fit — extended.model.frame","text":"formula model formula terms object R object. data data.frame, list environment (see model.frame). ... arguments pass model.frame. sep separator contraction names interactions (default = \".\").","code":""},{"path":"https://khliland.github.io/multiblock/reference/extended.model.frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracting the Extended Model Frame from a Formula or Fit — extended.model.frame","text":"data.frame includes everything model.frame plus interaction terms.","code":""},{"path":"https://khliland.github.io/multiblock/reference/extended.model.frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extracting the Extended Model Frame from a Formula or Fit — extended.model.frame","text":"","code":"dat <- data.frame(Y = c(1,2,3,4,5,6),                    X = factor(LETTERS[c(1,1,2,2,3,3)]),                    W = factor(letters[c(1,2,1,2,1,2)])) extended.model.frame(Y ~ X*W, dat) #>   Y X W X:W #> 1 1 A a A.a #> 2 2 A b A.b #> 3 3 B a B.a #> 4 4 B b B.b #> 5 5 C a C.a #> 6 6 C b C.b"},{"path":"https://khliland.github.io/multiblock/reference/gca.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Canonical Analysis - GCA — gca","title":"Generalized Canonical Analysis - GCA — gca","text":"interface SVD-based (default) RGCCA-based GCA (wrapping RGCCA::rgcca function)","code":""},{"path":"https://khliland.github.io/multiblock/reference/gca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Canonical Analysis - GCA — gca","text":"","code":"gca(X, ncomp = \"max\", svd = TRUE, tol = 10^-12, corrs = TRUE, ...)"},{"path":"https://khliland.github.io/multiblock/reference/gca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Canonical Analysis - GCA — gca","text":"X list input blocks. ncomp integer number components extract, either single integer (equal blocks), vector (individual per block) 'max' maximum possible number components. svd logical indicating Singular Value Decomposition approach used (default=TRUE). tol numeric tolerance component inclusion (singular values). corrs logical indicating correlations calculated RGCCA based approach. ... additional arguments RGCCA approach.","code":""},{"path":"https://khliland.github.io/multiblock/reference/gca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Canonical Analysis - GCA — gca","text":"multiblock object including relevant scores loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results. blockCoef contains canonical coefficients, blockDecomp contains decompositions block.","code":""},{"path":"https://khliland.github.io/multiblock/reference/gca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Canonical Analysis - GCA — gca","text":"GCA generalisation Canonical Correlation Analysis handle three blocks. several ways generalise, two available gca. default SVD based approach estimating common subspace measuring mean squared correlation . alternative approach available RGCCA. SVD based approach, ncomp parameter controls block-wise decomposition following consensus decomposition limited minimum number components individual blocks.","code":""},{"path":"https://khliland.github.io/multiblock/reference/gca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Canonical Analysis - GCA — gca","text":"Carroll, J. D. (1968). Generalization canonical correlation analysis three sets variables. Proceedings American Psychological Association, pages 227-22. Van der Burg, E. Dijksterhuis, G. (1996). Generalised canonical analysis individual sensory profiles instrument data, Elsevier, pp. 221–258.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/gca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Canonical Analysis - GCA — gca","text":"","code":"data(potato) potList <- as.list(potato[c(1,2,9)]) pot.gca <- gca(potList) plot(scores(pot.gca), labels=\"names\")"},{"path":"https://khliland.github.io/multiblock/reference/gpa.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Procrustes Analysis - GPA — gpa","title":"Generalized Procrustes Analysis - GPA — gpa","text":"wrapper FactoMineR::GPA function computing GPA.","code":""},{"path":"https://khliland.github.io/multiblock/reference/gpa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Procrustes Analysis - GPA — gpa","text":"","code":"gpa(X, graph = FALSE, ...)"},{"path":"https://khliland.github.io/multiblock/reference/gpa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Procrustes Analysis - GPA — gpa","text":"X list input blocks. graph logical indicating decomposition plotted. ... additional arguments RGCCA approach.","code":""},{"path":"https://khliland.github.io/multiblock/reference/gpa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Procrustes Analysis - GPA — gpa","text":"multiblock object including relevant scores loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/gpa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Procrustes Analysis - GPA — gpa","text":"GPA generalisation Procrustes analysis, one matrix scaled rotated similar possible another one. generalisation, individual scaling rotation input matrix performed common representation estimated iterative manner.","code":""},{"path":"https://khliland.github.io/multiblock/reference/gpa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Procrustes Analysis - GPA — gpa","text":"Gower, J. C. (1975). Generalized procrustes analysis. Psychometrika. 40: 33–51.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/gpa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Procrustes Analysis - GPA — gpa","text":"","code":"data(potato) potList <- as.list(potato[c(1,2,9)]) pot.gpa    <- gpa(potList) #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. #> Warning: Recycling array of length 1 in vector-array arithmetic is deprecated. #>   Use c() or as.vector() instead. plot(scores(pot.gpa), labels=\"names\")"},{"path":"https://khliland.github.io/multiblock/reference/gsvd.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalised Singular Value Decomposition - GSVD — gsvd","title":"Generalised Singular Value Decomposition - GSVD — gsvd","text":"wrapper geigen::gsvd function computing GSVD.","code":""},{"path":"https://khliland.github.io/multiblock/reference/gsvd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalised Singular Value Decomposition - GSVD — gsvd","text":"","code":"gsvd(X)"},{"path":"https://khliland.github.io/multiblock/reference/gsvd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalised Singular Value Decomposition - GSVD — gsvd","text":"X list input data blocks.","code":""},{"path":"https://khliland.github.io/multiblock/reference/gsvd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalised Singular Value Decomposition - GSVD — gsvd","text":"multiblock object associated printing, scores, loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/gsvd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalised Singular Value Decomposition - GSVD — gsvd","text":"GSVD generalisation SVD two variable-linked matrices common loadings block-wise scores estimated.","code":""},{"path":"https://khliland.github.io/multiblock/reference/gsvd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalised Singular Value Decomposition - GSVD — gsvd","text":"Van Loan, C. (1976) Generalizing singular value decomposition. SIAM Journal Numerical Analysis, 13, 76–83.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/gsvd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalised Singular Value Decomposition - GSVD — gsvd","text":"","code":"data(potato) X <- potato$Chemical  gsvd.pot <- gsvd(lapply(potato[3:4], t))"},{"path":"https://khliland.github.io/multiblock/reference/hogsvd.html","id":null,"dir":"Reference","previous_headings":"","what":"Higher Order Generalized SVD - HOGSVD — hogsvd","title":"Higher Order Generalized SVD - HOGSVD — hogsvd","text":"simple implementation computing HOGSVD","code":""},{"path":"https://khliland.github.io/multiblock/reference/hogsvd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Higher Order Generalized SVD - HOGSVD — hogsvd","text":"","code":"hogsvd(X)"},{"path":"https://khliland.github.io/multiblock/reference/hogsvd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Higher Order Generalized SVD - HOGSVD — hogsvd","text":"X list input blocks.","code":""},{"path":"https://khliland.github.io/multiblock/reference/hogsvd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Higher Order Generalized SVD - HOGSVD — hogsvd","text":"multiblock object including relevant scores loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/hogsvd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Higher Order Generalized SVD - HOGSVD — hogsvd","text":"HOGSVD generalisation SVD two blocks. finds common set loadings across blocks individual sets scores per block.","code":""},{"path":"https://khliland.github.io/multiblock/reference/hogsvd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Higher Order Generalized SVD - HOGSVD — hogsvd","text":"Ponnapalli, S. P., Saunders, M. ., Van Loan, C. F., & Alter, O. (2011). higher-order generalized singular value decomposition comparison global mRNA expression multiple organisms. PloS one, 6(12), e28072.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/hogsvd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Higher Order Generalized SVD - HOGSVD — hogsvd","text":"","code":"data(candies) candyList <- lapply(1:nlevels(candies$candy),function(x)candies$assessment[candies$candy==x,]) can.hogsvd <- hogsvd(candyList) scoreplot(can.hogsvd, block=1, labels=\"names\")"},{"path":"https://khliland.github.io/multiblock/reference/hpca.html","id":null,"dir":"Reference","previous_headings":"","what":"Hierarchical Principal component analysis - HPCA — hpca","title":"Hierarchical Principal component analysis - HPCA — hpca","text":"wrapper RGCCA::rgcca function computing HPCA.","code":""},{"path":"https://khliland.github.io/multiblock/reference/hpca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hierarchical Principal component analysis - HPCA — hpca","text":"","code":"hpca(X, ncomp = 2, scale = FALSE, verbose = FALSE, ...)"},{"path":"https://khliland.github.io/multiblock/reference/hpca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hierarchical Principal component analysis - HPCA — hpca","text":"X list input blocks. ncomp integer number components extract. scale logical indicating variables scaled. verbose logical indicating diagnostic information printed. ... additional arguments RGCCA.","code":""},{"path":"https://khliland.github.io/multiblock/reference/hpca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hierarchical Principal component analysis - HPCA — hpca","text":"multiblock object including relevant scores loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/hpca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hierarchical Principal component analysis - HPCA — hpca","text":"HPCA hierarchical PCA analysis combines two blocks two-level decomposition block-wise loadings scores superlevel common loadings scores. method closely related supervised method MB-PLS structure.","code":""},{"path":"https://khliland.github.io/multiblock/reference/hpca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hierarchical Principal component analysis - HPCA — hpca","text":"Westerhuis, J.., Kourti, T., MacGregor,J.F. (1998). Analysis multiblock hierarchical PCA PLS models. Journal Chemometrics, 12, 301–321.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/hpca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hierarchical Principal component analysis - HPCA — hpca","text":"","code":"data(potato) potList <- as.list(potato[c(1,2,9)]) pot.hpca   <- hpca(potList) plot(scores(pot.hpca), labels=\"names\")"},{"path":"https://khliland.github.io/multiblock/reference/ifa.html","id":null,"dir":"Reference","previous_headings":"","what":"Inter-battery Factor Analysis - IFA — ifa","title":"Inter-battery Factor Analysis - IFA — ifa","text":"wrapper RGCCA::rgcca function computing IFA.","code":""},{"path":"https://khliland.github.io/multiblock/reference/ifa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inter-battery Factor Analysis - IFA — ifa","text":"","code":"ifa(X, ncomp = 1, scale = FALSE, verbose = FALSE, ...)"},{"path":"https://khliland.github.io/multiblock/reference/ifa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inter-battery Factor Analysis - IFA — ifa","text":"X list input data blocks. ncomp integer number principal components return. scale logical indicating variables standardised (default=FALSE). verbose logical indicating intermediate results printed. ... additional arguments RGCCA::rgcca.","code":""},{"path":"https://khliland.github.io/multiblock/reference/ifa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inter-battery Factor Analysis - IFA — ifa","text":"multiblock object associated printing, scores, loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/ifa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inter-battery Factor Analysis - IFA — ifa","text":"IFA rotates two matrices align one factors , maximising correlations.","code":""},{"path":"https://khliland.github.io/multiblock/reference/ifa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Inter-battery Factor Analysis - IFA — ifa","text":"Tucker, L. R. (1958). inter-battery method factor analysis. Psychometrika, 23(2), 111-136.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/ifa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inter-battery Factor Analysis - IFA — ifa","text":"","code":"data(potato) X <- potato$Chemical  ifa.pot  <- ifa(potato[1:2])"},{"path":"https://khliland.github.io/multiblock/reference/jive.html","id":null,"dir":"Reference","previous_headings":"","what":"Joint and Individual Variation Explained - JIVE — jive","title":"Joint and Individual Variation Explained - JIVE — jive","text":"wrapper r.jive::jive function computing JIVE.","code":""},{"path":"https://khliland.github.io/multiblock/reference/jive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Joint and Individual Variation Explained - JIVE — jive","text":"","code":"jive(X, ...)"},{"path":"https://khliland.github.io/multiblock/reference/jive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Joint and Individual Variation Explained - JIVE — jive","text":"X list input blocks. ... additional arguments r.jive::jive.","code":""},{"path":"https://khliland.github.io/multiblock/reference/jive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Joint and Individual Variation Explained - JIVE — jive","text":"multiblock object including relevant scores loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/jive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Joint and Individual Variation Explained - JIVE — jive","text":"Jive performs decomposition variation two blocks low-dimensional representations individual joint variation plus residual variation.","code":""},{"path":"https://khliland.github.io/multiblock/reference/jive.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Joint and Individual Variation Explained - JIVE — jive","text":"Lock, E., Hoadley, K., Marron, J., Nobel, . (2013) Joint individual variation explained (JIVE) integrated analysis multiple data types. Ann Appl Stat, 7 (1), 523–542.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/jive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Joint and Individual Variation Explained - JIVE — jive","text":"","code":"# Too time consuming for testing   data(candies)   candyList <- lapply(1:nlevels(candies$candy),function(x)candies$assessment[candies$candy==x,])   can.jive  <- jive(candyList) #> Estimating  joint and individual ranks via permutation... #> Running JIVE algorithm for ranks: #> joint rank: 1 , individual ranks: 1 1 1 1 1  #> JIVE algorithm converged after  16  iterations. #> Re-estimating  joint and individual ranks via permutation... #> Running JIVE algorithm for ranks: #> joint rank: 1 , individual ranks: 1 0 1 0 1  #> JIVE algorithm converged after  13  iterations. #> Re-estimating  joint and individual ranks via permutation... #> Final joint rank: 1 , final individual ranks: 1 0 1 0 1    summary(can.jive) #> $Method #> [1] \"perm\" #>  #> $Ranks #>      Source     Rank #> [1,] \"Joint\"    \"1\"  #> [2,] \"Source_1\" \"1\"  #> [3,] \"Source_2\" \"0\"  #> [4,] \"Source_3\" \"1\"  #> [5,] \"Source_4\" \"0\"  #> [6,] \"Source_5\" \"1\"  #>  #> $Variance #>            Source_1 Source_2 Source_3 Source_4 Source_5 #> Joint         0.690    0.852    0.793    0.878    0.624 #> Individual    0.079    0.000    0.056    0.000    0.223 #> Residual      0.230    0.148    0.151    0.122    0.153 #>"},{"path":"https://khliland.github.io/multiblock/reference/lpls.html","id":null,"dir":"Reference","previous_headings":"","what":"L-PLS regression — lpls","title":"L-PLS regression — lpls","text":"Simultaneous decomposition three blocks connected L pattern.","code":""},{"path":"https://khliland.github.io/multiblock/reference/lpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-PLS regression — lpls","text":"","code":"lpls(   X1,   X2,   X3,   ncomp = 2,   doublecenter = TRUE,   scale = c(FALSE, FALSE, FALSE),   type = c(\"exo\"),   impute = FALSE,   niter = 25,   subsetX2 = NULL,   subsetX3 = NULL,   ... )"},{"path":"https://khliland.github.io/multiblock/reference/lpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-PLS regression — lpls","text":"X1 matrix size IxN (middle matrix) X2 matrix size IxJ (left matrix) X3 matrix size KxN (top matrix) ncomp number L-PLS components doublecenter logical indicating centering done ways X1 (default=TRUE) scale logical vector length three indicating matrices autoscaled. type character indicating type L-PLS (\"exo\"=default, \"exo_ort\" \"endo\") impute logical indicating SVD-based imputation missing data required. niter numeric giving number iterations component extraction loop. subsetX2 vector defining optional sub-setting X2 data. subsetX3 vector defining optional sub-setting X3 data. ... Additional arguments, used.","code":""},{"path":"https://khliland.github.io/multiblock/reference/lpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-PLS regression — lpls","text":"object type lpls multiblock containing results L-PLS analysis. object type lpls associated functions correlation loading plots, prediction cross-validation. type multiblock associated default functions result presentation (multiblock_results) plotting (multiblock_plots).","code":""},{"path":"https://khliland.github.io/multiblock/reference/lpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-PLS regression — lpls","text":"Two versions L-PLS available: exo- endo-L-PLS assume outward inward relationship main block X1 two blocks X2 X3. exo_ort algorithm returns orthogonal scores chosen visual exploration correlation loading plots. exo-L-PLS prediction main purpose model non-orthogonal exo type L-PLS chosen predict function prediction implemented.","code":""},{"path":"https://khliland.github.io/multiblock/reference/lpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-PLS regression — lpls","text":"Martens, H., Anderssen, E., Flatberg, .,Gidskehaug, L.H., Høy, M., Westad, F.,Thybo, ., Martens, M. (2005). Regression data matrix descriptors rows columns via latent variables: L-PLSR. Computational Statistics & Data Analysis, 48(1), 103 – 123. Sæbø, S., Almøy, T., Flatberg, ., Aastveit, .H., Martens, H. (2008). LPLS-regression: method prediction classification influence background information predictor variables. Chemometrics Intelligent Laboratory Systems, 91, 121–132. Sæbø, S., Martens, M. Martens H. (2010) Three-block data modeling endo- exo-LPLS regression. Handbook Partial Least Squares: Concepts, Methods Applications. Esposito Vinzi, V.; Chin, W.W.; Henseler, J.; Wang, H. (Eds.). Springer.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/lpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"L-PLS regression — lpls","text":"Solve Sæbø (adapted Kristian Hovde Liland)","code":""},{"path":"https://khliland.github.io/multiblock/reference/lpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-PLS regression — lpls","text":"","code":"# Simulate data set sim <- lplsData(I = 30, N = 20, J = 5, K = 6, ncomp = 2) X1  <- sim$X1; X2 <- sim$X2; X3 <- sim$X3 lp  <- lpls(X1,X2,X3) # exo-L-PLS"},{"path":"https://khliland.github.io/multiblock/reference/lplsData.html","id":null,"dir":"Reference","previous_headings":"","what":"L-PLS data simulation for exo-type analysis — lplsData","title":"L-PLS data simulation for exo-type analysis — lplsData","text":"Three data blocks simulated express covariance exo-L-PLS direction (see lpls. Dimensionality number underlying components can controlled.","code":""},{"path":"https://khliland.github.io/multiblock/reference/lplsData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-PLS data simulation for exo-type analysis — lplsData","text":"","code":"lplsData(I = 30, N = 20, J = 5, K = 6, ncomp = 2)"},{"path":"https://khliland.github.io/multiblock/reference/lplsData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-PLS data simulation for exo-type analysis — lplsData","text":"numeric number rows X1 X2 N numeric number columns X1 X3 J numeric number columns X2 K numeric number rows X3 ncomp numeric number latent components","code":""},{"path":"https://khliland.github.io/multiblock/reference/lplsData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-PLS data simulation for exo-type analysis — lplsData","text":"list three matrices dimensions matching L-shape.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/lplsData.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"L-PLS data simulation for exo-type analysis — lplsData","text":"Solve Sæbø (adapted Kristian Hovde Liland)","code":""},{"path":"https://khliland.github.io/multiblock/reference/lplsData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-PLS data simulation for exo-type analysis — lplsData","text":"","code":"lp <- lplsData(I = 30, N = 20, J = 5, K = 6, ncomp = 2) names(lp) #> [1] \"X1\" \"X2\" \"X3\""},{"path":"https://khliland.github.io/multiblock/reference/lpls_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Result functions for L-PLS objects (lpls) — lpls_results","title":"Result functions for L-PLS objects (lpls) — lpls_results","text":"Correlation loading plot, prediction cross-validation L-PLS models class lpls.","code":""},{"path":"https://khliland.github.io/multiblock/reference/lpls_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Result functions for L-PLS objects (lpls) — lpls_results","text":"","code":"# S3 method for class 'lpls' plot(   x,   comps = c(1, 2),   doplot = c(TRUE, TRUE, TRUE),   level = c(2, 2, 2),   arrow = c(1, 0, 1),   xlim = c(-1, 1),   ylim = c(-1, 1),   samplecol = 4,   pathcol = 2,   varcol = \"grey70\",   varsize = 1,   sampleindex = 1:dim(x$corloadings$R22)[1],   pathindex = 1:dim(x$corloadings$R3)[1],   varindex = 1:dim(x$corloadings$R21)[1],   ... )  # S3 method for class 'lpls' predict(   object,   X1new = NULL,   X2new = NULL,   X3new = NULL,   exo.direction = c(\"X2\", \"X3\"),   ... )  lplsCV(object, segments1 = NULL, segments2 = NULL, trace = TRUE)"},{"path":"https://khliland.github.io/multiblock/reference/lpls_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result functions for L-PLS objects (lpls) — lpls_results","text":"x lpls object comps integer vector components. doplot logical indicating plotting performed. level integer vector length 3 selecting plot symbol. 1=dots. 2=dimnames. arrow integer vector length 3 indicating arrows (1) (0). xlim numeric x limits. ylim numeric y limits. samplecol character sample colours. pathcol character third colour. varcol character variable colours. varsize numeric size symbols variables. sampleindex integer selecting samples. pathindex integer selecting third direction. varindex integer selecting variables. ... implemented. object lpls object. X1new matrix new X1 samples. X2new matrix new X2 samples. X3new matrix new X3 samples. exo.direction character selecting \"X2\" \"X3\" prediction. segments1 list sample segments. segments2 list variable segments. trace logical indicating verbose mode selected.","code":""},{"path":"https://khliland.github.io/multiblock/reference/lpls_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Result functions for L-PLS objects (lpls) — lpls_results","text":"Nothing return plotting (plot.lpls), predicted values returned predictions (predict.lpls) cross-validation metrics returned cross-validation (lplsCV).","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/lpls_results.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Result functions for L-PLS objects (lpls) — lpls_results","text":"","code":"# Simulate data set sim <- lplsData(I = 30, N = 20, J = 5, K = 6, ncomp = 2) X1  <- sim$X1; X2 <- sim$X2; X3 <- sim$X3  # exo-L-PLS: lp.exo  <- lpls(X1,X2,X3, ncomp = 2) # Predict X1 pred.exo.X2 <- predict(lp.exo, X1new = X1, exo.direction = \"X2\") # Predict X3 pred.exo.X2 <- predict(lp.exo, X1new = X1, exo.direction = \"X3\")  # endo-L-PLS: lp.endo <- lpls(X1,X2,X3, ncomp = 2, type = \"endo\") # Predict X1 from X2 and X3 (in this case fitted values): pred.endo.X1 <- predict(lp.endo, X2new = X2, X3new = X3)  # LOO cross-validation horizontally lp.cv1 <- lplsCV(lp.exo, segments1 = as.list(1:dim(X1)[1])) #> Segment 1 of 30 completed #> Segment 2 of 30 completed #> Segment 3 of 30 completed #> Segment 4 of 30 completed #> Segment 5 of 30 completed #> Segment 6 of 30 completed #> Segment 7 of 30 completed #> Segment 8 of 30 completed #> Segment 9 of 30 completed #> Segment 10 of 30 completed #> Segment 11 of 30 completed #> Segment 12 of 30 completed #> Segment 13 of 30 completed #> Segment 14 of 30 completed #> Segment 15 of 30 completed #> Segment 16 of 30 completed #> Segment 17 of 30 completed #> Segment 18 of 30 completed #> Segment 19 of 30 completed #> Segment 20 of 30 completed #> Segment 21 of 30 completed #> Segment 22 of 30 completed #> Segment 23 of 30 completed #> Segment 24 of 30 completed #> Segment 25 of 30 completed #> Segment 26 of 30 completed #> Segment 27 of 30 completed #> Segment 28 of 30 completed #> Segment 29 of 30 completed #> Segment 30 of 30 completed  # LOO cross-validation vertically lp.cv2 <- lplsCV(lp.exo, segments2 = as.list(1:dim(X1)[2])) #> Segment 1 of 20 completed #> Segment 2 of 20 completed #> Segment 3 of 20 completed #> Segment 4 of 20 completed #> Segment 5 of 20 completed #> Segment 6 of 20 completed #> Segment 7 of 20 completed #> Segment 8 of 20 completed #> Segment 9 of 20 completed #> Segment 10 of 20 completed #> Segment 11 of 20 completed #> Segment 12 of 20 completed #> Segment 13 of 20 completed #> Segment 14 of 20 completed #> Segment 15 of 20 completed #> Segment 16 of 20 completed #> Segment 17 of 20 completed #> Segment 18 of 20 completed #> Segment 19 of 20 completed #> Segment 20 of 20 completed  # Three-fold CV, horizontal lp.cv3 <- lplsCV(lp.exo, segments1 = as.list(1:10, 11:20, 21:30)) #> Segment 1 of 10 completed #> Segment 2 of 10 completed #> Segment 3 of 10 completed #> Segment 4 of 10 completed #> Segment 5 of 10 completed #> Segment 6 of 10 completed #> Segment 7 of 10 completed #> Segment 8 of 10 completed #> Segment 9 of 10 completed #> Segment 10 of 10 completed"},{"path":"https://khliland.github.io/multiblock/reference/maage.html","id":null,"dir":"Reference","previous_headings":"","what":"Måge plot — maage","title":"Måge plot — maage","text":"Måge plot -PLS (sopls) cross-validation visualisation.","code":""},{"path":"https://khliland.github.io/multiblock/reference/maage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Måge plot — maage","text":"","code":"maage(   object,   expl_var = TRUE,   pure.trace = FALSE,   pch = 20,   xlab = \"# components\",   ylab = ifelse(expl_var, \"Explained variance (%)\", \"RMSECV\"),   xlim = NULL,   ylim = NULL,   cex.text = 0.8,   ... )  maageSeq(   object,   compSeq = TRUE,   expl_var = TRUE,   pch = 20,   xlab = \"# components\",   ylab = ifelse(expl_var, \"Explained variance (%)\", \"RMSECV\"),   xlim = NULL,   ylim = NULL,   cex.text = 0.8,   col = \"gray\",   col.block = c(\"red\", \"blue\", \"darkgreen\", \"purple\", \"black\", \"red\", \"blue\",     \"darkgreen\"),   ... )"},{"path":"https://khliland.github.io/multiblock/reference/maage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Måge plot — maage","text":"object -PLS model (sopls object) expl_var Logical indicating explained variance (default) RMSECV displayed. pure.trace Logical indicating single block solutions traced plot. pch Scalar symbol giving plot symbol. xlab Label x-axis. ylab Label y-axis. xlim Plot limits x-axis (numeric vector). ylim Plot limits y-axis (numeric vector). cex.text Text scaling (scalar) better readability plots. ... Additional arguments plot. compSeq Integer vector giving sequence previous components chosen maageSeq (see example). col Line colour plot. col.block Line colours blocks (default = c('red','blue','darkgreen','purple','black'))","code":""},{"path":"https://khliland.github.io/multiblock/reference/maage.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Måge plot — maage","text":"maage plot return.","code":""},{"path":"https://khliland.github.io/multiblock/reference/maage.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Måge plot — maage","text":"function can either used global optimisation across blocks sequential optimisation, using maageSeq. examples show typical usage.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/maage.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Måge plot — maage","text":"","code":"data(wine) ncomp <- unlist(lapply(wine, ncol))[-5] so.wine <- sopls(`Global quality` ~ ., data=wine, ncomp=ncomp,              max_comps=10, validation=\"CV\", segments=10) maage(so.wine)   # Sequential search for optimal number of components per block old.par <- par(mfrow=c(2,2), mar=c(3,3,0.5,1), mgp=c(2,0.7,0)) maageSeq(so.wine) maageSeq(so.wine, 2) maageSeq(so.wine, c(2,1)) maageSeq(so.wine, c(2,1,1))  par(old.par)"},{"path":"https://khliland.github.io/multiblock/reference/mbpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiblock Partial Least Squares - MB-PLS — mbpls","title":"Multiblock Partial Least Squares - MB-PLS — mbpls","text":"function computing MB-PLS scores, loadings, etc. super-level block-level.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mbpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiblock Partial Least Squares - MB-PLS — mbpls","text":"","code":"mbpls(   formula,   data,   subset,   na.action,   X = NULL,   Y = NULL,   ncomp = 1,   scale = FALSE,   blockScale = c(\"sqrtnvar\", \"ssq\", \"none\"),   ... )"},{"path":"https://khliland.github.io/multiblock/reference/mbpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiblock Partial Least Squares - MB-PLS — mbpls","text":"formula Model formula accepting single response (block) predictor block names separated + signs. data data set analyse. subset Expression subsetting data modelling. na.action handle NAs (action implemented). X list input blocks. X supplied, formula interface skipped. Y matrix responses. ncomp integer number PLS components. scale logical autoscaling inputs (default = FALSE). blockScale Either character indicating type block scaling numeric vector block weights (see Details). ... additional arguments pls::plsr.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mbpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiblock Partial Least Squares - MB-PLS — mbpls","text":"multiblock, mvr object super-scores, super-loadings, block-scores block-loading, underlying mvr (PLS) object super model, result plot possibilities. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mbpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiblock Partial Least Squares - MB-PLS — mbpls","text":"MB-PLS prototypical component based supervised multiblock method. originally formulated two-level method block-level super-level, later discovered expressed ordinary PLS concatenated weighted X blocks followed simple loop calculating block-level loading weights, loadings scores. implementation uses plsr function scaled input blocks (1/sqrt(ncol)) enabling summaries plots pls package. Block weighting performed scaling variables default \"sqrtnvar\": 1/sqrt(ncol(X[[]])) block. Alternatives \"ssq\": 1/norm(X[[]], \"F\")^2 \"none\": 1/1. Finally, numeric vector supplied, used scale blocks \"ssq\" scaling, .e., Z[[]] = X[[]] / norm(X[[]], \"F\")^2 * blockScale[].","code":""},{"path":"https://khliland.github.io/multiblock/reference/mbpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multiblock Partial Least Squares - MB-PLS — mbpls","text":"Wangen, L.E. Kowalski, B.R. (1988). multiblock partial least squares algorithm investigating complex chemical systems. Journal Chemometrics, 3, 3–20. Westerhuis, J.., Kourti, T., MacGregor,J.F. (1998). Analysis multiblock hierarchical PCA PLS models. Journal Chemometrics, 12, 301–321.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/mbpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiblock Partial Least Squares - MB-PLS — mbpls","text":"","code":"data(potato) # Formula interface mb <- mbpls(Sensory ~ Chemical+Compression, data=potato, ncomp = 5)  # ... or X and Y mb.XY <- mbpls(X=potato[c('Chemical','Compression')], Y=potato[['Sensory']], ncomp = 5) identical(mb$scores, mb.XY$scores) #> [1] TRUE print(mb) #> Multiblock PLS  #>  #> Call: #> mbpls(formula = Sensory ~ Chemical + Compression, data = potato,     ncomp = 5) scoreplot(mb, labels=\"names\") # Exploiting mvr object structure from pls package   # Block scaling with emphasis on first block mbs <- mbpls(Sensory ~ Chemical+Compression, data=potato, ncomp = 5, blockScale = c(10, 1)) scoreplot(mbs, labels=\"names\") # Exploiting mvr object structure from pls package"},{"path":"https://khliland.github.io/multiblock/reference/mbrda.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiblock Redundancy Analysis - mbRDA — mbrda","title":"Multiblock Redundancy Analysis - mbRDA — mbrda","text":"wrapper ade4::mbpcaiv function computing mbRDA.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mbrda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiblock Redundancy Analysis - mbRDA — mbrda","text":"","code":"mbrda(formula, data, subset, na.action, X = NULL, Y = NULL, ncomp = 1, ...)"},{"path":"https://khliland.github.io/multiblock/reference/mbrda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiblock Redundancy Analysis - mbRDA — mbrda","text":"formula Model formula accepting single response (block) predictor block names separated + signs. data data set analyse. subset Expression subsetting data modelling. na.action handle NAs (action implemented). X list input blocks. Y matrix responses. ncomp integer number PLS components. ... additional arguments ade4::mbpcaiv.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mbrda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiblock Redundancy Analysis - mbRDA — mbrda","text":"multiblock, mvr object scores, block-scores block-loading. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mbrda.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiblock Redundancy Analysis - mbRDA — mbrda","text":"mbRDA multiblock formulation Redundancy (Data) Analysis. RDA theoretically PLS GCA. Like GCA, RDA consider correlations within X, like PLS consider correlations within Y. RDA can also viewed PCR Y constrained scores also linear combinations X. adegraphics package attached, nice overview can plotted plot(mbr$mbpcaiv) following example .","code":""},{"path":"https://khliland.github.io/multiblock/reference/mbrda.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multiblock Redundancy Analysis - mbRDA — mbrda","text":"Bougeard, S., Qannari, E.M., Lupo, C., andHanafi, M. (2011). Multiblock Partial Least Squares Multiblock Redundancy Analysis. Continuum Approach. Informatica, 22(1), 11–26.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/mbrda.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiblock Redundancy Analysis - mbRDA — mbrda","text":"","code":"# Convert data.frame with AsIs objects to list of matrices data(potato) potatoList <- lapply(potato, unclass)  mbr <- mbrda(Sensory ~ Chemical + Compression, data = potatoList, ncomp = 10) mbr.XY <- mbrda(X = potatoList[c('Chemical','Compression')], Y = potatoList[['Sensory']],                  ncomp = 10) print(mbr) #> Multiblock RDA  #>  #> Call: #> mbrda(formula = Sensory ~ Chemical + Compression, data = potatoList,     ncomp = 10) scoreplot(mbr) # Exploiting mvr object structure from pls package"},{"path":"https://khliland.github.io/multiblock/reference/mcoa.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple Co-Inertia Analysis - MCOA — mcoa","title":"Multiple Co-Inertia Analysis - MCOA — mcoa","text":"wrapper RGCCA::rgcca function computing MCOA.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mcoa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple Co-Inertia Analysis - MCOA — mcoa","text":"","code":"mcoa(X, ncomp = 2, scale = FALSE, verbose = FALSE, ...)"},{"path":"https://khliland.github.io/multiblock/reference/mcoa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple Co-Inertia Analysis - MCOA — mcoa","text":"X list input blocks. ncomp integer number components extract. scale logical indicating variables scaled. verbose logical indicating diagnostic information printed. ... additional arguments RGCCA.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mcoa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiple Co-Inertia Analysis - MCOA — mcoa","text":"multiblock object including relevant scores loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mcoa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiple Co-Inertia Analysis - MCOA — mcoa","text":"MCOA resembles GCA MFA creates set reference scores, block's individual scores correlate maximally , also variance within block taken account. single component solution equivalent PCA concatenated blocks scaled called inverse inertia.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mcoa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multiple Co-Inertia Analysis - MCOA — mcoa","text":"Le Roux; B. H. Rouanet (2004). Geometric Data Analysis, Correspondence Analysis Structured Data Analysis. Dordrecht. Kluwer: p.180. Greenacre, Michael Blasius, Jörg (editors) (2006). Multiple Correspondence Analysis Related Methods. London: Chapman & Hall/CRC.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/mcoa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple Co-Inertia Analysis - MCOA — mcoa","text":"","code":"data(potato) potList <- as.list(potato[c(1,2,9)]) pot.mcoa   <- mcoa(potList) plot(scores(pot.mcoa), labels=\"names\")"},{"path":"https://khliland.github.io/multiblock/reference/mcolors.html","id":null,"dir":"Reference","previous_headings":"","what":"Colour palette generation from matrix of RGB values — mcolors","title":"Colour palette generation from matrix of RGB values — mcolors","text":"Colour palette generation matrix RGB values","code":""},{"path":"https://khliland.github.io/multiblock/reference/mcolors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Colour palette generation from matrix of RGB values — mcolors","text":"","code":"mcolors(   n,   colmatrix = matrix(c(0, 0, 1, 1, 1, 1, 1, 0, 0), 3, 3, byrow = TRUE) )"},{"path":"https://khliland.github.io/multiblock/reference/mcolors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Colour palette generation from matrix of RGB values — mcolors","text":"n Integer number colorus produce. colmatrix numeric matrix three columns (R,G,B) generate colour palette .","code":""},{"path":"https://khliland.github.io/multiblock/reference/mcolors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Colour palette generation from matrix of RGB values — mcolors","text":"vector n colours hexadecimal RGB format.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mcolors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Colour palette generation from matrix of RGB values — mcolors","text":"","code":"mcolors(5) #> [1] \"#0000FF\" \"#8080FF\" \"#FFFFFF\" \"#FF8080\" \"#FF0000\""},{"path":"https://khliland.github.io/multiblock/reference/mfa.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple Factor Analysis - MFA — mfa","title":"Multiple Factor Analysis - MFA — mfa","text":"wrapper FactoMineR::MFA function computing MFA.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mfa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple Factor Analysis - MFA — mfa","text":"","code":"mfa(X, type = rep(\"c\", length(X)), graph = FALSE, ...)"},{"path":"https://khliland.github.io/multiblock/reference/mfa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple Factor Analysis - MFA — mfa","text":"X list input blocks. type character vector indicating block types, defaults rep(\"c\", length(X)) continuous values. graph logical indicating decomposition plotted. ... additional arguments RGCCA approach.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mfa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiple Factor Analysis - MFA — mfa","text":"multiblock object including relevant scores loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mfa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiple Factor Analysis - MFA — mfa","text":"MFA methods typically used compare several equally sized matrices. often used sensory analyses, matrices consist sensory characteristics products, assessor generates one matrix . basic form, MFA scales matrices largest eigenvalue, concatenates performs PCA result. several possibilities plots inspections model, handling categorical continuous inputs etc. connected MFA.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mfa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multiple Factor Analysis - MFA — mfa","text":"Pagès, J. (2005). Collection analysis perceived product inter-distances using multiple factor analysis: Application study 10 white wines Loire valley. Food Quality Preference, 16(7), 642–649.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/mfa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple Factor Analysis - MFA — mfa","text":"","code":"data(potato) potList <- as.list(potato[c(1,2,9)]) pot.mfa    <- mfa(potList) if(interactive()){   plot(pot.mfa$MFA) }"},{"path":"https://khliland.github.io/multiblock/reference/mobile.html","id":null,"dir":"Reference","previous_headings":"","what":"ECSI Mobile Mobile Phone Provider Dataset — mobile","title":"ECSI Mobile Mobile Phone Provider Dataset — mobile","text":"Mobile data questionnaire often used example path modelling. items scaled 1 10. Score 1 expresses negative point view product score 10 positive opinion. details, see original publication.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mobile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ECSI Mobile Mobile Phone Provider Dataset — mobile","text":"","code":"data(mobile)"},{"path":"https://khliland.github.io/multiblock/reference/mobile.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"ECSI Mobile Mobile Phone Provider Dataset — mobile","text":"data.frame 250 rows 7 variables: Image B Customer expectation C Perceived quality D Perceived value E Customer satisfaction F Customer complaints G Customer loyalty","code":""},{"path":"https://khliland.github.io/multiblock/reference/mobile.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ECSI Mobile Mobile Phone Provider Dataset — mobile","text":"Tenenhaus M, Esposito Vinzi V, Chatelin YM, Lauro C. PLS path modeling. Comput Stat Data Anal. 2005;48(1):159‐205.","code":""},{"path":"https://khliland.github.io/multiblock/reference/multiblock.html","id":null,"dir":"Reference","previous_headings":"","what":"multiblock — multiblock","title":"multiblock — multiblock","text":"collection methods analysis data sets two blocks data. Unsupervised methods: SCA - Simultaneous Component Analysis (sca) GCA - Generalized Canonical Analysis (gca) GPA - Generalized Procrustes Analysis (gpa) MFA - Multiple Factor Analysis (mfa) PCA-GCA (pcagca) DISCO - Distinctive Common Components SCA (disco) HPCA - Hierarchical Principal component analysis (hpca) MCOA - Multiple Co-Inertia Analysis (mcoa) JIVE - Joint Individual Variation Explained (jive) STATIS - Structuration des Tableaux à Trois Indices de la Statistique (statis) HOGSVD - Higher Order Generalized SVD (hogsvd) Design based methods: ASCA - Anova Simultaneous Component Analysis (asca) Supervised methods: MB-PLS - Multiblock Partial Least Squares (mbpls) sMB-PLS - Sparse Multiblock Partial Least Squares (smbpls) -PLS - Sequential Orthogonalized PLS (sopls) PO-PLS - Parallel Orthogonalized PLS (popls) ROSA - Response Oriented Sequential Alternation (rosa) mbRDA - Multiblock Redundancy Analysis (mbrda) Complex methods: L-PLS - Partial Least Squares L configuration (lpls) -PLS-PM - Sequential Orthogonalised PLS Path Modelling (sopls_pm) Single- two-block methods: PCA - Principal Component Analysis (pca) PCR - Principal Component Regression (pcr) PLSR - Partial Least Squares Regression (plsr) CCA - Canonical Correlation Analysis (cca) IFA - Interbattery Factor Analysis (ifa) GSVD - Generalized SVD (gsvd) Datasets: Sensory assessment candies (candies) Sensory, rheological, chemical spectroscopic analysis potatoes (potato) Data simulated certain characteristics (simulated) Wines Val de Loire (wine) Utility functions: Block-wise indexable data.frame (block.data.frame) Dummy-code vector (dummycode)","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/multiblock.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"multiblock — multiblock","text":"Maintainer: Kristian Hovde Liland kristian.liland@nmbu.(ORCID) contributors: Solve Sæbø [contributor] Stefan Schrunner [reviewer]","code":""},{"path":"https://khliland.github.io/multiblock/reference/multiblock_plots.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Functions for Multiblock Objects — multiblock_plots","title":"Plot Functions for Multiblock Objects — multiblock_plots","text":"Plotting procedures multiblock objects.","code":""},{"path":"https://khliland.github.io/multiblock/reference/multiblock_plots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Functions for Multiblock Objects — multiblock_plots","text":"","code":"# S3 method for class 'multiblock' scoreplot(   object,   comps = 1:2,   block = 0,   labels,   identify = FALSE,   type = \"p\",   xlab,   ylab,   main,   ... )  # S3 method for class 'multiblock' loadingplot(   object,   comps = 1:2,   block = 0,   scatter = TRUE,   labels,   identify = FALSE,   type,   lty,   lwd = NULL,   pch,   cex = NULL,   col,   legendpos,   xlab,   ylab,   main,   pretty.xlabels = TRUE,   xlim,   ... )  loadingweightplot(object, main = \"Loading weights\", ...)  # S3 method for class 'multiblock' biplot(   x,   block = 0,   comps = 1:2,   which = c(\"x\", \"y\", \"scores\", \"loadings\"),   var.axes = FALSE,   xlabs,   ylabs,   main,   ... )  corrplot(object, ...)  # Default S3 method corrplot(object, ...)  # S3 method for class 'mvr' corrplot(object, ...)  # S3 method for class 'multiblock' corrplot(   object,   comps = 1:2,   labels = TRUE,   col = 1:5,   plotx = TRUE,   ploty = TRUE,   blockScores = FALSE,   ... )"},{"path":"https://khliland.github.io/multiblock/reference/multiblock_plots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Functions for Multiblock Objects — multiblock_plots","text":"object multiblock object. comps integer vector giving components, within block, plot. block integer/character block selection. labels character indicating \"names\" \"numbers\" plot symbols (optional). identify logical activating identify interactively identify points. type character selecting type plot make. Defaults \"p\" (points) scatter plots \"l\" (lines) line plots. xlab character text x labels. ylab character text y labels. main character text main header. ... implemented. scatter logical indicating scatterplot loadings made (default = TRUE). lty Vector line type specifications (see par details). lwd numeric vector line width specifications. pch Vector point specifications (see points details). cex numeric vector plot size expansions (see par details). col integer vector symbol/line colours (see par details). legendpos character indicating legend position (scatter FALSE), e.g. legendpos = \"topright\". pretty.xlabels logical indicating xlabels nicely plotted (default = TRUE). xlim numeric vector length two, x limits plot (optional). x multiblock object. character selecting type biplot (\"x\" = default, \"y\", \"scores\", \"loadings\"). var.axes logical indicating second axes biplot arrows. xlabs character vector labelling first set biplot points (optional). ylabs character vector labelling second set biplot points (optional). plotx locical integer/character.  Whether plot \\(X\\) correlation loadings, optionally block(s). Defaults TRUE. ploty logical.  Whether plot \\(Y\\) correlation loadings. Defaults TRUE. blockScores logical. Correlation loadings blockScores (default = FALSE).","code":""},{"path":"https://khliland.github.io/multiblock/reference/multiblock_plots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Functions for Multiblock Objects — multiblock_plots","text":"plotting routines generate plots return values.","code":""},{"path":"https://khliland.github.io/multiblock/reference/multiblock_plots.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Functions for Multiblock Objects — multiblock_plots","text":"Plot functions scores, loadings loading.weights based functions found pls package.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/multiblock_plots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Functions for Multiblock Objects — multiblock_plots","text":"","code":"data(wine) sc <- sca(wine[c('Smell at rest', 'View', 'Smell after shaking')], ncomp = 4) loadingplot(sc, block = 1, labels = \"names\", scatter = TRUE)  scoreplot(sc, labels = \"names\")  corrplot(sc)   data(potato) so <- sopls(Sensory ~ NIRraw + Chemical + Compression, data=potato, ncomp = c(2,2,2),              max_comps = 6, validation = \"CV\", segments = 10) scoreplot(so, ncomp = c(2,1), block = 3, labels = \"names\")  corrplot(pcp(so, ncomp = c(2,2,2)))"},{"path":"https://khliland.github.io/multiblock/reference/multiblock_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Result Functions for Multiblock Objects — multiblock_results","title":"Result Functions for Multiblock Objects — multiblock_results","text":"Standard result computation extraction functions multiblock objects.","code":""},{"path":"https://khliland.github.io/multiblock/reference/multiblock_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Result Functions for Multiblock Objects — multiblock_results","text":"","code":"# S3 method for class 'multiblock' scores(object, block = 0, ...)  # S3 method for class 'multiblock' loadings(object, block = 0, ...)  # S3 method for class 'multiblock' print(x, ...)  # S3 method for class 'multiblock' summary(object, ...)"},{"path":"https://khliland.github.io/multiblock/reference/multiblock_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result Functions for Multiblock Objects — multiblock_results","text":"object multiblock object. block integer/character block selection. ... implemented. x multiblock object.","code":""},{"path":"https://khliland.github.io/multiblock/reference/multiblock_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Result Functions for Multiblock Objects — multiblock_results","text":"Scores loadings returned scores.multiblock loadings.multiblock, print summary methods invisibly returns object.","code":""},{"path":"https://khliland.github.io/multiblock/reference/multiblock_results.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Result Functions for Multiblock Objects — multiblock_results","text":"Usage functions shown using generics examples . Object printing summary available : print.multiblock summary.multiblock. Scores loadings extensions scores() loadings() throught scores.multiblock loadings.multiblock.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/multiblock_results.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Result Functions for Multiblock Objects — multiblock_results","text":"","code":"data(wine) sc <- sca(wine[c('Smell at rest', 'View', 'Smell after shaking')], ncomp = 4) print(sc) #> Simultaneous Component Analysis  #>  #> Call: #> sca(X = wine[c(\"Smell at rest\", \"View\", \"Smell after shaking\")],     ncomp = 4) summary(sc) #> Simultaneous Component Analysis  #> ===============================  #>  #> $scores: Common scores (21x4) #> $blockLoadings: Block loadings: #> - Smell at rest (5x4), View (3x4), Smell after shaking (10x4) head(loadings(sc, block = 1)) #>                                   Comp 1     Comp 2      Comp 3      Comp 4 #> Odor Intensity before shaking 0.19548267 -0.3267557  0.50138779 -0.09348863 #> Aroma quality before shaking  0.16311889  0.1296282  0.28552072  0.14894779 #> Fruity before shaking         0.12978290  0.1773340  0.34890797  0.26269486 #> Flower before shaking         0.05514227  0.1048857 -0.02986196 -0.47929451 #> Spice before shaking          0.04176668 -0.4175496  0.07332530  0.04104202 head(scores(sc)) #>       Comp 1      Comp 2      Comp 3       Comp 4 #> 1  0.4048505  0.14408310 -0.26713729 -0.221396684 #> 2 -1.2711617  0.25270420 -0.02202010 -0.533496550 #> 3 -0.7036213  0.06526523 -0.11229055  0.078719372 #> 4 -2.0075068 -0.45716224 -0.08211518 -0.007645878 #> 5  1.0467680  0.25398203  0.52254058 -0.029381096 #> 6  0.6670676  0.15451746 -0.58710038  0.050253448"},{"path":"https://khliland.github.io/multiblock/reference/mvrVal.html","id":null,"dir":"Reference","previous_headings":"","what":"MSEP, RMSEP and R2 of the MB-PLS model — mvrVal","title":"MSEP, RMSEP and R2 of the MB-PLS model — mvrVal","text":"Functions estimate mean squared error prediction (MSEP), root mean squared error prediction (RMSEP) \\(R^2\\) (.K.. coefficient multiple determination) fitted MB-PLS models.  Test-set, cross-validation calibration-set estimates implemented.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mvrVal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MSEP, RMSEP and R2 of the MB-PLS model — mvrVal","text":"","code":"# S3 method for class 'mbpls' R2(   object,   estimate,   newdata,   ncomp = 1:object$ncomp,   comps,   intercept = TRUE,   se = FALSE,   ... )  # S3 method for class 'mbpls' MSEP(   object,   estimate,   newdata,   ncomp = 1:object$ncomp,   comps,   intercept = TRUE,   se = FALSE,   ... )  # S3 method for class 'mbpls' RMSEP(object, ...)"},{"path":"https://khliland.github.io/multiblock/reference/mvrVal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MSEP, RMSEP and R2 of the MB-PLS model — mvrVal","text":"object mvr object estimate character vector.  estimators use.  subset c(\"\", \"train\", \"CV\", \"adjCV\", \"test\").  \"adjCV\" available (R)MSEP.  See estimators chosen. newdata data frame test set data. ncomp, comps vector positive integers.  components number components use.  See . intercept logical.  Whether estimates model zero components returned well. se logical.  Whether estimated standard errors estimates calculated.  implemented yet. ... arguments sent underlying functions (RMSEP) MSEP","code":""},{"path":"https://khliland.github.io/multiblock/reference/mvrVal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MSEP, RMSEP and R2 of the MB-PLS model — mvrVal","text":"RMSEP simply calls MSEP takes square root estimates.  therefore accepts arguments MSEP. Several estimators can used.  \"train\" training calibration data estimate, also called (R)MSEC.  R2, unadjusted \\(R^2\\).  overoptimistic used assessing models.  \"CV\" cross-validation estimate, \"adjCV\" (RMSEP MSEP) bias-corrected cross-validation estimate.  can calculated model cross-validated.  Finally, \"test\" test set estimate, using newdata test set. estimators use decided follows (see pls:mvrValstats).  estimate specified, test set estimate returned newdata specified, otherwise CV adjusted CV (RMSEP MSEP) estimates model cross-validated, otherwise training data estimate.  estimate \"\", possible estimates calculated. Otherwise, specified estimates calculated. Several model sizes can also specified.  comps missing (NULL), length(ncomp) models used, ncomp[1] components, ..., ncomp[length(ncomp)] components.  Otherwise, single model components comps[1], ..., comps[length(comps)] used.  intercept TRUE, model zero components also used (addition ). \\(R^2\\) values returned \"R2\" calculated \\(1 - SSE/SST\\), \\(SST\\) (corrected) total sum squares response, \\(SSE\\) sum squared errors either fitted values (.e., residual sum squares), test set predictions cross-validated predictions (.e., \\(PRESS\\)).  estimate = \"train\", equivalent squared correlation fitted values response.  estimate = \"train\", estimate often called prediction \\(R^2\\). mvrValstats utility function calculates statistics needed MSEP R2.  intended used interactively.  accepts arguments MSEP R2. However, estimate argument must specified explicitly: partial matching automatic choice made.  function simply calculates types estimates knows, leaves untouched.","code":""},{"path":"https://khliland.github.io/multiblock/reference/mvrVal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MSEP, RMSEP and R2 of the MB-PLS model — mvrVal","text":"mvrValstats returns list components SSE three-dimensional array SSE values.  first dimension different estimators, second response variables third models. SST matrix SST values.  first dimension different estimators second response variables. nobj numeric vector giving number objects used estimator. comps components specified, 0 prepended intercept TRUE. cumulative TRUE comps NULL specified. functions return object class \"mvrVal\", components val three-dimensional array estimates.  first dimension different estimators, second response variables third models. type \"MSEP\", \"RMSEP\" \"R2\". comps components specified, 0 prepended intercept TRUE. cumulative TRUE comps NULL specified. call function call","code":""},{"path":"https://khliland.github.io/multiblock/reference/mvrVal.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"MSEP, RMSEP and R2 of the MB-PLS model — mvrVal","text":"Mevik, B.-H., Cederkvist, H. R. (2004) Mean Squared Error Prediction (MSEP) Estimates Principal Component Regression (PCR) Partial Least Squares Regression (PLSR).  Journal Chemometrics, 18(9), 422–429.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/mvrVal.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"MSEP, RMSEP and R2 of the MB-PLS model — mvrVal","text":"Kristian Hovde Liland","code":""},{"path":"https://khliland.github.io/multiblock/reference/mvrVal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MSEP, RMSEP and R2 of the MB-PLS model — mvrVal","text":"","code":"data(oliveoil, package = \"pls\") mod <- pls::plsr(sensory ~ chemical, ncomp = 4, data = oliveoil, validation = \"LOO\") RMSEP(mod) #>  #> Response: yellow  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV            20.1    18.97    16.10    16.71    18.11 #> adjCV         20.1    18.91    16.03    16.61    17.93 #>  #> Response: green  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV           24.26    23.88    20.45    21.35    23.96 #> adjCV        24.26    23.80    20.35    21.20    23.70 #>  #> Response: brown  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV           5.297    4.019    3.987    3.987    4.107 #> adjCV        5.297    3.990    3.955    3.947    4.050 #>  #> Response: glossy  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV           6.391    5.109    5.161    5.571    6.446 #> adjCV        6.391    5.087    5.129    5.522    6.363 #>  #> Response: transp  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV            8.58    7.258    7.158    7.665    8.794 #> adjCV         8.58    7.232    7.118    7.607    8.691 #>  #> Response: syrup  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV           3.166    2.134    2.325    2.478    2.939 #> adjCV        3.166    2.128    2.310    2.458    2.901 if (FALSE) plot(R2(mod)) # \\dontrun{}"},{"path":"https://khliland.github.io/multiblock/reference/pca.html","id":null,"dir":"Reference","previous_headings":"","what":"Principal Component Analysis - PCA — pca","title":"Principal Component Analysis - PCA — pca","text":"wrapper pls::PCR function computing PCA.","code":""},{"path":"https://khliland.github.io/multiblock/reference/pca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Principal Component Analysis - PCA — pca","text":"","code":"pca(X, scale = FALSE, ncomp = 1, ...)"},{"path":"https://khliland.github.io/multiblock/reference/pca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Principal Component Analysis - PCA — pca","text":"X matrix input data. scale logical indicating variables standardised (default=FALSE). ncomp integer number principal components return. ... additional arguments pls:pcr.","code":""},{"path":"https://khliland.github.io/multiblock/reference/pca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Principal Component Analysis - PCA — pca","text":"multiblock object scores, loadings, mean X values explained variances. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/pca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Principal Component Analysis - PCA — pca","text":"PCA method decomposing matrix subspace components sample scores variable loadings. can formulated various ways, standard formulation uses singular value decomposition create scores loadings. PCA guaranteed optimal way extracting orthogonal subspaces matrix regard amount explained variance per component.","code":""},{"path":"https://khliland.github.io/multiblock/reference/pca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Principal Component Analysis - PCA — pca","text":"Pearson, K. (1901) lines planes closest fit points space. Philosophical Magazine, 2, 559–572.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/pca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Principal Component Analysis - PCA — pca","text":"","code":"data(potato) X <- potato$Chemical  pca.pot  <- pca(X, ncomp = 2)"},{"path":"https://khliland.github.io/multiblock/reference/pcagca.html","id":null,"dir":"Reference","previous_headings":"","what":"PCA-GCA — pcagca","title":"PCA-GCA — pcagca","text":"PCA-GCA methods aims estimating subspaces common, local distinct variation two blocks.","code":""},{"path":"https://khliland.github.io/multiblock/reference/pcagca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PCA-GCA — pcagca","text":"","code":"pcagca(   X,   commons = 2,   auto = TRUE,   auto.par = list(explVarLim = 40, rLim = 0.8),   manual.par = list(ncomp = 0, ncommon = 0),   tol = 10^-12 )"},{"path":"https://khliland.github.io/multiblock/reference/pcagca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PCA-GCA — pcagca","text":"X list input blocks commons numeric giving highest number blocks combine calculating local common scores. auto logical indicating automatic choice complexities used. auto.par named list setting limits automatic choice complexities. manual.par named list manual choice blocks. list consists ncomp indicates number components extract block ncommon corresponding choosing block combinations (local/common). latter, use unique_combos(n_blocks, commons) see order local/common blocks. Component numbers reduced simpler models give better predictions. See example. tol numeric tolerance component inclusion (singular values).","code":""},{"path":"https://khliland.github.io/multiblock/reference/pcagca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PCA-GCA — pcagca","text":"multiblock object including relevant scores loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results. Distinct components marked 'D(x), Comp c' block x component c local common components marked \"C(x1, x2), Comp c\", x1 x2 () block numbers.","code":""},{"path":"https://khliland.github.io/multiblock/reference/pcagca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PCA-GCA — pcagca","text":"name PCA-GCA comes process first applying PCA block, using GCA estimate local common components, finally orthogonalising block-wise scores local/common ones re-estimating obtain distinct components. procedure highly similar supervised method PO-PLS, PCA steps exchanged PLS.","code":""},{"path":"https://khliland.github.io/multiblock/reference/pcagca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"PCA-GCA — pcagca","text":"Smilde, ., Måge, ., Naes, T., Hankemeier, T.,Lips, M., Kiers, H., Acar, E., Bro, R.(2017). Common distinct components data fusion. Journal Chemometrics, 31(7), e2900.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/pcagca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PCA-GCA — pcagca","text":"","code":"data(potato) potList <- as.list(potato[c(1,2,9)]) pot.pcagca <- pcagca(potList) #> Warning: 'ncomp' reduced due to low singular value for block 2  # Show origin and type of all components lapply(pot.pcagca$blockScores,colnames) #> $Chemical #> NULL #>  #> $Compression #> [1] \"D(2), Comp 1\" #>  #> $Sensory #> [1] \"C(1,3), Comp 1\" #>   # Basic multiblock plot plot(scores(pot.pcagca, block=2), comps=1, labels=\"names\")"},{"path":"https://khliland.github.io/multiblock/reference/popls.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel and Orthogonalised Partial Least Squares - PO-PLS — popls","title":"Parallel and Orthogonalised Partial Least Squares - PO-PLS — popls","text":"basic implementation PO-PLS manual automatic component selections.","code":""},{"path":"https://khliland.github.io/multiblock/reference/popls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel and Orthogonalised Partial Least Squares - PO-PLS — popls","text":"","code":"popls(   X,   Y,   commons = 2,   auto = TRUE,   auto.par = list(explVarLim = 40, rLim = 0.8),   manual.par = list(ncomp = rep(0, length(X)), ncommon = list()) )"},{"path":"https://khliland.github.io/multiblock/reference/popls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel and Orthogonalised Partial Least Squares - PO-PLS — popls","text":"X list input blocks Y matrix response variable(s) commons numeric giving highest number blocks combine calculating local common scores. auto logical indicating automatic choice complexities used. auto.par named list setting limits automatic choice complexities. See Details. manual.par named list manual choice blocks. list consists ncomp indicates number components extract block ncommon corresponding choosing block combinations (local/common). latter, use unique_combos(n_blocks, commons) see order local/common blocks. Component numbers reduced simpler models give better predictions. See example.","code":""},{"path":"https://khliland.github.io/multiblock/reference/popls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parallel and Orthogonalised Partial Least Squares - PO-PLS — popls","text":"multiblock object block-wise, local common loadings scores. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/popls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parallel and Orthogonalised Partial Least Squares - PO-PLS — popls","text":"PO-PLS decomposes set input data blocks common, local distinct components process involving pls gca. rLim parameter lower bound GCA correlation building common components, explVarLim minimum explained variance common components unique components.","code":""},{"path":"https://khliland.github.io/multiblock/reference/popls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parallel and Orthogonalised Partial Least Squares - PO-PLS — popls","text":"Måge, BH Mevik, T Næs. (2008). Regression models process variables parallel blocks raw material measurements. Journal Chemometrics: Journal Chemometrics Society 22 (8), 443-456 Måge, E Menichelli, T Næs (2012). Preference mapping PO-PLS: Separating common unique information several data blocks. Food quality preference 24 (1), 8-16","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/popls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel and Orthogonalised Partial Least Squares - PO-PLS — popls","text":"","code":"data(potato)  # Automatic analysis pot.po.auto <- popls(potato[1:3], potato[['Sensory']][,1]) #> Warning: 'ncomp' reduced due to low singular value for block 1 #> Warning: 'ncomp' reduced due to low singular value for block 1 pot.po.auto$explVar #> $Chemical #> named numeric(0) #>  #> $Compression #> C(1,2), Comp 1  #>       68.14595  #>  #> $NIRraw #> D(3), Comp 1  #>     42.53836  #>   # Manual choice of up to 5 components for each block and 1, 0, and 2 blocks, # respectively from the (1,2), (1,3) and (2,3) combinations of blocks. pot.po.man <- popls(potato[1:3], potato[['Sensory']][,1], auto=FALSE,                  manual.par = list(ncomp=c(5,5,5), ncommon=c(1,0,2))) #> Warning: 'ncomp' reduced due to low singular value for block 1 #> Warning: 'ncomp' reduced due to low singular value for block 1 pot.po.man$explVar #> $Chemical #> C(1,2), Comp 1   D(1), Comp 1   D(1), Comp 2  #>       32.22944       20.74357       20.87956  #>  #> $Compression #> C(1,2), Comp 1 C(2,3), Comp 1 C(2,3), Comp 2  #>      68.145954       5.504006       7.214911  #>  #> $NIRraw #> C(2,3), Comp 1 C(2,3), Comp 2  #>      32.606459       5.475702  #>   # Score plot for local (2,3) components plot(scores(pot.po.man,3), comps=1:2, labels=\"names\")"},{"path":"https://khliland.github.io/multiblock/reference/potato.html","id":null,"dir":"Reference","previous_headings":"","what":"Sensory, rheological, chemical and spectroscopic analysis of potatoes. — potato","title":"Sensory, rheological, chemical and spectroscopic analysis of potatoes. — potato","text":"dataset containing 9 blocks measurements 26 potatoes. Original dataset can found http://models.life.ku.dk/Texture_Potatoes. version pre-processed follows (corresponding Liland et al. 2016): Variables containing NaN removed. Chemical Compression blocks scaled standard deviations. NIR blocks subjected SNV (Standard Normal Variate).","code":""},{"path":"https://khliland.github.io/multiblock/reference/potato.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sensory, rheological, chemical and spectroscopic analysis of potatoes. — potato","text":"","code":"data(potato)"},{"path":"https://khliland.github.io/multiblock/reference/potato.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sensory, rheological, chemical and spectroscopic analysis of potatoes. — potato","text":"data.frame 26 rows 9 variables: Chemical Matrix chemical measurements Compression Matrix rheological compression data NIRraw Matrix near-infrared measurements raw potatoes NIRcooked Matrix near-infrared measurements cooked potatoes CPMGraw Matrix NMR (CPMG) measurements raw potatoes CPMGcooked Matrix NMR (CPMG) measurements cooked potatoes FIDraw Matrix NMR (FID) measurements raw potatoes FIDcooked Matrix NMR (FID) measurements cooked potatoes Sensory Matrix sensory assessments","code":""},{"path":"https://khliland.github.io/multiblock/reference/potato.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sensory, rheological, chemical and spectroscopic analysis of potatoes. — potato","text":"L.G.Thygesen, .K.Thybo, S.B.Engelsen, Prediction Sensory Texture Quality Boiled Potatoes Low-field1H NMR Raw Potatoes. Role Chemical Constituents. LWT - Food Science Technology 34(7), 2001, pp 469-477. Kristian Hovde Liland, Tormod Næs, Ulf Geir Indahl, ROSA – fast extension Partial Least Squares Regression Multiblock Data Analysis, Journal Chemometrics 30:11 (2016), pp. 651-662.","code":""},{"path":"https://khliland.github.io/multiblock/reference/predict.mbpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict Method for MBPLS — predict.mbpls","title":"Predict Method for MBPLS — predict.mbpls","text":"Prediction mbpls (MBPLS) model. New responses scores predicted using fitted model data.frame list containing matrices observations.","code":""},{"path":"https://khliland.github.io/multiblock/reference/predict.mbpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict Method for MBPLS — predict.mbpls","text":"","code":"# S3 method for class 'mbpls' predict(   object,   newdata,   ncomp = 1:object$ncomp,   comps,   type = c(\"response\", \"scores\"),   na.action = na.pass,   ... )"},{"path":"https://khliland.github.io/multiblock/reference/predict.mbpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict Method for MBPLS — predict.mbpls","text":"object mvr object.  fitted model newdata data frame.  new data.  missing, training data used. ncomp, comps vector positive integers.  components use prediction.  See . type character.  Whether predict scores response values na.action function determining done missing values newdata.  default predict NA.  See na.omit alternatives. ... arguments.  Currently used","code":""},{"path":"https://khliland.github.io/multiblock/reference/predict.mbpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict Method for MBPLS — predict.mbpls","text":"type \"response\", three dimensional array predicted response values returned.  dimensions correspond observations, response variables model sizes, respectively. type \"scores\", score matrix returned.","code":""},{"path":"https://khliland.github.io/multiblock/reference/predict.mbpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict Method for MBPLS — predict.mbpls","text":"type \"response\" (default), predicted response values returned.  comps missing (NULL), predictions length(ncomp) models ncomp[1] components, ncomp[2] components, etc., returned.  Otherwise, predictions single model exact components comps returned. (Note cases, intercept always included predictions.  can removed subtracting Ymeans component fitted model.) type \"scores\", predicted score values returned components given comps.  comps missing NULL, ncomps used instead.","code":""},{"path":"https://khliland.github.io/multiblock/reference/predict.mbpls.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Predict Method for MBPLS — predict.mbpls","text":"warning message like 'newdata' 10 rows variable(s) found 106 rows means variables found newdata data frame.  (usually) happens formula contains terms like yarn$NIR.  use terms; use data argument instead.  See mvr details.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/predict.mbpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predict Method for MBPLS — predict.mbpls","text":"Kristian Hovde Liland","code":""},{"path":"https://khliland.github.io/multiblock/reference/predict.mbpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict Method for MBPLS — predict.mbpls","text":"","code":"data(potato) mb <- mbpls(Sensory ~ Chemical+Compression, data=potato, ncomp = 5, subset = 1:26 <= 18) testdata <- subset(potato, 1:26 > 18)  # Predict response yhat <- predict(mb, newdata = testdata)  # Predict scores and plot scores <- predict(mb, newdata = testdata, type = \"scores\") scoreplot(mb) points(scores[,1], scores[,2], col=\"red\") legend(\"topright\", legend = c(\"training\", \"test\"), col=1:2, pch = 1)"},{"path":"https://khliland.github.io/multiblock/reference/preprocess.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocessing of block data — preprocess","title":"Preprocessing of block data — preprocess","text":"interface simplify preprocessing one, subset blocks multiblock object, e.g., data.frame (see block.data.frame) list. Several standard preprocessing methods supplied addition letting user supply function.","code":""},{"path":"https://khliland.github.io/multiblock/reference/preprocess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocessing of block data — preprocess","text":"","code":"block.preprocess(   X,   block = 1:length(X),   fun = c(\"autoscale\", \"center\", \"scale\", \"SNV\", \"EMSC\", \"Fro\", \"FroSq\", \"SingVal\"),   ... )"},{"path":"https://khliland.github.io/multiblock/reference/preprocess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocessing of block data — preprocess","text":"X data.frame list data. block vector block(s) preprocess (integers characters). fun character function selecting preprocessing apply (see Details). ... additional arguments underlying functions.","code":""},{"path":"https://khliland.github.io/multiblock/reference/preprocess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocessing of block data — preprocess","text":"input multiblock object preprocessed returned.","code":""},{"path":"https://khliland.github.io/multiblock/reference/preprocess.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preprocessing of block data — preprocess","text":"fun parameter controls type preprocessing performed: autoscale: centre scale feature/variable. center: centre feature/variable. scale: scale feature/variable. SNV: Standard Normal Variate correction, .e., centre scale sample across features/variables. EMSC: Extended Multiplicative Signal Correction defaulting basic EMSC (2nd order polynomials). parameters sent EMSC::EMSC. Fro: Frobenius norm scaling whole block. FroSq: Squared Frobenius norm scaling whole block (sum squared values). SingVal: Singular value scaling whole block (first singular value). User defined: function supplied, applied chosen blocks. Preprocessing can done blocks subset. can also done series operations combine preprocessing techniques.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/preprocess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocessing of block data — preprocess","text":"","code":"data(potato) # Autoscale Chemical block potato <- block.preprocess(potato, block = \"Chemical\", \"autoscale\") # Apply SNV to NIR blocks potato <- block.preprocess(potato, block = 3:4, \"SNV\") # Centre Sensory block potato <- block.preprocess(potato, block = \"Sensory\", \"center\") # Scale all blocks to unit Frobenius norm potato <- block.preprocess(potato, fun = \"Fro\")  # Effect of SNV NIR <- (potato$NIRraw + rnorm(26)) * rnorm(26,1,0.2) NIRc <- block.preprocess(list(NIR), fun = \"SNV\")[[1]] old.par <- par(mfrow = c(2,1), mar = c(4,4,1,1)) matplot(t(NIR), type=\"l\", main = \"uncorrected\", ylab = \"\") matplot(t(NIRc), type=\"l\", main = \"corrected\", ylab = \"\")  par(old.par)"},{"path":"https://khliland.github.io/multiblock/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. HDANOVA asca, loadingplot, permutationplot, scoreplot, timeplot pls coefplot, cvsegments, loading.weights, loadingplot, loadings, MSEP, mvrValstats, pcr, plsr, predplot, R2, RMSEP, scoreplot, scores, validationplot","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa.html","id":null,"dir":"Reference","previous_headings":"","what":"Response Oriented Sequential Alternation - ROSA — rosa","title":"Response Oriented Sequential Alternation - ROSA — rosa","text":"Formula based interface ROSA algorithm following style pls package.","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Response Oriented Sequential Alternation - ROSA — rosa","text":"","code":"rosa(   formula,   ncomp,   Y.add,   common.comp = 1,   data,   subset,   na.action,   scale = FALSE,   weights = NULL,   validation = c(\"none\", \"CV\", \"LOO\"),   internal.validation = FALSE,   fixed.block = NULL,   design.block = NULL,   canonical = TRUE,   ... )"},{"path":"https://khliland.github.io/multiblock/reference/rosa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Response Oriented Sequential Alternation - ROSA — rosa","text":"formula Model formula accepting single response (block) predictor block names separated + signs. ncomp maximum number ROSA components. Y.add Optional response(s) available data set. common.comp Automatically create combinations common components length common.comp (default = 1). data data set analyse. subset Expression subsetting data modelling. na.action handle NAs (action implemented). scale Optionally scale predictor variables individual standard deviations. weights Optional object weights. validation Optional cross-validation strategy \"CV\" \"LOO\". internal.validation Optional cross-validation block selection process, \"LOO\", \"CV3\", \"CV5\", \"CV10\" (CV-number segments), vector integers (default = FALSE). fixed.block integer vector block numbers component (0 = fixed) list length <= ncomp (element length 0 = fixed). design.block integer vector containing block numbers design blocks canonical logical indicating canonical correlation use calculating loading weights (default), enabling B/W maximization, common components, etc. Alternatively (FALSE) PLS2 strategy, e.g. spectra response, used. ... Additional arguments cvseg rosa.fit","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Response Oriented Sequential Alternation - ROSA — rosa","text":"object classes rosa mvr several associated printing (rosa_results) plotting methods (rosa_plots).","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Response Oriented Sequential Alternation - ROSA — rosa","text":"ROSA opportunistic method sequentially selecting components whichever block explains response effectively. can formulated PLS model concatenated input block block selection per component. implementation adds several options described literature. importantly, opens internal validation block selection process, making robust. addition handles design blocks explicitly, enables classification secondary responses (CPLS), definition common components.","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Response Oriented Sequential Alternation - ROSA — rosa","text":"Liland, K.H., Næs, T., Indahl, U.G. (2016). ROSA - fast extension partial least squares regression multiblock data analysis. Journal Chemometrics, 30, 651–662, doi:10.1002/cem.2824.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/rosa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Response Oriented Sequential Alternation - ROSA — rosa","text":"","code":"data(potato) mod <- rosa(Sensory[,1] ~ ., data = potato, ncomp = 10, validation = \"CV\", segments = 5) summary(mod) #> Data: \tX dimension: 26 3946  #> \tY dimension: 26 1 #> Fit method: #> Number of components considered: 10 #>  #> VALIDATION: RMSEP #> Cross-validated using 5 random segments. #>        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps #> CV           1.778   1.0003    0.869   0.5666   0.5506   0.5227   0.5370 #> adjCV        1.778   0.9597    0.822   0.5459   0.5224   0.4912   0.5014 #>        7 comps  8 comps  9 comps  10 comps #> CV      0.5607   0.6254   0.6578    0.7528 #> adjCV   0.5186   0.5747   0.6001    0.6875 #>  #> TRAINING: % variance explained #>               1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps #> X               27.82    40.72    47.95    49.48    53.96    55.28    57.79 #> Sensory[, 1]    76.54    86.77    94.07    96.47    97.03    97.49    97.83 #>               8 comps  9 comps  10 comps #> X               65.49    67.14     68.16 #> Sensory[, 1]    98.03    98.28     98.51  # For examples of ROSA results and plotting see  # ?rosa_results and ?rosa_plots."},{"path":"https://khliland.github.io/multiblock/reference/rosa_plots.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting functions for ROSA models — rosa_plots","title":"Plotting functions for ROSA models — rosa_plots","text":"Various plotting procedures rosa objects.","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa_plots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting functions for ROSA models — rosa_plots","text":"","code":"# S3 method for class 'rosa' image(   x,   type = c(\"correlation\", \"residual\", \"order\"),   ncomp = x$ncomp,   col = mcolors(128),   legend = TRUE,   mar = c(5, 6, 4, 7),   las = 1,   ... )  # S3 method for class 'rosa' barplot(   height,   type = c(\"train\", \"CV\"),   ncomp = height$ncomp,   col = mcolors(ncomp),   ... )"},{"path":"https://khliland.github.io/multiblock/reference/rosa_plots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting functions for ROSA models — rosa_plots","text":"x rosa object type optional character selecting plot type. image.rosa options : \"correlation\" (default), \"residual\" \"order\". barplot.rosa options indicate: explained variance based training data (\"train\") cross-validation (\"CV\"). ncomp Integer control number components plot (fewer fitted number components). col Colours used image bar plot, defaulting mcolors(128). legend Logical indicating legend included (default = TRUE) image.rosa. mar Figure margins, default = c(5,6,4,7) image.rosa. las Axis text direction, default = 1 image.rosa. ... Additional parameters passed loadingplot, image, axis, color.legend, barplot. height rosa object.","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa_plots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plotting functions for ROSA models — rosa_plots","text":"return.","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa_plots.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plotting functions for ROSA models — rosa_plots","text":"Usage functions shown using generics examples . image.rosa makes image plot candidate score's correlation winner block-wise response residual. plots can used find alternative block selection tweaking ROSA model. barplot.rosa makes barplot block component explained variances. loadingweightsplot adaptation pls::loadingplot plot loading weights.","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa_plots.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plotting functions for ROSA models — rosa_plots","text":"Liland, K.H., Næs, T., Indahl, U.G. (2016). ROSA - fast extension partial least squares regression multiblock data analysis. Journal Chemometrics, 30, 651–662, doi:10.1002/cem.2824.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/rosa_plots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting functions for ROSA models — rosa_plots","text":"","code":"data(potato) mod <- rosa(Sensory[,1] ~ ., data = potato, ncomp = 5) image(mod)  barplot(mod)  loadingweightplot(mod)"},{"path":"https://khliland.github.io/multiblock/reference/rosa_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Result functions for ROSA models — rosa_results","title":"Result functions for ROSA models — rosa_results","text":"Standard result computation extraction functions ROSA (rosa).","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Result functions for ROSA models — rosa_results","text":"","code":"# S3 method for class 'rosa' predict(   object,   newdata,   ncomp = 1:object$ncomp,   comps,   type = c(\"response\", \"scores\"),   na.action = na.pass,   ... )  # S3 method for class 'rosa' coef(object, ncomp = object$ncomp, comps, intercept = FALSE, ...)  # S3 method for class 'rosa' print(x, ...)  # S3 method for class 'rosa' summary(   object,   what = c(\"all\", \"validation\", \"training\"),   digits = 4,   print.gap = 2,   ... )  blockexpl(object, ncomp = object$ncomp, type = c(\"train\", \"CV\"))  # S3 method for class 'rosaexpl' print(x, digits = 3, compwise = FALSE, ...)  rosa.classify(object, classes, newdata, ncomp, LQ)  # S3 method for class 'rosa' scores(object, ...)  # S3 method for class 'rosa' loadings(object, ...)"},{"path":"https://khliland.github.io/multiblock/reference/rosa_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result functions for ROSA models — rosa_results","text":"object rosa object. newdata Optional new data types predictor blocks ones used fitting object. ncomp integer giving number components apply (cummulative). comps integer vector giving exact components apply (subset). type blockexpl: Character indicating type explained variance compute (default = \"train\", alternative = \"CV\"). na.action Function determining missing values newdata. ... Additional arguments. Currently implemented. intercept logical indicating coefficients intercept included (default = FALSE). x rosa object. character indicating summary include , validation training. digits number digits used printing. print.gap Gap columns printing. compwise Logical indicating block-wise (default/FALSE) component-wise (TRUE) explained variance printed. classes character vector class labels. LQ character indicating 'max' (maximum score value), 'lda' 'qda' used classifying.","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Result functions for ROSA models — rosa_results","text":"Returns depend method used, e.g. predict.rosa returns predicted responses scores depending inputs, coef.rosa returns regression coefficients, blockexpl returns object class rosaexpl containing block-wise component-wise explained variance contained matrix attributes.","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa_results.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Result functions for ROSA models — rosa_results","text":"Usage functions shown using generics examples . Prediction, regression coefficients, object printing summary available : predict.rosa,  coef.rosa, print.rosa summary.rosa. Explained variances available (block-wise global) blockexpl print.rosaexpl. Scores loadings extensions scores() loadings() throught scores.rosa loadings.rosa. Finally, work progress classifcation support rosa.classify. type \"response\" (default), predicted response values returned.  comps missing (NULL), predictions length(ncomp) models ncomp[1] components, ncomp[2] components, etc., returned.  Otherwise, predictions single model exact components comps returned. (Note cases, intercept always included predictions.  can removed subtracting Ymeans component fitted model.) comps missing (NULL), coef()[,,ncomp[]] coefficients models ncomp[] components, \\(= 1, \\ldots, length(ncomp)\\).  Also, intercept = TRUE, first dimension \\(nxvar + 1\\), intercept coefficients first row. comps given, however, coef()[,,comps[]] coefficients model component comps[], .e., contribution component comps[] regression coefficients.","code":""},{"path":"https://khliland.github.io/multiblock/reference/rosa_results.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Result functions for ROSA models — rosa_results","text":"Liland, K.H., Næs, T., Indahl, U.G. (2016). ROSA - fast extension partial least squares regression multiblock data analysis. Journal Chemometrics, 30, 651–662, doi:10.1002/cem.2824.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/rosa_results.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Result functions for ROSA models — rosa_results","text":"","code":"data(potato) mod <- rosa(Sensory[,1] ~ ., data = potato, ncomp = 5, subset = 1:20) testset <- potato[-(1:20),]; testset$Sensory <- testset$Sensory[,1,drop=FALSE] predict(mod, testset, ncomp=5) #> , , 5 comps #>  #>    Sensory[, 1] #> 21     4.892899 #> 22     4.454407 #> 23     8.177141 #> 24     3.087408 #> 25     4.671565 #> 26     3.926871 #>  dim(coef(mod, ncomp=5)) # <variables x responses x components> #> [1] 3946    1    1 print(mod) #> Response Orinented Sequential Alternation , fitted with the CPPLS algorithm. #> Call: #> rosa(formula = Sensory[, 1] ~ ., ncomp = 5, data = potato, subset = 1:20) summary(mod) #> Data: \tX dimension: 20 3946  #> \tY dimension: 20 1 #> Fit method: #> Number of components considered: 5 #> TRAINING: % variance explained #>               1 comps  2 comps  3 comps  4 comps  5 comps #> X               28.09    45.00    49.16    62.24    72.58 #> Sensory[, 1]    72.84    91.32    93.68    95.15    96.73 blockexpl(mod) #> Block-wise explained variance #>  #>   Chemical Compression NIRraw NIRcooked CPMGraw CPMGcooked FIDraw FIDcooked #> X    0.453       0.103  0.169         0       0          0      0         0 #> Y    0.767       0.016  0.185         0       0          0      0         0 #>   residual #> X    0.274 #> Y    0.033 print(blockexpl(mod), compwise=TRUE) #> Component-wise explained variance #>  #>   comp.1 (Chemical) comp.2 (NIRraw) comp.3 (Chemical) comp.4 (Chemical) #> X             0.281           0.169             0.042             0.131 #> Y             0.728           0.185             0.024             0.015 #>   comp.5 (Compression) residual #> X                0.103    0.033 #> Y                0.016    0.033"},{"path":"https://khliland.github.io/multiblock/reference/sca.html","id":null,"dir":"Reference","previous_headings":"","what":"Simultaneous Component Analysis - SCA — sca","title":"Simultaneous Component Analysis - SCA — sca","text":"basic implementation SCA-P algorithm (least restricted SCA) support sample- variable-linked modes.","code":""},{"path":"https://khliland.github.io/multiblock/reference/sca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simultaneous Component Analysis - SCA — sca","text":"","code":"sca(X, ncomp = 2, scale = FALSE, samplelinked = \"auto\", ...)"},{"path":"https://khliland.github.io/multiblock/reference/sca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simultaneous Component Analysis - SCA — sca","text":"X list input blocks. ncomp integer number components extract. scale logical indicating autoscaling features (default = FALSE). samplelinked character/logical indicating blocks linked samples (TRUE) variables (FALSE). Using 'auto' (default), determined automatically. ... additional arguments (used).","code":""},{"path":"https://khliland.github.io/multiblock/reference/sca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simultaneous Component Analysis - SCA — sca","text":"multiblock object including relevant scores loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/sca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simultaneous Component Analysis - SCA — sca","text":"SCA, original variable-linked version, calculates common loadings block-wise scores. many possible constraints specialisations. implementations uses PCA backbone, thus resulting deterministic, ordered components. parameter controls linking mode, left untouched attempt made automatically determining variable sample linking.","code":""},{"path":"https://khliland.github.io/multiblock/reference/sca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simultaneous Component Analysis - SCA — sca","text":"Levin, J. (1966) Simultaneous factor analysis several gramian matrices. Psychometrika, 31(3), 413–419.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/sca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simultaneous Component Analysis - SCA — sca","text":"","code":"# Object linked data data(potato) potList <- as.list(potato[c(1,2,9)]) pot.sca    <- sca(potList) plot(scores(pot.sca), labels=\"names\")   # Variable linked data data(candies) candyList <- lapply(1:nlevels(candies$candy),function(x)candies$assessment[candies$candy==x,]) pot.sca    <- sca(candyList, samplelinked = FALSE) pot.sca #> Simultaneous Component Analysis  #>  #> Call: #> sca(X = candyList, samplelinked = FALSE)"},{"path":"https://khliland.github.io/multiblock/reference/simulated.html","id":null,"dir":"Reference","previous_headings":"","what":"Data simulated to have certain characteristics. — simulated","title":"Data simulated to have certain characteristics. — simulated","text":"dataset containing simulated data 4 connected events starting point D end point. can described directed acyclic graph (sketched , moving left->right).  Subpaths include: ABD, AD, ABCD, ACD","code":""},{"path":"https://khliland.github.io/multiblock/reference/simulated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data simulated to have certain characteristics. — simulated","text":"","code":"data(simulated)"},{"path":"https://khliland.github.io/multiblock/reference/simulated.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data simulated to have certain characteristics. — simulated","text":"list matrices 200 rows 10 variables: Simulated matrix B Simulated matrix B","code":""},{"path":"https://khliland.github.io/multiblock/reference/simulated.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data simulated to have certain characteristics. — simulated","text":"Tormod Næs, Rosaria Romano, Oliver Tomic, Ingrid Måge, Age Smilde, Kristian Hovde Liland, Sequential orthogonalized PLS (-PLS) regression path analysis: Order blocks relations effects. Journal Chemometrics, Press","code":""},{"path":"https://khliland.github.io/multiblock/reference/smbpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse Multiblock Partial Least Squares - sMB-PLS — smbpls","title":"Sparse Multiblock Partial Least Squares - sMB-PLS — smbpls","text":"sMB-PLS adaptation MB-PLS (mbpls) enforces sparseness loading weights computing PLS components global model.","code":""},{"path":"https://khliland.github.io/multiblock/reference/smbpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparse Multiblock Partial Least Squares - sMB-PLS — smbpls","text":"","code":"smbpls(   formula,   data,   subset,   na.action,   X = NULL,   Y = NULL,   ncomp = 1,   scale = FALSE,   shrink = NULL,   truncation = NULL,   trunc.width = 0.95,   blockScale = c(\"sqrtnvar\", \"ssq\", \"none\"),   ... )"},{"path":"https://khliland.github.io/multiblock/reference/smbpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparse Multiblock Partial Least Squares - sMB-PLS — smbpls","text":"formula Model formula accepting single response (block) predictor block names separated + signs. data data set analyse. subset Expression subsetting data modelling. na.action handle NAs (action implemented). X list input blocks. X supplied, formula interface skipped. Y matrix responses. ncomp integer number PLS components. scale logical autoscaling inputs (default = FALSE). shrink numeric scalar indicating degree L1-shrinkage/Soft-Thresholding (optional), 0 <= shrink < 1. truncation character indicating type truncation (optional) \"Lenth\" uses asymmetric confidence intervals determine outlying loading weights. \"quantile\" uses quantile plot approach determining outliers. trunc.width numeric indicating confidence \"Lenth type\" confidence interval quantile \"quantile plot\" approach. Default = 0.95. blockScale Either character indicating type block scaling numeric vector block weights (see Details). ... additional arguments pls::plsr.","code":""},{"path":"https://khliland.github.io/multiblock/reference/smbpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sparse Multiblock Partial Least Squares - sMB-PLS — smbpls","text":"multiblock, mvr object super-scores, super-loadings, block-scores block-loading, underlying mvr (PLS) object super model, result plot possibilities. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/smbpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sparse Multiblock Partial Least Squares - sMB-PLS — smbpls","text":"Two versions sparseness supplied: Soft-Threshold PLS, also known Sparse PLS, Truncation PLS. former uses L1 shrinkage loading weights, latter comes two flavours, estimating inliers outliers. \"Lenth\" method uses asymmetric confidence intervals around median loading weigh vector estimate inliers. \"quantile\" method uses quantile plot approach estimate outliers deviations estimated quantile line. ordinary MB-PLS scaled input blocks (1/sqrt(ncol)) used. Block weighting performed scaling variables default \"sqrtnvar\": 1/sqrt(ncol(X[[]])) block. Alternatives \"ssq\": 1/norm(X[[]], \"F\")^2 \"none\": 1/1. Finally, numeric vector supplied, used scale blocks \"ssq\" scaling, .e., Z[[]] = X[[]] / norm(X[[]], \"F\")^2 * blockScale[].","code":""},{"path":"https://khliland.github.io/multiblock/reference/smbpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sparse Multiblock Partial Least Squares - sMB-PLS — smbpls","text":"Sæbø, S.; Almøy, T.; Aarøe, J. & Aastveit, . ST-PLS: multi-directional nearest shrunken centroid type classifier via PLS Journal Chemometrics: Journal Chemometrics Society, Wiley Online Library, 2008, 22, 54-62. Lê Cao, K.; Rossouw, D.; Robert-Granié, C. & Besse, P. sparse PLS variable selection integrating omics data Statistical applications genetics molecular biology, 2008, 7. Liland, K.; Høy, M.; Martens, H. & Sæbø, S. Distribution based truncation variable selection subspace methods multivariate regression Chemometrics Intelligent Laboratory Systems, 2013, 122, 103-111. Karaman, .; Nørskov, N.; Yde, C.; Hedemann, M.; Knudsen, K. & Kohler, . Sparse multi-block PLSR biomarker discovery integrating data LC–MS NMR metabolomics Metabolomics, 2015, 11, 367-379.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/smbpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse Multiblock Partial Least Squares - sMB-PLS — smbpls","text":"","code":"data(potato)  # Truncation MB-PLS  # Loading weights inside 60% confidence intervals around the median are set to 0. tmb <- smbpls(Sensory ~ Chemical+Compression, data=potato, ncomp = 5,                truncation = \"Lenth\", trunc.width = 0.6)                # Alternative XY-interface tmb.XY <- smbpls(X=potato[c('Chemical','Compression')], Y=potato[['Sensory']], ncomp = 5,                truncation = \"Lenth\", trunc.width = 0.6) identical(tmb, tmb.XY) #> [1] FALSE scoreplot(tmb, labels=\"names\") # Exploiting mvr object structure from pls package  loadingweightplot(tmb, labels=\"names\")   # Soft-Threshold / Sparse MB-PLS  # Loading weights are subtracted by 60% of maximum value. smb <- smbpls(X=potato[c('Chemical','Compression')], Y=potato[['Sensory']],                ncomp = 5, shrink = 0.6) print(smb) #> Sparse Multiblock PLS (Soft-Threshold)  #>  #> Call: #> smbpls(X = potato[c(\"Chemical\", \"Compression\")], Y = potato[[\"Sensory\"]],     ncomp = 5, shrink = 0.6) scoreplot(smb, labels=\"names\") # Exploiting mvr object structure from pls package  loadingweightplot(smb, labels=\"names\")   # Emphasis may be different for blocks smb <- smbpls(X=potato[c('Chemical','Compression')], Y=potato[['Sensory']],                ncomp = 5, shrink = 0.6, blockScale = c(1, 10))"},{"path":"https://khliland.github.io/multiblock/reference/sopls.html","id":null,"dir":"Reference","previous_headings":"","what":"Sequential and Orthogonalized PLS (SO-PLS) — sopls","title":"Sequential and Orthogonalized PLS (SO-PLS) — sopls","text":"Function computing standard -PLS based interface pls package.","code":""},{"path":"https://khliland.github.io/multiblock/reference/sopls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sequential and Orthogonalized PLS (SO-PLS) — sopls","text":"","code":"sopls(   formula,   ncomp,   max_comps = min(sum(ncomp), 20),   data,   subset,   na.action,   scale = FALSE,   validation = c(\"none\", \"CV\", \"LOO\"),   sequential = FALSE,   segments = 10,   sel.comp = \"opt\",   progress = TRUE,   ... )"},{"path":"https://khliland.github.io/multiblock/reference/sopls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sequential and Orthogonalized PLS (SO-PLS) — sopls","text":"formula Model formula accepting single response (block) predictor block names separated + signs. ncomp Numeric vector components per block scalar overall maximum components. max_comps Maximum total number components blocks combined (<= sum(ncomp)). data data set analyse. subset Expression subsetting data modelling. na.action handle NAs (action implemented). scale Logical indicating variables scaled. validation Optional cross-validation strategy \"CV\" \"LOO\". sequential Logical indicating optimal components chosen sequentially globally (default=FALSE). segments Optional number segments list segments cross-validation. (See [pls::cvsegments()]). sel.comp Character indicating sequential optimal number components chosen minimum RMSECV ('opt', default) Chi-square test ('chi'). progress Logical indicating progress bar displayed cross-validating. ... Additional arguments underlying methods.","code":""},{"path":"https://khliland.github.io/multiblock/reference/sopls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sequential and Orthogonalized PLS (SO-PLS) — sopls","text":"sopls, mvr object scores, loadings, etc. associated printing (sopls_results) plotting methods (sopls_plots).","code":""},{"path":"https://khliland.github.io/multiblock/reference/sopls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sequential and Orthogonalized PLS (SO-PLS) — sopls","text":"-PLS method handles two input blocks sequentially performing PLS blocks response orthogonalising remaining blocks extracted components. Component number optimisation can either done globally (best combination across blocks) sequentially (determine one block, move next, etc.).","code":""},{"path":"https://khliland.github.io/multiblock/reference/sopls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sequential and Orthogonalized PLS (SO-PLS) — sopls","text":"Jørgensen K, Mevik BH, Næs T. Combining designed experiments several blocks spectroscopic data. Chemometr Intell Lab Syst. 2007;88(2): 154–166.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/sopls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sequential and Orthogonalized PLS (SO-PLS) — sopls","text":"","code":"data(potato) so <- sopls(Sensory ~ Chemical + Compression, data=potato, ncomp=c(10,10),              max_comps=10, validation=\"CV\", segments=10) summary(so) #> Data: \tX dimension: 26 0  #> \tY dimension: 26 9 #> Fit method: PKPLS #> Number of components considered: 10 #>  #> VALIDATION: RMSEP #> Cross-validated using 10 random segments. #>    0,0     0,1     0,2     0,3     0,4     0,5     0,6     0,7     0,8     0,9   #> 1.1174  0.9463  0.9470  0.9319  0.9327  1.0831  0.9802  1.0401  1.0562  1.0670   #>   0,10     1,0     1,1     1,2     1,3     1,4     1,5     1,6     1,7     1,8   #> 1.0344  0.8491  0.8039  0.8427  0.7785  0.8005  0.8442  0.8449  0.9155  0.9279   #>    1,9     2,0     2,1     2,2     2,3     2,4     2,5     2,6     2,7     2,8   #> 0.9669  0.7712  0.6732  0.6563  0.6951  0.7161  0.7289  0.7394  0.7929  0.8404   #>    3,0     3,1     3,2     3,3     3,4     3,5     3,6     3,7     4,0     4,1   #> 0.7056  0.6732  0.6582  0.7098  0.7358  0.7529  0.7766  0.8266  0.6964  0.6639   #>    4,2     4,3     4,4     4,5     4,6     5,0     5,1     5,2     5,3     5,4   #> 0.6495  0.6961  0.7294  0.7635  0.8050  0.7057  0.6702  0.6645  0.7261  0.7685   #>    5,5     6,0     6,1     6,2     6,3     6,4     7,0     7,1     7,2     7,3   #> 0.8480  0.7746  0.7380  0.7335  0.7767  0.8225  0.8324  0.7910  0.7826  0.8379   #>    8,0     8,1     8,2     9,0     9,1    10,0   #> 1.0183  0.9750  0.9628  1.0054  0.9663  1.2920   #>  #> TRAINING: % variance explained #>         0,0    0,1    0,2    0,3    0,4    0,5    0,6    0,7    0,8    0,9 #> X         0  45.87  55.51  62.90  66.46  67.73  74.95  78.26  79.85  82.39 #> ref       0  42.19  54.73  65.01  66.85  73.96  74.10  74.44  77.45  77.57 #> hard      0  39.11  41.97  42.23  43.80  50.95  54.87  56.78  59.50  74.53 #> firm      0  42.55  57.44  59.44  61.06  66.78  68.62  69.02  71.34  76.53 #> elas      0  38.64  65.31  73.51  75.63  77.23  79.25  81.19  83.71  86.57 #> adhes     0  16.13  18.11  26.71  26.74  29.70  42.07  44.57  46.47  46.54 #> grainy    0  23.21  43.78  62.23  64.02  67.18  67.72  69.83  74.79  74.79 #> mealy     0  35.35  41.99  57.36  58.84  67.17  70.33  73.21  77.77  78.88 #> moist     0  24.48  27.71  43.10  44.27  48.41  53.39  62.37  67.60  74.79 #> chewi     0  21.98  22.78  48.17  55.50  59.96  68.39  72.54  76.39  77.42 #>          0,10    1,0    1,1    1,2    1,3    1,4    1,5    1,6    1,7    1,8 #> X       83.18  34.20  64.12  71.71  76.24  78.20  79.49  83.37  84.42  85.59 #> ref     77.57  55.79  64.00  64.25  73.75  77.39  79.53  80.42  80.50  80.96 #> hard    75.43  24.10  41.42  44.05  44.07  44.09  47.61  53.70  53.86  62.46 #> firm    79.31  42.73  54.16  58.42  62.05  63.55  64.91  70.85  70.91  70.93 #> elas    88.14  53.24  59.32  63.95  71.43  74.51  75.33  77.16  78.86  78.88 #> adhes   54.68  17.49  22.70  33.54  33.75  34.70  34.90  39.43  48.51  48.92 #> grainy  74.82  57.69  58.26  58.39  71.89  75.95  76.07  76.72  77.73  79.00 #> mealy   79.25  61.37  65.64  66.70  74.33  75.36  77.44  78.35  79.55  80.15 #> moist   77.22  57.32  58.51  62.12  66.20  66.35  67.13  67.14  69.51  71.02 #> chewi   81.68  53.27  54.25  64.22  66.35  69.59  69.96  72.80  77.64  77.64 #>           1,9    2,0    2,1    2,2    2,3    2,4    2,5    2,6    2,7    2,8 #> X       86.07  42.76  72.61  79.40  81.41  82.69  84.98  88.16  88.87  89.84 #> ref     81.20  76.03  85.17  87.21  89.03  90.67  90.68  91.36  91.36  91.39 #> hard    69.98  25.29  44.10  46.63  46.63  46.88  52.03  61.89  64.48  73.84 #> firm    80.21  55.93  69.19  76.45  76.45  76.80  77.79  82.58  82.64  86.03 #> elas    87.63  63.10  70.21  78.03  78.08  78.17  80.37  82.19  84.54  85.69 #> adhes   49.97  34.43  39.48  46.70  46.78  48.48  54.50  56.16  67.45  72.74 #> grainy  79.50  83.95  84.78  87.19  88.01  88.56  89.28  89.29  89.30  89.49 #> mealy   80.19  81.14  85.67  85.68  87.94  88.28  88.57  89.15  89.69  90.49 #> moist   72.44  67.94  69.06  70.49  72.51  72.53  72.61  72.80  73.61  78.69 #> chewi   78.05  70.55  71.41  77.11  77.11  78.09  78.17  79.79  83.27  86.51 #>           3,0    3,1    3,2    3,3    3,4    3,5    3,6    3,7    4,0    4,1 #> X       63.76  78.59  84.55  86.77  87.73  90.09  91.81  92.46  70.09  80.35 #> ref     84.50  86.31  87.91  89.34  91.72  91.74  93.12  93.13  84.91  87.28 #> hard    29.51  45.43  50.00  50.23  51.56  54.69  61.12  63.12  30.80  49.39 #> firm    62.42  68.64  76.93  76.96  77.84  78.25  82.67  82.72  62.64  73.46 #> elas    69.44  70.75  78.04  78.06  78.07  80.60  82.75  85.36  69.94  73.16 #> adhes   34.51  46.88  50.83  51.04  51.60  57.45  58.26  69.10  64.76  65.66 #> grainy  87.18  87.45  88.87  89.86  90.34  91.06  91.37  91.45  87.20  87.21 #> mealy   84.89  86.14  86.18  88.32  89.25  89.48  91.02  91.95  88.83  88.96 #> moist   70.03  70.05  72.13  74.57  74.71  74.88  74.97  76.40  75.09  76.33 #> chewi   70.56  72.61  77.34  77.39  78.58  78.58  79.89  83.77  82.06  82.29 #>           4,2    4,3    4,4    4,5    4,6    5,0    5,1    5,2    5,3    5,4 #> X       87.12  88.89  89.78  92.03  93.37  75.21  84.27  91.16  92.52  93.47 #> ref     88.13  89.65  92.48  92.54  93.63  85.03  88.23  89.16  90.27  92.85 #> hard    49.95  50.65  50.76  54.96  60.99  41.38  53.88  54.08  54.33  54.70 #> firm    77.00  77.10  77.44  78.23  83.34  68.24  75.97  78.78  78.78  79.40 #> elas    78.98  79.09  79.43  82.78  83.85  72.35  74.56  79.87  80.48  80.91 #> adhes   67.28  68.26  69.21  70.41  70.90  64.77  65.81  67.35  67.83  69.01 #> grainy  89.07  90.46  91.63  92.15  92.30  87.53  87.56  89.67  90.98  91.93 #> mealy   88.99  93.13  94.52  94.64  95.00  89.21  89.65  89.73  93.45  94.51 #> moist   76.60  82.33  82.90  82.90  83.28  79.72  79.91  79.98  83.86  84.08 #> chewi   84.08  84.45  86.24  86.38  86.39  82.11  82.31  83.97  84.76  86.45 #>           5,5    6,0    6,1    6,2    6,3    6,4    7,0    7,1    7,2    7,3 #> X       95.40  77.28  86.22  93.18  94.55  95.63  79.57  88.43  95.46  96.65 #> ref     92.91  86.80  90.43  91.47  92.26  94.07  88.07  91.60  92.62  92.70 #> hard    60.53  45.27  56.94  57.05  57.64  59.71  45.28  56.91  56.99  57.22 #> firm    80.75  68.98  76.56  79.17  79.42  80.55  69.02  76.72  79.16  79.35 #> elas    83.34  72.55  74.96  80.08  80.15  80.26  73.76  76.39  81.36  81.61 #> adhes   70.53  64.77  65.79  67.29  69.17  69.37  65.04  65.96  67.53  68.89 #> grainy  92.38  91.29  91.41  93.80  94.06  94.27  91.78  91.89  94.29  94.34 #> mealy   94.83  90.67  91.24  91.36  94.83  95.44  92.38  92.87  92.98  94.77 #> moist   84.08  82.80  82.90  82.93  85.65  85.67  85.12  85.26  85.29  86.55 #> chewi   86.50  84.60  84.72  86.16  86.49  87.50  86.05  86.22  87.61  87.62 #>           8,0    8,1    8,2    9,0    9,1   10,0 #> X       82.82  88.16  95.96  85.49  90.21  87.08 #> ref     90.82  94.67  94.93  91.52  94.42  91.79 #> hard    52.73  59.90  60.33  52.75  63.37  52.92 #> firm    71.26  80.42  80.49  71.81  80.88  71.82 #> elas    73.78  80.71  81.41  75.22  80.15  76.14 #> adhes   68.88  68.89  69.28  71.74  72.73  74.17 #> grainy  91.80  93.21  94.39  91.99  92.91  92.43 #> mealy   93.59  94.05  94.31  93.75  93.98  93.83 #> moist   86.40  86.60  87.34  87.11  88.40  87.14 #> chewi   87.11  88.40  88.43  87.27  89.53  87.28  # Scatter plot matrix with two first components from Chemical block # and 1 component from the Compression block. scoreplot(so, comps=list(1:2,1), ncomp=2, block=2)   # Result functions and more plots for SO-PLS  # are found in ?sopls_results and ?sopls_plots."},{"path":"https://khliland.github.io/multiblock/reference/sopls_plots.html","id":null,"dir":"Reference","previous_headings":"","what":"Scores, loadings and plots for sopls objects — sopls_plots","title":"Scores, loadings and plots for sopls objects — sopls_plots","text":"Extraction scores loadings adaptation scoreplot, loadingplot biplot package pls sopls objects.","code":""},{"path":"https://khliland.github.io/multiblock/reference/sopls_plots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scores, loadings and plots for sopls objects — sopls_plots","text":"","code":"# S3 method for class 'sopls' loadings(object, ncomp = \"all\", block = 1, y = FALSE, ...)  # S3 method for class 'sopls' scores(object, ncomp = \"all\", block = 1, y = FALSE, ...)  # S3 method for class 'sopls' scoreplot(   object,   comps = 1:2,   ncomp = NULL,   block = 1,   labels,   identify = FALSE,   type = \"p\",   xlab,   ylab,   ... )  # S3 method for class 'sopls' loadingplot(   object,   comps = 1:2,   ncomp = NULL,   block = 1,   scatter = TRUE,   labels,   identify = FALSE,   type,   lty,   lwd = NULL,   pch,   cex = NULL,   col,   legendpos,   xlab,   ylab,   pretty.xlabels = TRUE,   xlim,   ... )  # S3 method for class 'sopls' corrplot(   object,   comps = 1:2,   ncomp = NULL,   block = 1,   labels = TRUE,   col = 1:5,   plotx = TRUE,   ploty = TRUE,   ... )  # S3 method for class 'sopls' biplot(   x,   comps = 1:2,   ncomp = \"all\",   block = 1,   which = c(\"x\", \"y\", \"scores\", \"loadings\"),   var.axes = FALSE,   xlabs,   ylabs,   main,   ... )"},{"path":"https://khliland.github.io/multiblock/reference/sopls_plots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scores, loadings and plots for sopls objects — sopls_plots","text":"object sopls object ncomp integer vector giving components blocks block (see next argument). block integer indicating block extract components . y logical extract Y loadings/scores instead X loadings/scores (default = FALSE). ... arguments sent underlying plot function(s) comps integer vector giving components, within block, plot (see Details regarding combination blocks). labels character indicating \"names\" \"numbers\" plot symbols (optional). identify logical activating identify interactively identify points. type character selecting type plot make. Defaults \"p\" (points) scatter plots \"l\" (lines) line plots. xlab character text x labels. ylab character text y labels. scatter logical indicating scatterplot loadings made (default = TRUE). lty Vector line type specifications (see par details). lwd numeric vector line width specifications. pch Vector point specifications (see points details). cex numeric vector plot size expansions (see par details). col integer vector symbol/line colours (see par details). legendpos character indicating legend position (scatter FALSE), e.g. legendpos = \"topright\". pretty.xlabels logical indicating xlabels nicely plotted (default = TRUE). xlim numeric vector length two, x limits plot (optional). plotx locical integer/character.  Whether plot \\(X\\) correlation loadings, optionally block(s). Defaults TRUE. ploty logical.  Whether plot \\(Y\\) correlation loadings. Defaults TRUE. x sopls object character selecting type biplot (\"x\" = default, \"y\", \"scores\", \"loadings\"). var.axes logical indicating second axes biplot arrows. xlabs character vector labelling first set biplot points (optional). ylabs character vector labelling second set biplot points (optional). main character setting main title plot.","code":""},{"path":"https://khliland.github.io/multiblock/reference/sopls_plots.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scores, loadings and plots for sopls objects — sopls_plots","text":"comps supplied list scoreplot, assumed elements refer blocks block number block. instance comps = list(1, 0, 1:2) select 1 component first block, components second block first two components last block. must matched ncomp, specifying many components selected block number block.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/sopls_plots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scores, loadings and plots for sopls objects — sopls_plots","text":"","code":"data(potato) so <- sopls(Sensory ~ Chemical + Compression + NIRraw, data=potato, ncomp=c(5,5,5))  # Loadings loadings(so, ncomp=c(3), block=2)[, 1:3] #>          3,1,0       3,2,0        3,3,0 #> FW20  2.899592 -2.25518600 -1.181401337 #> BW20  3.253005 -0.34748421  0.211162557 #> ST20  3.232381  0.40110809 -0.042460853 #> SH20  2.450377 -3.89643043 -1.273002388 #> Mo20  1.471707  2.63506368 -0.950867682 #> Sl20  2.726383  0.26885897  0.002480118 #> FW750 3.159111 -0.21770583  0.551632015 #> BW750 2.892770  0.48171215  0.667057573 #> ST750 2.851268  0.01964503  0.173617022 #> SH750 3.370985 -1.53962601  1.348135225 #> Mo750 1.173309  1.92291778 -1.496492798 #> Sl750 2.539819  0.46410991 -0.071181501  # Scores scores(so, block=1)[, 1:4] #>           1,0,0       2,0,0        3,0,0       4,0,0 #> 1  -0.078379126 -0.15756558 -0.030150796 -0.08882899 #> 2   0.033599245  0.03345139 -0.264837392 -0.02082345 #> 3  -0.454087240 -0.50387774 -0.257625630  0.24822188 #> 4  -0.010144029  0.04409907  0.254739277  0.34206013 #> 5  -0.231320589  0.02813994  0.331647163 -0.15209020 #> 6  -0.100806072 -0.03203490  0.058511494 -0.07824489 #> 7   0.103759602  0.05587580  0.171495995  0.13245956 #> 8   0.142341829 -0.02952316  0.135315864  0.17766566 #> 9   0.160175421 -0.13395363  0.067732083 -0.34567441 #> 10  0.078862890 -0.20282246  0.065251294 -0.21205811 #> 11  0.200245777 -0.02882659  0.149667777 -0.08872396 #> 12  0.223602068 -0.07321286 -0.029748834 -0.22950703 #> 13  0.217320106 -0.26815383  0.096949900 -0.10070260 #> 14  0.142847549 -0.29951537  0.077252287  0.24996525 #> 15  0.213820293  0.17228886 -0.461863019 -0.11767172 #> 16  0.164964325  0.26005269 -0.323577542  0.10235857 #> 17  0.002967383  0.19480792 -0.246885356  0.19701818 #> 18  0.066258347  0.09356886 -0.228532411  0.20484080 #> 19  0.194213760 -0.01568159  0.132000297  0.14447620 #> 20  0.141301554 -0.07654188  0.049224760  0.26084474 #> 21 -0.129888279  0.04471652  0.038982799 -0.30565064 #> 22 -0.105636544  0.24576605 -0.030041538 -0.14535670 #> 23 -0.464479945 -0.11433433 -0.194275154 -0.06714686 #> 24 -0.082441922  0.22751259  0.233417343  0.13675311 #> 25 -0.325181587  0.44765983  0.208213841  0.07217114 #> 26 -0.103914818  0.08810440 -0.002864502 -0.31635566  # Default plot from first block scoreplot(so)   # Second block with names scoreplot(so, ncomp=c(3), block=2, labels=\"names\")   # Scatterplot matrix scoreplot(so, ncomp=c(3,2), block=3, comps=1:3)   # Combination of blocks (see Details) scoreplot(so, ncomp=c(3,2), block=3, comps=list(1,0,1))   # Default plot from first block loadingplot(so, scatter=TRUE)   # Second block with names loadingplot(so, ncomp=c(3), block=2, labels=\"names\", scatter=TRUE)   # Scatterplot matrix loadingplot(so, ncomp=c(3,2), block=3, comps=1:3, scatter=TRUE)   # Correlation loadings corrplot(so, block=2, ncomp=1)   # Default plot from first block biplot(so)"},{"path":"https://khliland.github.io/multiblock/reference/sopls_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Result functions for SO-PLS models — sopls_results","title":"Result functions for SO-PLS models — sopls_results","text":"Standard result functions -PLS (sopls).","code":""},{"path":"https://khliland.github.io/multiblock/reference/sopls_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Result functions for SO-PLS models — sopls_results","text":"","code":"# S3 method for class 'sopls' predict(   object,   newdata,   ncomp = object$ncomp,   type = c(\"response\", \"scores\"),   na.action = na.pass,   ... )  # S3 method for class 'sopls' coef(object, ncomp = object$ncomp, intercept = FALSE, ...)  # S3 method for class 'sopls' print(x, ...)  # S3 method for class 'sopls' summary(   object,   what = c(\"all\", \"validation\", \"training\"),   digits = 4,   print.gap = 2,   ... )  classify(object, ...)  # S3 method for class 'sopls' classify(object, classes, newdata, ncomp, LQ = \"LDA\", ...)  # S3 method for class 'sopls' R2(object, estimate, newdata, ncomp = \"all\", individual = FALSE, ...)  # S3 method for class 'sopls' RMSEP(object, estimate, newdata, ncomp = \"all\", individual = FALSE, ...)  pcp(object, ...)  # S3 method for class 'sopls' pcp(object, ncomp, ...)  # Default S3 method pcp(object, X, ...)  cvanova(pred, ...)  # Default S3 method cvanova(pred, true, absRes = TRUE, ...)  # S3 method for class 'sopls' cvanova(pred, comps, absRes = TRUE, ...)  # S3 method for class 'cvanova' print(x, ...)  # S3 method for class 'cvanova' summary(object, ...)  # S3 method for class 'cvanova' plot(x, ...)  # S3 method for class 'sopls' residuals(object, ...)"},{"path":"https://khliland.github.io/multiblock/reference/sopls_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result functions for SO-PLS models — sopls_results","text":"object sopls object. newdata Optional new data types predictor blocks ones used fitting object. ncomp integer vector giving exact components apply. type character predict indicating responses scores predicted (default = \"response\", \"scores\"), summary indicating type explained variance compute (default = \"train\", alternative = \"CV\"). na.action Function determining missing values newdata. ... Additional arguments. Currently implemented. intercept logical indicating coefficients intercept included (default = FALSE). x sopls object. character indicating summary include , validation training. digits number digits used printing. print.gap Gap columns printing. classes character vector class labels. LQ character indicating 'max' (maximum score value), 'lda' 'qda' used classifying. estimate character indicating 'train', 'CV' 'test' results displayed. individual logical indicating results individual responses displayed. X list data blocks. pred object holding CV-predicted values (sopls, matrix list vectors) true numeric true response values CVANOVA. absRes logical indicating absolute (TRUE) squared (FALSE) residuals computed. comps integer vector giving exact components apply.","code":""},{"path":"https://khliland.github.io/multiblock/reference/sopls_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Result functions for SO-PLS models — sopls_results","text":"Returns depend method used, e.g. predict.sopls returns predicted responses scores depending inputs, coef.sopls return regression coefficients, print summary methods return object invisibly.","code":""},{"path":"https://khliland.github.io/multiblock/reference/sopls_results.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Result functions for SO-PLS models — sopls_results","text":"parameter ncomp controls components apply/extract, resulting sequence components leading specific choice, .e. ncomp = c(2,2,1) results sequence 1,0,0; 2,0,0; 2,1,0; 2,2,0; 2,2,1. Usage functions shown using generics examples . Prediction, regression coefficients, object printing summary available : predict.sopls, coef.sopls, print.sopls summary.sopls. Explained variances RMSEP available R2.sopls RMSEP.sopls. Principal components predictions available pcp.sopls. Finally, work progress classifcation support classify.sopls.","code":""},{"path":"https://khliland.github.io/multiblock/reference/sopls_results.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Result functions for SO-PLS models — sopls_results","text":"Jørgensen K, Mevik BH, Næs T. Combining designed experiments several blocks spectroscopic data. Chemometr Intell Lab Syst. 2007;88(2): 154–166.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/sopls_results.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Result functions for SO-PLS models — sopls_results","text":"","code":"data(potato) mod <- sopls(Sensory[,1] ~ ., data = potato[c(1:3,9)], ncomp = 5, subset = 1:20) testset <- potato[-(1:20),]; testset$Sensory <- testset$Sensory[,1,drop=FALSE] predict(mod, testset, ncomp=c(2,1,2)) #> , , 1,0,0 #>  #>      Sensory[, 1] #> [1,]     3.922829 #> [2,]     3.801854 #> [3,]     6.409450 #> [4,]     2.960830 #> [5,]     4.433857 #> [6,]     3.223006 #>  #> , , 2,0,0 #>  #>      Sensory[, 1] #> [1,]     4.062985 #> [2,]     4.238679 #> [3,]     7.178207 #> [4,]     2.477011 #> [5,]     3.319856 #> [6,]     2.904183 #>  #> , , 2,1,0 #>  #>      Sensory[, 1] #> [1,]     4.169790 #> [2,]     4.471989 #> [3,]     7.282654 #> [4,]     2.426714 #> [5,]     3.273465 #> [6,]     2.898753 #>  #> , , 2,1,1 #>  #>      Sensory[, 1] #> [1,]    5.2214087 #> [2,]    5.1427034 #> [3,]    9.7861678 #> [4,]   -0.7742392 #> [5,]    0.9645707 #> [6,]    2.2666501 #>  #> , , 2,1,2 #>  #>      Sensory[, 1] #> [1,]    5.4727706 #> [2,]    5.5669734 #> [3,]   11.3237645 #> [4,]   -2.3105720 #> [5,]    0.2755925 #> [6,]    2.1649361 #>  dim(coef(mod, ncomp=c(3,0,1))) # <variables x responses x components> #> [1] 1076    1    4 R2(mod, ncomp = c(4,1,2)) #>     1,0,0     2,0,0     3,0,0     4,0,0     4,1,0     4,1,1     4,1,2  #> 0.7283653 0.8638657 0.8754625 0.8865483 0.9065776 0.9672131 0.9705168  print(mod) #> Sequential and Orthogonalized Partial Least Squares, fitted with the PKPLS algorithm. #> Call: #> sopls(formula = Sensory[, 1] ~ ., ncomp = 5, data = potato[c(1:3,     9)], subset = 1:20) summary(mod) #> Data: \tX dimension: 20 0  #> \tY dimension: 20 1 #> Fit method: PKPLS #> Number of components considered: 15 #> TRAINING: % variance explained #>               0,0,0  0,0,1  0,0,2  0,0,3  0,0,4  0,0,5  0,1,0  0,1,1  0,1,2 #> X                 0  20.86  28.31  36.64  44.50  49.32  43.07  48.93  57.63 #> Sensory[, 1]      0  67.18  76.02  79.52  82.14  86.78  31.94  77.34  78.82 #>               0,1,3  0,1,4  0,1,5  0,2,0  0,2,1  0,2,2  0,2,3  0,2,4  0,2,5 #> X             64.80  72.01  75.43  53.34   58.2  63.49  70.46  77.88  80.61 #> Sensory[, 1]  81.95  85.33  90.05  57.59   79.4  84.80  86.19  87.51  94.30 #>               0,3,0  0,3,1  0,3,2  0,3,3  0,3,4  0,3,5  0,4,0  0,4,1  0,4,2 #> X             64.51  67.17  68.88  75.52  80.49  83.06  67.33  68.65  71.70 #> Sensory[, 1]  64.12  85.01  86.62  87.59  93.18  94.14  74.00  83.04  87.33 #>               0,4,3  0,4,4  0,4,5  0,5,0  0,5,1  0,5,2  0,5,3  0,5,4  0,5,5 #> X             76.96  81.33  84.16  71.36  73.06  76.39  78.64  81.95  86.70 #> Sensory[, 1]  87.88  94.30  95.34  80.83  86.18  89.54  90.73  92.24  95.77 #>               1,0,0  1,0,1  1,0,2  1,0,3  1,0,4  1,0,5  1,1,0  1,1,1  1,1,2 #> X             26.79  31.20  43.68  46.20  52.01  55.18  61.24  66.52  71.52 #> Sensory[, 1]  72.84  91.32  92.82  95.22  95.51  96.93  76.08  88.73  93.14 #>               1,1,3  1,1,4  1,1,5  1,2,0  1,2,1  1,2,2  1,2,3  1,2,4  1,2,5 #> X             74.07  79.80  81.43  67.65  73.86  76.42  78.58  84.35  85.69 #> Sensory[, 1]  95.49  95.82  97.27  79.16  88.85  93.93  95.79  96.00  97.71 #>               1,3,0  1,3,1  1,3,2  1,3,3  1,3,4  1,3,5  1,4,0  1,4,1  1,4,2 #> X             77.02  78.22  79.95  83.57  86.14  88.56  78.39  79.69  80.67 #> Sensory[, 1]  81.81  93.93  94.20  95.89  96.11  97.76  85.47  91.35  94.63 #>               1,4,3  1,4,4  1,4,5  1,5,0  1,5,1  1,5,2  1,5,3  1,5,4  1,5,5 #> X             84.14  86.57  89.08  82.78  84.04  84.95  88.04  89.04  90.79 #> Sensory[, 1]  95.99  96.22  97.90  86.07  91.69  94.63  95.98  96.39  98.57 #>               2,0,0  2,0,1  2,0,2  2,0,3  2,0,4  2,0,5  2,1,0  2,1,1  2,1,2 #> X             34.87  37.53  48.20  50.75  55.97  59.45  68.53  70.72  76.16 #> Sensory[, 1]  86.39  94.20  94.31  95.79  96.04  97.41  87.33  93.13  94.50 #>               2,1,3  2,1,4  2,1,5  2,2,0  2,2,1  2,2,2  2,2,3  2,2,4  2,2,5 #> X             78.45  83.48  85.00  75.89  78.58  80.38  82.27  86.68  88.61 #> Sensory[, 1]  96.01  96.30  97.72  88.70  93.06  95.15  96.23  97.50  98.19 #>               2,3,0  2,3,1  2,3,2  2,3,3  2,3,4  2,3,5  2,4,0  2,4,1  2,4,2 #> X             79.17  80.67  83.25  85.01  87.84  90.11  82.09  82.98  84.07 #> Sensory[, 1]  92.41  93.82  95.29  96.23  96.73  98.47  92.65  94.89  95.63 #>               2,4,3  2,4,4  2,4,5  2,5,0  2,5,1  2,5,2  2,5,3  2,5,4  2,5,5 #> X             85.28  89.93  90.89  83.91  84.81  86.30  88.20  90.32  92.83 #> Sensory[, 1]  96.54  97.24  99.08  92.87  95.07  95.84  96.82  97.06  99.46 #>               3,0,0  3,0,1  3,0,2  3,0,3  3,0,4  3,0,5  3,1,0  3,1,1  3,1,2 #> X             59.03  60.65  67.95  70.92  75.78  78.19  69.06  71.96  73.84 #> Sensory[, 1]  87.55  94.19  94.84  96.29  96.67  98.11  88.70  93.08  95.30 #>               3,1,3  3,1,4  3,1,5  3,2,0  3,2,1  3,2,2  3,2,3  3,2,4  3,2,5 #> X             76.78  81.94  85.02  78.92  82.53  84.55  87.83  89.64  92.04 #> Sensory[, 1]  96.44  96.79  98.38  90.25  93.89  95.89  96.50  97.03  98.11 #>               3,3,0  3,3,1  3,3,2  3,3,3  3,3,4  3,3,5  3,4,0  3,4,1  3,4,2 #> X             85.24  86.31  88.93  91.19  92.91  94.53  87.57  88.49  89.60 #> Sensory[, 1]  92.87  94.71  95.90  96.52  97.17  98.90  93.39  95.41  96.33 #>               3,4,3  3,4,4  3,4,5  3,5,0  3,5,1  3,5,2  3,5,3  3,5,4  3,5,5 #> X             92.66  93.73  95.33  88.38  89.34  90.28  93.27  94.34  96.69 #> Sensory[, 1]  96.89  97.69  99.48  93.82  95.72  96.59  97.23  97.75  99.49 #>               4,0,0  4,0,1  4,0,2  4,0,3  4,0,4  4,0,5  4,1,0  4,1,1  4,1,2 #> X             70.41  72.12  74.08  79.57  81.18  83.20  77.16  78.39  79.70 #> Sensory[, 1]  88.65  95.40  96.30  96.76  97.29  97.98  90.66  96.72  97.05 #>               4,1,3  4,1,4  4,1,5  4,2,0  4,2,1  4,2,2  4,2,3  4,2,4  4,2,5 #> X             84.71  85.89  87.74  89.89  91.13  92.42  94.25  94.80  96.04 #> Sensory[, 1]  97.29  97.92  98.72  91.21  97.00  97.43  97.85  98.52  99.11 #>               4,3,0  4,3,1  4,3,2  4,3,3  4,3,4  4,3,5  4,4,0  4,4,1  4,4,2 #> X             91.46  92.59  92.95  94.13  94.93  96.32  92.88  93.93  94.29 #> Sensory[, 1]  94.59  95.99  97.39  97.76  99.11  99.26  95.17  96.24  97.51 #>               4,4,3  4,4,4  4,4,5  4,5,0  4,5,1  4,5,2  4,5,3  4,5,4  4,5,5 #> X             95.36  95.70  97.96  93.79  94.63  94.91  95.99  96.25  98.56 #> Sensory[, 1]  97.87  98.61  99.19  95.36  96.95  97.82  98.18  99.02  99.50 #>               5,0,0  5,0,1  5,0,2  5,0,3  5,0,4  5,0,5  5,1,0  5,1,1  5,1,2 #> X             77.24  78.66  81.59  89.61  91.01  92.56  86.22  87.57  90.46 #> Sensory[, 1]  90.58  94.51  96.27  96.80  97.36  98.45  92.18  95.85  96.90 #>               5,1,3  5,1,4  5,1,5  5,2,0  5,2,1  5,2,2  5,2,3  5,2,4  5,2,5 #> X             91.65  92.24  95.65  92.51  93.92  95.20  95.54  95.83  96.87 #> Sensory[, 1]  97.71  98.50  98.74  92.88  97.40  97.44  98.25  98.99  99.32 #>               5,3,0  5,3,1  5,3,2  5,3,3  5,3,4  5,3,5  5,4,0  5,4,1  5,4,2 #> X             93.67  95.09  95.47  96.08  96.43  97.46  95.04  96.33  96.72 #> Sensory[, 1]  95.76  96.58  97.44  98.65  99.22  99.46  96.35  96.90  97.52 #>               5,4,3  5,4,4  5,4,5  5,5,0  5,5,1  5,5,2  5,5,3  5,5,4  5,5,5 #> X             97.24  97.57  97.76  96.06  97.06  97.55  98.14  98.37  98.51 #> Sensory[, 1]  98.70  99.13  99.62  96.58  97.22  97.75  98.73  99.30  99.77  # PCP from sopls object modMulti <- sopls(Sensory ~ ., data = potato[c(1:3,9)], ncomp = 5, validation = \"CV\", segment = 5) (PCP <- pcp(modMulti, c(2,1,2))) #> Principal Components of Predictions  #>  #> Call: #> pcp.sopls(object = modMulti, ncomp = c(2, 1, 2)) scoreplot(PCP)   # PCP from matrices preds <- modMulti$validation$Ypred[,,\"2,1,2\"] PCP_default <- pcp(preds, potato[1:3])  # CVANOVA modCV <- sopls(Sensory[,1] ~ ., data = potato[c(1:3,9)], ncomp = 5, validation = \"CV\", segment = 5) summary(cva <- cvanova(modCV, \"2,1,2\")) #> Analysis of Variance Table #>  #> Response: Residual #>           Df  Sum Sq Mean Sq F value    Pr(>F)     #> Model      2  1.4248 0.71238  5.8825  0.005078 **  #> Object    25 18.7475 0.74990  6.1923 2.424e-08 *** #> Residuals 50  6.0551 0.12110                       #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #> Tukey's HSD #> Alpha: 0.05 #>  #>            Mean G1 G2 #> 2,0,0 0.9144251     B #> 2,1,0 0.7730244  A  B #> 2,1,2 0.5844908  A    plot(cva)"},{"path":"https://khliland.github.io/multiblock/reference/statis.html","id":null,"dir":"Reference","previous_headings":"","what":"Structuration des Tableaux à Trois Indices de la Statistique - STATIS — statis","title":"Structuration des Tableaux à Trois Indices de la Statistique - STATIS — statis","text":"wrapper ade4::statis function computing STATIS.","code":""},{"path":"https://khliland.github.io/multiblock/reference/statis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Structuration des Tableaux à Trois Indices de la Statistique - STATIS — statis","text":"","code":"statis(X, ncomp = 3, scannf = FALSE, tol = 1e-07, ...)"},{"path":"https://khliland.github.io/multiblock/reference/statis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Structuration des Tableaux à Trois Indices de la Statistique - STATIS — statis","text":"X list input blocks. ncomp integer number components extract. scannf logical indicating eigenvalue bar plot shoulde displayed. tol numeric eigenvalue threshold tolerance. ... additional arguments (used).","code":""},{"path":"https://khliland.github.io/multiblock/reference/statis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Structuration des Tableaux à Trois Indices de la Statistique - STATIS — statis","text":"multiblock object including relevant scores loadings. Relevant plotting functions: multiblock_plots result functions: multiblock_results.","code":""},{"path":"https://khliland.github.io/multiblock/reference/statis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Structuration des Tableaux à Trois Indices de la Statistique - STATIS — statis","text":"STATIS method, related MFA, analysing two blocks. also decomposes data low-dimensional subspace uses different scaling individual blocks.","code":""},{"path":"https://khliland.github.io/multiblock/reference/statis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Structuration des Tableaux à Trois Indices de la Statistique - STATIS — statis","text":"Lavit, C.; Escoufier, Y.; Sabatier, R.; Traissac, P. (1994). ACT (STATIS method). Computational Statistics & Data Analysis. 18: 97","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/statis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Structuration des Tableaux à Trois Indices de la Statistique - STATIS — statis","text":"","code":"data(candies) candyList <- lapply(1:nlevels(candies$candy),function(x)candies$assessment[candies$candy==x,]) can.statis <- statis(candyList) plot(scores(can.statis), labels=\"names\")"},{"path":"https://khliland.github.io/multiblock/reference/supervised.html","id":null,"dir":"Reference","previous_headings":"","what":"Supervised Multiblock Methods — supervised","title":"Supervised Multiblock Methods — supervised","text":"Collection supervised multiblock methods: MB-PLS - Multiblock Partial Least Squares (mbpls) sMB-PLS - Sparse Multiblock Partial Least Squares (smbpls) -PLS - Sequential Orthogonalized PLS (sopls) PO-PLS - Parallel Orthogonalized PLS (popls) ROSA - Response Oriented Sequential Alternation (rosa) mbRDA - Multiblock Redundancy Analysis (mbrda)","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/supervised.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Supervised Multiblock Methods — supervised","text":"","code":"data(potato) mb <- mbpls(Sensory ~ Chemical + Compression, data=potato, ncomp = 5) print(mb) #> Multiblock PLS  #>  #> Call: #> mbpls(formula = Sensory ~ Chemical + Compression, data = potato,     ncomp = 5)  # Convert data.frame with AsIs objects to list of matrices potatoList <- lapply(potato, unclass) mbr <- mbrda(Sensory ~ Chemical + Compression, data=potatoList, ncomp = 10) print(mbr) #> Multiblock RDA  #>  #> Call: #> mbrda(formula = Sensory ~ Chemical + Compression, data = potatoList,     ncomp = 10) scoreplot(mbr, labels=\"names\")"},{"path":"https://khliland.github.io/multiblock/reference/unique_combos.html","id":null,"dir":"Reference","previous_headings":"","what":"Unique combinations of blocks — unique_combos","title":"Unique combinations of blocks — unique_combos","text":"Compute list possible block combinations number blocks combination limited parameters min_level max_level.","code":""},{"path":"https://khliland.github.io/multiblock/reference/unique_combos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unique combinations of blocks — unique_combos","text":"","code":"unique_combos(n_block, max_level, min_level = 2)"},{"path":"https://khliland.github.io/multiblock/reference/unique_combos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unique combinations of blocks — unique_combos","text":"n_block integer number input blocks. max_level integer maximum number blocks per combination. min_level integer minimum number blocks per combination.","code":""},{"path":"https://khliland.github.io/multiblock/reference/unique_combos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unique combinations of blocks — unique_combos","text":"list unique block combinations.","code":""},{"path":"https://khliland.github.io/multiblock/reference/unique_combos.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unique combinations of blocks — unique_combos","text":"function used minimal redundancy implementations rosa sopls lookups computed components.","code":""},{"path":"https://khliland.github.io/multiblock/reference/unique_combos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unique combinations of blocks — unique_combos","text":"","code":"unique_combos(3, 2) #> [[1]] #> [1] 1 2 #>  #> [[2]] #> [1] 1 3 #>  #> [[3]] #> [1] 2 3 #>"},{"path":"https://khliland.github.io/multiblock/reference/unsupervised.html","id":null,"dir":"Reference","previous_headings":"","what":"Unsupervised Multiblock Methods — unsupervised","title":"Unsupervised Multiblock Methods — unsupervised","text":"Collection unsupervised multiblock methods: SCA - Simultaneous Component Analysis (sca) GCA - Generalized Canonical Analysis (gca) GPA - Generalized Procrustes Analysis (gpa) MFA - Multiple Factor Analysis (mfa) PCA-GCA (pcagca) DISCO - Distinctive Common Components SCA (disco) HPCA - Hierarchical Principal component analysis (hpca) MCOA - Multiple Co-Inertia Analysis (mcoa) JIVE - Joint Individual Variation Explained (jive) STATIS - Structuration des Tableaux à Trois Indices de la Statistique (statis) HOGSVD - Higher Order Generalized SVD (hogsvd)","code":""},{"path":"https://khliland.github.io/multiblock/reference/unsupervised.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unsupervised Multiblock Methods — unsupervised","text":"Original documentation STATIS: statis. JIVE, STATIS HOGSVD assume variable linked matrices/data.frames, SCA handles links.","code":""},{"path":[]},{"path":"https://khliland.github.io/multiblock/reference/unsupervised.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unsupervised Multiblock Methods — unsupervised","text":"","code":"# Object linked data data(potato) potList <- as.list(potato[c(1,2,9)]) pot.sca    <- sca(potList)  # Variable linked data data(candies) candyList <- lapply(1:nlevels(candies$candy),function(x)candies$assessment[candies$candy==x,]) can.statis <- statis(candyList) plot(can.statis$statis)"},{"path":"https://khliland.github.io/multiblock/reference/wine.html","id":null,"dir":"Reference","previous_headings":"","what":"Wines of Val de Loire — wine","title":"Wines of Val de Loire — wine","text":"dataset contains sensory assessment 21 wines. assessments grouped according tasting process thus natural ordering blocks pointing forward remaining blocks process.","code":""},{"path":"https://khliland.github.io/multiblock/reference/wine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wines of Val de Loire — wine","text":"","code":"data(wine)"},{"path":"https://khliland.github.io/multiblock/reference/wine.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Wines of Val de Loire — wine","text":"data.frame 21 rows 5 variables: Smell rest Matrix sensory assessments View Matrix sensory assessments Smell shaking Matrix sensory assessments Tasting Matrix sensory assessments Global quality Matrix sensory assessments","code":""},{"path":"https://khliland.github.io/multiblock/reference/wine.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Wines of Val de Loire — wine","text":"Escofier B, Pages L. Analyses Factorielles Simples Multiples. Paris: Dunod; 1988.","code":""}]
